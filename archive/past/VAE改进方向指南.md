# AudioLDM2 VAE éŸ³é¢‘é‡å»ºæ”¹è¿›æ–¹å‘ä¸å®æ–½æ–¹æ¡ˆ

## å½“å‰çŠ¶å†µæ€»ç»“
- **æœ€ä½³SNR**: -1.96 dB
- **ç›¸å…³ç³»æ•°**: 0.0125 (å¾ˆä½)
- **ä¸»è¦é—®é¢˜**: Griffin-Limé‡å»ºè´¨é‡å·®ï¼Œç›¸ä½ä¿¡æ¯ä¸¢å¤±ä¸¥é‡

## æ”¹è¿›æ–¹å‘ä¼˜å…ˆçº§æ’åº

### ğŸš€ æ–¹å‘1ï¼šä½¿ç”¨ç¥ç»ç½‘ç»œVocoderæ›¿ä»£Griffin-Lim (æœ€é«˜ä¼˜å…ˆçº§)
**åŸå› **: Griffin-Limæ˜¯ä¸»è¦ç“¶é¢ˆï¼Œç¥ç»vocoderèƒ½å¤§å¹…æå‡é‡å»ºè´¨é‡

#### å…·ä½“æ–¹æ¡ˆï¼š
1. **é›†æˆHiFi-GAN vocoder**
   - AudioLDM2å†…éƒ¨ä½¿ç”¨çš„vocoderç±»å‹
   - ä¸“é—¨è®­ç»ƒç”¨äºmelåˆ°éŸ³é¢‘è½¬æ¢

2. **ä½¿ç”¨é¢„è®­ç»ƒçš„vocoderæ¨¡å‹**
   - Universal vocoder models
   - MelGAN, WaveGlowç­‰

**é¢„æœŸæ”¹å–„**: SNRå¯èƒ½æå‡5-10dB

---

### ğŸ“Š æ–¹å‘2ï¼šä¼˜åŒ–mel-spectrogramå‚æ•° (é«˜ä¼˜å…ˆçº§)
**å½“å‰é—®é¢˜**: 64ä¸ªmel binsä¿¡æ¯é‡ä¸è¶³

#### å…·ä½“æ”¹è¿›ï¼š
1. **å¢åŠ é¢‘ç‡åˆ†è¾¨ç‡**
   ```python
   n_mels = 128        # å½“å‰64 â†’ 128
   n_fft = 2048        # å½“å‰1024 â†’ 2048
   hop_length = 128    # å½“å‰160 â†’ 128 (æ›´é«˜æ—¶é—´åˆ†è¾¨ç‡)
   ```

2. **ä¼˜åŒ–é¢‘ç‡èŒƒå›´**
   ```python
   fmax = sample_rate // 2  # ä½¿ç”¨å…¨é¢‘å¸¦è€Œä¸æ˜¯8000Hz
   ```

**é¢„æœŸæ”¹å–„**: SNRæå‡2-3dB

---

### ğŸ§  æ–¹å‘3ï¼šæ”¹è¿›VAEæ¶æ„ (ä¸­ç­‰ä¼˜å…ˆçº§)
**é—®é¢˜**: å½“å‰VAEä¸ºç”Ÿæˆä¼˜åŒ–ï¼Œä¸æ˜¯é‡å»ºä¼˜åŒ–

#### æ–¹æ¡ˆï¼š
1. **å¾®è°ƒç°æœ‰VAE**
   - åœ¨é‡å»ºä»»åŠ¡ä¸Šfine-tune
   - æ·»åŠ æ„ŸçŸ¥æŸå¤±

2. **è®¾è®¡ä¸“ç”¨é‡å»ºVAE**
   - æ›´å¤§çš„æ½œåœ¨ç»´åº¦
   - æ®‹å·®è¿æ¥
   - æ³¨æ„åŠ›æœºåˆ¶

**é¢„æœŸæ”¹å–„**: SNRæå‡3-5dB

---

### ğŸ”§ æ–¹å‘4ï¼šå¤šé˜¶æ®µé‡å»ºç­–ç•¥ (ä¸­ç­‰ä¼˜å…ˆçº§)
**æ€è·¯**: åˆ†é˜¶æ®µé€æ­¥æå‡é‡å»ºè´¨é‡

#### å®ç°ï¼š
```
ç²—é‡å»º(VAE) â†’ ç»†èŠ‚è¡¥å¿(CNN) â†’ åå¤„ç†(æ»¤æ³¢)
```

**é¢„æœŸæ”¹å–„**: SNRæå‡2-4dB

---

### ğŸ“ˆ æ–¹å‘5ï¼šç«¯åˆ°ç«¯éŸ³é¢‘å‹ç¼© (é•¿æœŸç›®æ ‡)
**ç»ˆææ–¹æ¡ˆ**: ç›´æ¥åœ¨æ³¢å½¢åŸŸè¿›è¡Œå‹ç¼©

#### æŠ€æœ¯è·¯çº¿ï¼š
1. **WaveNet-based VAE**
2. **Transformer-basedéŸ³é¢‘ç¼–ç å™¨**
3. **GAN-basedé‡å»ºç½‘ç»œ**

**é¢„æœŸæ”¹å–„**: SNRæå‡10+dB

---

## ç«‹å³å¯å®æ–½çš„æ”¹è¿›æ–¹æ¡ˆ

### 1. ä½¿ç”¨AudioLDM2å†…ç½®Vocoder
æˆ‘å‘ç°AudioLDM2å·²ç»åŒ…å«äº†SpeechT5HifiGan vocoderï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•ç›´æ¥ä½¿ç”¨å®ƒï¼š

```python
# ç›´æ¥ä½¿ç”¨AudioLDM2çš„vocoderè¿›è¡Œé‡å»º
vocoder = pipeline.vocoder
mel_spectrogram = reconstructed_mel  # ä»VAEè§£ç çš„ç»“æœ
audio = vocoder(mel_spectrogram)
```

### 2. æ”¹è¿›melå‚æ•°é…ç½®
```python
# é«˜è´¨é‡melé…ç½®
mel_config = {
    'n_fft': 2048,
    'hop_length': 256,
    'win_length': 2048, 
    'n_mels': 128,
    'fmin': 0,
    'fmax': 8000,
    'power': 1.0  # ä½¿ç”¨å¹…åº¦è°±
}
```

### 3. å¤šç§å½’ä¸€åŒ–æ–¹æ³•æµ‹è¯•
```python
# æ–¹æ³•1: ç™¾åˆ†ä½æ•°å½’ä¸€åŒ–
p1, p99 = np.percentile(mel_db, [1, 99])
normalized = (mel_db - p1) / (p99 - p1)

# æ–¹æ³•2: Z-scoreå½’ä¸€åŒ–  
normalized = (mel_db - mel_db.mean()) / mel_db.std()

# æ–¹æ³•3: åŠ¨æ€èŒƒå›´å‹ç¼©
normalized = np.tanh(mel_db / 40)  # è½¯å‹ç¼©
```

### 4. åå¤„ç†æ”¹è¿›
```python
# é¢‘åŸŸæ»¤æ³¢
def spectral_smoothing(audio, sr=16000):
    stft = librosa.stft(audio)
    magnitude = np.abs(stft)
    phase = np.angle(stft)
    
    # å¹³æ»‘å¹…åº¦è°±
    smoothed_mag = scipy.signal.medfilt(magnitude, kernel_size=3)
    smoothed_stft = smoothed_mag * np.exp(1j * phase)
    
    return librosa.istft(smoothed_stft)
```

---

## æ¨èçš„å®æ–½é¡ºåº

### ç¬¬ä¸€é˜¶æ®µ (1-2å‘¨)ï¼šå¿«é€Ÿæ”¹è¿›
1. âœ… **é›†æˆAudioLDM2å†…ç½®vocoder** - é¢„æœŸæœ€å¤§æ”¹å–„
2. âœ… **ä¼˜åŒ–melå‚æ•°** - æå‡è¾“å…¥è´¨é‡  
3. âœ… **æ”¹è¿›å½’ä¸€åŒ–æ–¹æ³•** - ç¨³å®šè®­ç»ƒ

### ç¬¬äºŒé˜¶æ®µ (2-4å‘¨)ï¼šæ·±åº¦ä¼˜åŒ–
1. ğŸ”§ **å¤šé˜¶æ®µé‡å»ºpipeline**
2. ğŸ”§ **æ·»åŠ æ„ŸçŸ¥æŸå¤±å‡½æ•°**
3. ğŸ”§ **åå¤„ç†ç½‘ç»œè®¾è®¡**

### ç¬¬ä¸‰é˜¶æ®µ (1-3æœˆ)ï¼šæ¶æ„åˆ›æ–°
1. ğŸš€ **ç«¯åˆ°ç«¯å‹ç¼©ç½‘ç»œ**
2. ğŸš€ **è‡ªé€‚åº”å‹ç¼©ç‡**
3. ğŸš€ **å¤šæ¨¡æ€å‹ç¼©**

---

## å…·ä½“æŠ€æœ¯å®ç°å»ºè®®

### ç«‹å³å°è¯•ï¼šä½¿ç”¨AudioLDM2 Vocoder
æ ¹æ®æˆ‘ä»¬çš„æµ‹è¯•ï¼ŒAudioLDM2åŒ…å«`SpeechT5HifiGan` vocoderï¼Œé…ç½®å¦‚ä¸‹ï¼š
- sampling_rate: 16000
- model_in_dim: 64 (æ­£å¥½åŒ¹é…æˆ‘ä»¬çš„mel bins)
- upsample_rates: [5, 4, 2, 2, 2]

è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥ç›´æ¥ç”¨å®ƒè¿›è¡Œmelåˆ°éŸ³é¢‘çš„è½¬æ¢ï¼

### ä¸­æœŸç›®æ ‡ï¼šè®­ç»ƒä¸“ç”¨é‡å»ºç½‘ç»œ
```python
class ReconstructionVAE(nn.Module):
    def __init__(self, base_vae):
        super().__init__()
        self.encoder = base_vae.encoder
        self.decoder = base_vae.decoder
        self.refinement = RefinementNetwork()  # æ–°å¢ç»†åŒ–ç½‘ç»œ
    
    def forward(self, x):
        latents = self.encoder(x)
        coarse = self.decoder(latents)
        refined = self.refinement(coarse, x)  # æ®‹å·®è¿æ¥
        return refined
```

### è¯„ä¼°æŒ‡æ ‡æ‰©å±•
```python
def comprehensive_metrics(original, reconstructed):
    # åŸºç¡€æŒ‡æ ‡
    snr = calculate_snr(original, reconstructed)
    
    # æ„ŸçŸ¥æŒ‡æ ‡  
    pesq_score = pesq(16000, original, reconstructed)
    stoi_score = stoi(original, reconstructed, 16000)
    
    # é¢‘è°±æŒ‡æ ‡
    spectral_distance = spectral_convergence(original, reconstructed)
    
    return {
        'snr': snr,
        'pesq': pesq_score, 
        'stoi': stoi_score,
        'spectral_distance': spectral_distance
    }
```

---

## é¢„æœŸæ”¹å–„æ•ˆæœ

| æ”¹è¿›æ–¹æ¡ˆ | é¢„æœŸSNRæ”¹å–„ | å®æ–½éš¾åº¦ | æ—¶é—´æˆæœ¬ |
|---------|------------|---------|---------|
| ä½¿ç”¨ç¥ç»vocoder | +5~10 dB | ä¸­ç­‰ | 1-2å‘¨ |
| ä¼˜åŒ–melå‚æ•° | +2~3 dB | ç®€å• | 1-3å¤© |
| æ”¹è¿›å½’ä¸€åŒ– | +1~2 dB | ç®€å• | 1å¤© |
| å¤šé˜¶æ®µé‡å»º | +3~5 dB | è¾ƒéš¾ | 2-4å‘¨ |
| ç«¯åˆ°ç«¯æ–¹æ¡ˆ | +10+ dB | å¾ˆéš¾ | 1-3æœˆ |

**ç›®æ ‡**: å°†å½“å‰-1.96dBæå‡åˆ°+5dBä»¥ä¸Šï¼Œè¾¾åˆ°å¯ç”¨çš„å‹ç¼©è´¨é‡ã€‚

æ‚¨æƒ³ä»å“ªä¸ªæ–¹å‘å¼€å§‹ï¼Ÿæˆ‘å»ºè®®å…ˆä»é›†æˆAudioLDM2å†…ç½®vocoderå¼€å§‹ï¼Œå› ä¸ºè¿™å¯èƒ½å¸¦æ¥æœ€å¤§çš„æ”¹å–„ï¼
