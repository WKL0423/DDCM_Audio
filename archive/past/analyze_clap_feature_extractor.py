#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ·±å…¥åˆ†æAudioLDM2çš„ClapFeatureExtractor
"""

from diffusers import AudioLDM2Pipeline
import torch
import numpy as np
import librosa
from pathlib import Path

def analyze_clap_feature_extractor(audio_path):
    """åˆ†æClapFeatureExtractorçš„å·¥ä½œæ–¹å¼"""
    print("ğŸ” æ·±å…¥åˆ†æClapFeatureExtractor...")
    
    # åŠ è½½pipeline
    pipe = AudioLDM2Pipeline.from_pretrained('cvssp/audioldm2', torch_dtype=torch.float32)
    fe = pipe.feature_extractor
    
    print(f"\nğŸ“Š ClapFeatureExtractorè¯¦ç»†é…ç½®:")
    print(f"- é‡‡æ ·ç‡: {fe.sampling_rate} Hz")
    print(f"- n_fft: {fe.n_fft}")
    print(f"- hop_length: {fe.hop_length}")
    print(f"- é¢‘ç‡èŒƒå›´: {fe.frequency_min}-{fe.frequency_max} Hz")
    print(f"- ç‰¹å¾ç»´åº¦: {fe.feature_size}")
    print(f"- æœ€å¤§é•¿åº¦: {fe.max_length_s}ç§’")
    print(f"- chunk_length: {fe.chunk_length_s}ç§’")
    
    # åŠ è½½æµ‹è¯•éŸ³é¢‘
    print(f"\nğŸ“ åŠ è½½æµ‹è¯•éŸ³é¢‘: {Path(audio_path).name}")
    # æ³¨æ„ï¼šClapFeatureExtractoræœŸæœ›48kHz
    audio_48k, sr_48k = librosa.load(audio_path, sr=fe.sampling_rate, duration=3)
    audio_16k, sr_16k = librosa.load(audio_path, sr=16000, duration=3)
    
    print(f"- 48kHzéŸ³é¢‘: {len(audio_48k)/sr_48k:.2f}ç§’, {len(audio_48k)}æ ·æœ¬")
    print(f"- 16kHzéŸ³é¢‘: {len(audio_16k)/sr_16k:.2f}ç§’, {len(audio_16k)}æ ·æœ¬")
    
    # æµ‹è¯•feature extractor
    print(f"\nğŸ§ª æµ‹è¯•ClapFeatureExtractor:")
    try:
        # ä½¿ç”¨feature extractorå¤„ç†éŸ³é¢‘
        features = fe(audio_48k, return_tensors="pt", sampling_rate=fe.sampling_rate)
        print(f"- è¾“å…¥éŸ³é¢‘: {len(audio_48k)}æ ·æœ¬")
        print(f"- è¾“å‡ºç‰¹å¾: {features.input_features.shape}")
        print(f"- ç‰¹å¾èŒƒå›´: [{features.input_features.min():.3f}, {features.input_features.max():.3f}]")
        
        # æ£€æŸ¥è¾“å‡ºæ ¼å¼
        mel_from_fe = features.input_features
        print(f"- ç‰¹å¾ç»´åº¦: {mel_from_fe.shape}")
        
    except Exception as e:
        print(f"- å¤„ç†å¤±è´¥: {e}")
        mel_from_fe = None
    
    # å¯¹æ¯”æˆ‘ä»¬çš„melå¤„ç†
    print(f"\nğŸ“Š å¯¹æ¯”æˆ‘ä»¬çš„melå¤„ç†:")
    
    # æˆ‘ä»¬çš„æ–¹æ³•1: 16kHz
    mel_ours_16k = librosa.feature.melspectrogram(
        y=audio_16k, sr=16000, n_mels=64, hop_length=160, n_fft=1024
    )
    mel_ours_16k_db = librosa.power_to_db(mel_ours_16k, ref=np.max)
    print(f"- æˆ‘ä»¬çš„16kHz: {mel_ours_16k_db.shape}, èŒƒå›´[{mel_ours_16k_db.min():.1f}, {mel_ours_16k_db.max():.1f}]dB")
    
    # æˆ‘ä»¬çš„æ–¹æ³•2: 48kHzï¼Œä½†ç”¨ClapFeatureExtractorçš„å‚æ•°
    mel_ours_48k = librosa.feature.melspectrogram(
        y=audio_48k, sr=48000, n_mels=64, hop_length=480, n_fft=1024,
        fmin=50, fmax=14000  # ä½¿ç”¨ClapFeatureExtractorçš„é¢‘ç‡èŒƒå›´
    )
    mel_ours_48k_db = librosa.power_to_db(mel_ours_48k, ref=np.max)
    print(f"- æˆ‘ä»¬çš„48kHz: {mel_ours_48k_db.shape}, èŒƒå›´[{mel_ours_48k_db.min():.1f}, {mel_ours_48k_db.max():.1f}]dB")
    
    # æµ‹è¯•ç”¨ä¸åŒçš„melè¾“å…¥VAE
    print(f"\nğŸ§  æµ‹è¯•ä¸åŒmelè¾“å…¥çš„VAEæ•ˆæœ:")
    
    methods = []
    
    # æ–¹æ³•1: æˆ‘ä»¬çš„16kHzæ–¹æ³•
    if mel_ours_16k_db.shape[1] > 0:
        methods.append(("Our_16kHz", mel_ours_16k_db))
    
    # æ–¹æ³•2: æˆ‘ä»¬çš„48kHzæ–¹æ³•
    if mel_ours_48k_db.shape[1] > 0:
        methods.append(("Our_48kHz", mel_ours_48k_db))
    
    # æ–¹æ³•3: ClapFeatureExtractor
    if mel_from_fe is not None:
        methods.append(("ClapFeatureExtractor", mel_from_fe.squeeze().numpy()))
    
    results = {}
    
    for method_name, mel_data in methods:
        try:
            print(f"\n--- æµ‹è¯• {method_name} ---")
            
            # è½¬æ¢ä¸ºtensor
            mel_tensor = torch.from_numpy(mel_data).float()
            if mel_tensor.dim() == 2:
                mel_input = mel_tensor.unsqueeze(0).unsqueeze(0)
            else:
                mel_input = mel_tensor.unsqueeze(0)
            
            print(f"   è¾“å…¥: {mel_input.shape}")
            
            # VAEå¤„ç†
            with torch.no_grad():
                # ç¼–ç 
                latent_dist = pipe.vae.encode(mel_input)
                if hasattr(latent_dist, 'latent_dist'):
                    latent = latent_dist.latent_dist.sample()
                else:
                    latent = latent_dist.sample()
                
                latent = latent * pipe.vae.config.scaling_factor
                
                # è§£ç 
                latent_for_decode = latent / pipe.vae.config.scaling_factor
                reconstructed_mel = pipe.vae.decode(latent_for_decode).sample
                
                print(f"   VAEè¾“å‡º: {reconstructed_mel.shape}")
                print(f"   è¾“å‡ºèŒƒå›´: [{reconstructed_mel.min():.3f}, {reconstructed_mel.max():.3f}]")
                
                # å°è¯•vocoder
                try:
                    waveform = pipe.mel_spectrogram_to_waveform(reconstructed_mel)
                    recon_audio = waveform.squeeze().cpu().numpy()
                    
                    # è®¡ç®—SNR
                    if method_name == "Our_16kHz":
                        ref_audio = audio_16k
                    else:
                        ref_audio = audio_48k
                        
                    min_len = min(len(ref_audio), len(recon_audio))
                    ref_aligned = ref_audio[:min_len]
                    recon_aligned = recon_audio[:min_len]
                    
                    mse = np.mean((ref_aligned - recon_aligned) ** 2)
                    snr = 10 * np.log10(np.mean(ref_aligned ** 2) / (mse + 1e-10))
                    
                    print(f"   âœ… VocoderæˆåŠŸ: SNR={snr:.2f}dB")
                    
                    results[method_name] = {
                        'snr': snr,
                        'output_range': [recon_audio.min(), recon_audio.max()],
                        'success': True
                    }
                    
                except Exception as ve:
                    print(f"   âŒ Vocoderå¤±è´¥: {ve}")
                    results[method_name] = {'success': False, 'error': str(ve)}
                    
        except Exception as e:
            print(f"   âŒ æ•´ä½“å¤±è´¥: {e}")
            results[method_name] = {'success': False, 'error': str(e)}
    
    # æ€»ç»“ç»“æœ
    print(f"\nğŸ“‹ ç»“æœæ€»ç»“:")
    for method, result in results.items():
        if result['success']:
            print(f"âœ… {method}: SNR={result['snr']:.2f}dB, è¾“å‡ºèŒƒå›´{result['output_range']}")
        else:
            print(f"âŒ {method}: å¤±è´¥ - {result['error']}")
    
    return results

def main():
    """ä¸»å‡½æ•°"""
    audio_files = list(Path('.').glob('*.wav'))
    if not audio_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
        return
    
    print("æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶:")
    for i, file in enumerate(audio_files[:3], 1):
        print(f"{i}. {file.name}")
    
    try:
        choice = int(input("é€‰æ‹©æ–‡ä»¶: "))
        audio_path = str(audio_files[choice-1])
        
        results = analyze_clap_feature_extractor(audio_path)
        
        print(f"\nğŸ¯ å…³é”®å‘ç°:")
        print(f"- AudioLDM2ä½¿ç”¨ClapFeatureExtractorå¤„ç†éŸ³é¢‘")
        print(f"- æœŸæœ›48kHzé‡‡æ ·ç‡ï¼Œä¸æ˜¯16kHz")
        print(f"- ä½¿ç”¨ç‰¹å®šçš„hop_length=480å’Œé¢‘ç‡èŒƒå›´")
        
        # æ‰¾åˆ°æœ€ä½³æ–¹æ³•
        best_method = None
        best_snr = float('-inf')
        
        for method, result in results.items():
            if result['success'] and result['snr'] > best_snr:
                best_snr = result['snr']
                best_method = method
        
        if best_method:
            print(f"\nğŸ† æœ€ä½³æ–¹æ³•: {best_method} (SNR={best_snr:.2f}dB)")
        else:
            print(f"\nâš ï¸ æ²¡æœ‰æ‰¾åˆ°å®Œå…¨æˆåŠŸçš„æ–¹æ³•")
            
    except (ValueError, IndexError):
        print("âŒ æ— æ•ˆé€‰æ‹©")
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
