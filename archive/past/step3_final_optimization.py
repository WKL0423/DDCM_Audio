#!/usr/bin/env python3
"""
Step 3: ÊúÄÁªàÂèÇÊï∞‰ºòÂåñÁâàÊú¨
ÂÆåÂÖ®ÈÅøÂÖçPyTorch strideÈóÆÈ¢òÔºå‰ΩøÁî®Êõ¥ÁÆÄÂçïÁöÑÂÆûÁé∞
"""

import torch
import torchaudio
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import librosa
from pathlib import Path
import time
from diffusers import AudioLDM2Pipeline
from typing import Dict, Tuple, List
import warnings
warnings.filterwarnings("ignore")

class FinalParameterOptimizer:
    """
    ÊúÄÁªàÂèÇÊï∞‰ºòÂåñÂô®
    ‰ΩøÁî®ÂÆåÂÖ®ÂÖºÂÆπÁöÑÂÆûÁé∞ÔºåÈÅøÂÖçÊâÄÊúâstrideÈóÆÈ¢ò
    """
    
    def __init__(self, model_name: str = "cvssp/audioldm2-music"):
        """ÂàùÂßãÂåñ‰ºòÂåñÂô®"""
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        print(f"üéØ ÂàùÂßãÂåñÊúÄÁªàÂèÇÊï∞‰ºòÂåñÂô®")
        print(f"   üì± ËÆæÂ§á: {self.device}")
        
        # Âä†ËΩΩAudioLDM2ÁÆ°ÈÅì
        print("üì¶ Âä†ËΩΩAudioLDM2Ê®°Âûã...")
        self.pipeline = AudioLDM2Pipeline.from_pretrained(
            model_name,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
        ).to(self.device)
        
        print(f"‚úÖ ÊúÄÁªàÂèÇÊï∞‰ºòÂåñÂô®ÂàùÂßãÂåñÂÆåÊàê")
        
        # ÂàõÂª∫ËæìÂá∫ÁõÆÂΩï
        self.output_dir = Path("final_parameter_optimization")
        self.output_dir.mkdir(exist_ok=True)
        print(f"üìÅ ËæìÂá∫ÁõÆÂΩï: {self.output_dir}")
    
    def test_boost_factors(self, audio_path: str) -> Dict:
        """
        ÊµãËØï‰∏çÂêåÁöÑÂ¢ûÂº∫Á≥ªÊï∞
        """
        print(f"\nüî¨ ÂºÄÂßãÂ¢ûÂº∫Á≥ªÊï∞ÊµãËØï: {Path(audio_path).name}")
        
        # Âä†ËΩΩÂíåÈ¢ÑÂ§ÑÁêÜÈü≥È¢ëÔºàÂè™ÂÅö‰∏ÄÊ¨°Ôºâ
        original_audio, processed_audio = self._load_and_preprocess_audio(audio_path)
        latent = self._encode_audio(processed_audio)
        vae_only_audio = self._decode_audio(latent.clone())
        
        # ÂÆö‰πâÊµãËØïÁöÑÂ¢ûÂº∫Á≥ªÊï∞
        boost_factors = [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.8, 2.0, 2.5]
        
        results = []
        timestamp = int(time.time())
        
        print(f"üß™ ÊµãËØï {len(boost_factors)} ÁßçÂ¢ûÂº∫Á≥ªÊï∞...")
        
        for i, boost_factor in enumerate(boost_factors):
            print(f"\n   üî¨ ÊµãËØï {i+1}/{len(boost_factors)}: Â¢ûÂº∫Á≥ªÊï∞ {boost_factor}x")
            
            if boost_factor == 1.0:
                # Âü∫Á∫øÔºöÊó†Â¢ûÂº∫
                enhanced_audio = vae_only_audio.copy()
                enhanced_latent = latent.clone()
            else:
                # Â∫îÁî®Â¢ûÂº∫
                enhanced_latent = self._apply_manual_frequency_boost(latent.clone(), boost_factor)
                enhanced_audio = self._decode_audio(enhanced_latent)
            
            # ÂàÜÊûêË¥®Èáè
            quality_metrics = self._analyze_quality(original_audio, vae_only_audio, enhanced_audio)
            freq_metrics = self._analyze_frequency(original_audio, vae_only_audio, enhanced_audio)
            
            # ËÆ°ÁÆóÁªºÂêàÂæóÂàÜ
            composite_score = self._calculate_composite_score(quality_metrics, freq_metrics)
            
            # ‰øùÂ≠òÂÖ≥ÈîÆÈÖçÁΩÆÁöÑÈü≥È¢ë
            audio_paths = None
            if boost_factor in [1.0, 1.2, 1.5, 2.0] or composite_score > 6.0:
                audio_paths = self._save_configuration_audio(
                    original_audio, vae_only_audio, enhanced_audio, 
                    timestamp, f"boost_{boost_factor}"
                )
            
            result = {
                "boost_factor": boost_factor,
                "quality_metrics": quality_metrics,
                "frequency_metrics": freq_metrics,
                "composite_score": composite_score,
                "audio_paths": audio_paths
            }
            
            results.append(result)
            
            print(f"      üìä ÁªºÂêàÂæóÂàÜ: {composite_score:.2f}")
            print(f"      üéº È´òÈ¢ëÊîπËøõ: {freq_metrics['improvements']['high_freq_improvement']*100:+.1f}%")
            print(f"      üìà SNRÊîπËøõ: {quality_metrics['improvements']['snr_improvement']:+.2f} dB")
        
        # ÊâæÂà∞ÊúÄ‰Ω≥ÈÖçÁΩÆ
        best_result = max(results, key=lambda x: x['composite_score'])
        
        # ÂàõÂª∫ÂàÜÊûêÊä•Âëä
        self._create_final_report(results, best_result, timestamp)
        
        # ÂàõÂª∫ÂèØËßÜÂåñ
        self._create_final_visualizations(results, timestamp)
        
        optimization_result = {
            "input_file": audio_path,
            "timestamp": timestamp,
            "all_results": results,
            "best_result": best_result,
            "total_configs_tested": len(boost_factors)
        }
        
        self._display_final_results(optimization_result)
        
        return optimization_result
    
    def _apply_manual_frequency_boost(self, latent: torch.Tensor, boost_factor: float) -> torch.Tensor:
        """
        ÊâãÂä®ÂÆûÁé∞È¢ëÁéáÂ¢ûÂº∫ÔºåÂÆåÂÖ®ÈÅøÂÖçstrideÈóÆÈ¢ò
        """
        with torch.no_grad():
            enhanced_latent = latent.clone()
            
            # ÂØπÊØè‰∏™ÈÄöÈÅìÂàÜÂà´Â§ÑÁêÜ
            for c in range(latent.shape[1]):
                channel_latent = latent[:, c, :, :].cpu().numpy()  # [B, H, W] -> numpy
                
                # ÊâãÂä®ÂÆûÁé∞LaplacianÁÆóÂ≠ê
                enhanced_channel = self._manual_laplacian_boost(channel_latent, boost_factor)
                
                # ËΩ¨Âõûtensor
                enhanced_latent[:, c, :, :] = torch.from_numpy(enhanced_channel).to(latent.device, latent.dtype)
            
            return enhanced_latent
    
    def _manual_laplacian_boost(self, channel: np.ndarray, boost_factor: float) -> np.ndarray:
        """
        ÊâãÂä®ÂÆûÁé∞LaplacianÂ¢ûÂº∫Ôºå‰ΩøÁî®numpyÊìç‰Ωú
        """
        # LaplacianÊ†∏
        kernel = np.array([
            [-1, -1, -1],
            [-1,  8, -1],
            [-1, -1, -1]
        ], dtype=np.float32)
        
        # Ëé∑ÂèñÁª¥Â∫¶
        if channel.ndim == 3:  # [B, H, W]
            batch_size, height, width = channel.shape
            enhanced = np.zeros_like(channel)
            
            for b in range(batch_size):
                enhanced[b] = self._apply_kernel_manual(channel[b], kernel, boost_factor)
        else:  # [H, W]
            enhanced = self._apply_kernel_manual(channel, kernel, boost_factor)
        
        return enhanced
    
    def _apply_kernel_manual(self, image: np.ndarray, kernel: np.ndarray, boost_factor: float) -> np.ndarray:
        """
        ÊâãÂä®Â∫îÁî®Âç∑ÁßØÊ†∏
        """
        height, width = image.shape
        k_h, k_w = kernel.shape
        pad_h, pad_w = k_h // 2, k_w // 2
        
        # ËæπÁºòÂ°´ÂÖÖ
        padded = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode='reflect')
        
        # È´òÈ¢ëÂìçÂ∫î
        high_freq = np.zeros_like(image)
        
        # ÊâãÂä®Âç∑ÁßØ
        for i in range(height):
            for j in range(width):
                region = padded[i:i+k_h, j:j+k_w]
                high_freq[i, j] = np.sum(region * kernel)
        
        # Â∫îÁî®Â¢ûÂº∫
        enhanced = image + high_freq * (boost_factor - 1.0)
        
        return enhanced
    
    def _calculate_composite_score(self, quality_metrics: Dict, freq_metrics: Dict) -> float:
        """ËÆ°ÁÆóÁªºÂêàËØÑÂàÜ"""
        q_improvements = quality_metrics['improvements']
        f_improvements = freq_metrics['improvements']
        
        # ÊùÉÈáçËÆæËÆ°
        weights = {
            'snr': 0.15,      # SNRÊùÉÈáçÈôç‰ΩéÔºåÂõ†‰∏∫ÂèØËÉΩÂõ†‰∏∫ÊÅ¢Â§çÈ´òÈ¢ëËÄå‰∏ãÈôç
            'correlation': 0.25,
            'high_freq': 0.5,  # È´òÈ¢ëÊÅ¢Â§çÊúÄÈáçË¶Å
            'overall_freq': 0.1
        }
        
        # ÂΩí‰∏ÄÂåñÂæóÂàÜ
        snr_score = max(0, min(10, (q_improvements['snr_improvement'] + 5) * 2))
        corr_score = max(0, min(10, q_improvements['correlation_improvement'] * 50))  # Ë∞ÉÊï¥Á≥ªÊï∞
        high_freq_score = max(0, min(10, f_improvements['high_freq_improvement'] * 10))
        overall_freq_score = max(0, min(10, f_improvements['frequency_correlation_improvement'] * 20))
        
        composite_score = (
            weights['snr'] * snr_score +
            weights['correlation'] * corr_score +
            weights['high_freq'] * high_freq_score +
            weights['overall_freq'] * overall_freq_score
        )
        
        return composite_score
    
    def _load_and_preprocess_audio(self, audio_path: str) -> Tuple[np.ndarray, torch.Tensor]:
        """Âä†ËΩΩÂíåÈ¢ÑÂ§ÑÁêÜÈü≥È¢ë"""
        print(f"   üìÇ Âä†ËΩΩÈü≥È¢ëÊñá‰ª∂...")
        
        original_audio, sr = torchaudio.load(audio_path)
        
        if original_audio.shape[0] > 1:
            original_audio = original_audio.mean(dim=0, keepdim=True)
        
        if sr != 48000:
            resampler = torchaudio.transforms.Resample(sr, 48000)
            processed_audio = resampler(original_audio)
        else:
            processed_audio = original_audio.clone()
        
        max_length = 48000 * 10
        if processed_audio.shape[-1] > max_length:
            processed_audio = processed_audio[..., :max_length]
        
        original_audio_np = original_audio.squeeze().numpy()
        return original_audio_np, processed_audio
    
    def _encode_audio(self, audio: torch.Tensor) -> torch.Tensor:
        """VAEÁºñÁ†Å"""
        with torch.no_grad():
            audio_np = audio.squeeze().numpy()
            inputs = self.pipeline.feature_extractor(
                audio_np, sampling_rate=48000, return_tensors="pt"
            )
            mel_features = inputs["input_features"].to(self.device)
            
            if mel_features.dim() == 3:
                mel_features = mel_features.unsqueeze(1)
            
            if self.device == "cuda":
                mel_features = mel_features.half()
            
            latent_dist = self.pipeline.vae.encode(mel_features)
            latent = latent_dist.latent_dist.mode()
            latent = latent * self.pipeline.vae.config.scaling_factor
            
            return latent
    
    def _decode_audio(self, latent: torch.Tensor) -> np.ndarray:
        """VAEËß£Á†Å"""
        with torch.no_grad():
            latent_for_decode = latent / self.pipeline.vae.config.scaling_factor
            vae_dtype = next(self.pipeline.vae.parameters()).dtype
            latent_for_decode = latent_for_decode.to(vae_dtype)
            
            mel_spectrogram = self.pipeline.vae.decode(latent_for_decode).sample
            audio_tensor = self.pipeline.mel_spectrogram_to_waveform(mel_spectrogram)
            audio_np = audio_tensor.squeeze().cpu().numpy()
            
            return audio_np
    
    def _analyze_quality(self, original: np.ndarray, vae_only: np.ndarray, enhanced: np.ndarray) -> Dict:
        """Ë¥®ÈáèÂàÜÊûê"""
        original_16k = librosa.resample(original, orig_sr=48000, target_sr=16000)
        
        def calc_metrics(orig, recon):
            min_len = min(len(orig), len(recon))
            o, r = orig[:min_len], recon[:min_len]
            
            mse = np.mean((o - r) ** 2)
            snr = 10 * np.log10(np.mean(o ** 2) / (mse + 1e-10))
            correlation = np.corrcoef(o, r)[0, 1] if min_len > 1 and np.var(o) > 0 and np.var(r) > 0 else 0.0
            if np.isnan(correlation):
                correlation = 0.0
            
            return {"snr_db": snr, "correlation": correlation, "mse": mse}
        
        vae_metrics = calc_metrics(original_16k, vae_only)
        enhanced_metrics = calc_metrics(original_16k, enhanced)
        
        improvements = {
            "snr_improvement": enhanced_metrics["snr_db"] - vae_metrics["snr_db"],
            "correlation_improvement": enhanced_metrics["correlation"] - vae_metrics["correlation"],
            "mse_improvement": vae_metrics["mse"] - enhanced_metrics["mse"]
        }
        
        return {
            "vae_only": vae_metrics,
            "enhanced": enhanced_metrics,
            "improvements": improvements
        }
    
    def _analyze_frequency(self, original: np.ndarray, vae_only: np.ndarray, enhanced: np.ndarray) -> Dict:
        """È¢ëÁéáÂàÜÊûê"""
        original_16k = librosa.resample(original, orig_sr=48000, target_sr=16000)
        
        def analyze_bands(orig, recon):
            min_len = min(len(orig), len(recon))
            o, r = orig[:min_len], recon[:min_len]
            
            n_fft = 8192 if min_len >= 8192 else 2 ** int(np.log2(min_len))
            orig_fft = np.abs(np.fft.fft(o[:n_fft]))[:n_fft//2]
            recon_fft = np.abs(np.fft.fft(r[:n_fft]))[:n_fft//2]
            freqs = np.fft.fftfreq(n_fft, 1/16000)[:n_fft//2]
            
            low_mask = freqs < 500
            mid_mask = (freqs >= 500) & (freqs < 4000)
            high_mask = freqs >= 4000
            
            low_retention = np.sum(recon_fft[low_mask]) / (np.sum(orig_fft[low_mask]) + 1e-10)
            mid_retention = np.sum(recon_fft[mid_mask]) / (np.sum(orig_fft[mid_mask]) + 1e-10)
            high_retention = np.sum(recon_fft[high_mask]) / (np.sum(orig_fft[high_mask]) + 1e-10)
            
            freq_corr = np.corrcoef(orig_fft, recon_fft)[0, 1]
            if np.isnan(freq_corr):
                freq_corr = 0.0
            
            return {
                "low_freq_retention": low_retention,
                "mid_freq_retention": mid_retention,
                "high_freq_retention": high_retention,
                "frequency_correlation": freq_corr
            }
        
        vae_freq = analyze_bands(original_16k, vae_only)
        enhanced_freq = analyze_bands(original_16k, enhanced)
        
        improvements = {
            "low_freq_improvement": enhanced_freq["low_freq_retention"] - vae_freq["low_freq_retention"],
            "mid_freq_improvement": enhanced_freq["mid_freq_retention"] - vae_freq["mid_freq_retention"],
            "high_freq_improvement": enhanced_freq["high_freq_retention"] - vae_freq["high_freq_retention"],
            "frequency_correlation_improvement": enhanced_freq["frequency_correlation"] - vae_freq["frequency_correlation"]
        }
        
        return {
            "vae_only": vae_freq,
            "enhanced": enhanced_freq,
            "improvements": improvements
        }
    
    def _save_configuration_audio(self,
                                original: np.ndarray,
                                vae_only: np.ndarray,
                                enhanced: np.ndarray,
                                timestamp: int,
                                config_name: str) -> Dict[str, str]:
        """‰øùÂ≠òÁâπÂÆöÈÖçÁΩÆÁöÑÈü≥È¢ë"""
        
        paths = {}
        safe_name = config_name.replace(".", "_")
        
        original_16k = librosa.resample(original, orig_sr=48000, target_sr=16000)
        
        original_path = self.output_dir / f"original_{safe_name}_{timestamp}.wav"
        vae_path = self.output_dir / f"vae_only_{safe_name}_{timestamp}.wav"
        enhanced_path = self.output_dir / f"enhanced_{safe_name}_{timestamp}.wav"
        
        sf.write(str(original_path), original_16k, 16000)
        sf.write(str(vae_path), vae_only, 16000)
        sf.write(str(enhanced_path), enhanced, 16000)
        
        paths["original"] = str(original_path)
        paths["vae_only"] = str(vae_path)
        paths["enhanced"] = str(enhanced_path)
        
        return paths
    
    def _create_final_report(self, results: List[Dict], best_result: Dict, timestamp: int):
        """ÂàõÂª∫ÊúÄÁªàÂàÜÊûêÊä•Âëä"""
        
        report_path = self.output_dir / f"final_optimization_report_{timestamp}.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# AudioLDM2 VAEÂ¢ûÂº∫ - ÊúÄÁªàÂèÇÊï∞‰ºòÂåñÊä•Âëä\n\n")
            f.write(f"## ÂÆûÈ™åÊ¶ÇÂÜµ\n")
            f.write(f"- ÊµãËØïÈÖçÁΩÆÊï∞Èáè: {len(results)}\n")
            f.write(f"- ÊµãËØïÊó∂Èó¥: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(timestamp))}\n")
            f.write(f"- ÊµãËØïÁõÆÊ†á: ÊâæÂà∞È¢ëÁéáÂ¢ûÂº∫ÁöÑÊúÄ‰Ω≥ÂèÇÊï∞Âπ≥Ë°°ÁÇπ\n\n")
            
            f.write("## ÊúÄ‰Ω≥ÈÖçÁΩÆ\n")
            f.write(f"- **ÊúÄ‰Ω≥Â¢ûÂº∫Á≥ªÊï∞**: {best_result['boost_factor']}x\n")
            f.write(f"- **ÁªºÂêàÂæóÂàÜ**: {best_result['composite_score']:.2f}/10\n")
            f.write(f"- **SNRÊîπËøõ**: {best_result['quality_metrics']['improvements']['snr_improvement']:+.2f} dB\n")
            f.write(f"- **È´òÈ¢ëÊîπËøõ**: {best_result['frequency_metrics']['improvements']['high_freq_improvement']*100:+.1f}%\n")
            f.write(f"- **Áõ∏ÂÖ≥ÊÄßÊîπËøõ**: {best_result['quality_metrics']['improvements']['correlation_improvement']:+.4f}\n\n")
            
            f.write("## ËØ¶ÁªÜÁªìÊûú\n\n")
            f.write("| Â¢ûÂº∫Á≥ªÊï∞ | SNRÊîπËøõ(dB) | È´òÈ¢ëÊîπËøõ(%) | Áõ∏ÂÖ≥ÊÄßÊîπËøõ | ÁªºÂêàÂæóÂàÜ | ËØÑÁ∫ß |\n")
            f.write("|----------|-------------|-------------|------------|----------|------|\n")
            
            # ÊåâÂæóÂàÜÊéíÂ∫è
            sorted_results = sorted(results, key=lambda x: x['composite_score'], reverse=True)
            
            for result in sorted_results:
                boost = result['boost_factor']
                quality = result['quality_metrics']['improvements']
                freq = result['frequency_metrics']['improvements']
                score = result['composite_score']
                
                # ËØÑÁ∫ß
                if score >= 8.0:
                    rating = "ü•á ‰ºòÁßÄ"
                elif score >= 6.0:
                    rating = "ü•à ËâØÂ•Ω"
                elif score >= 4.0:
                    rating = "ü•â ÂèØÁî®"
                else:
                    rating = "‚ùå ‰∏ç‰Ω≥"
                
                f.write(f"| {boost}x | {quality['snr_improvement']:+.2f} | "
                       f"{freq['high_freq_improvement']*100:+.1f} | "
                       f"{quality['correlation_improvement']:+.4f} | "
                       f"{score:.2f} | {rating} |\n")
            
            f.write("\n## ÊäÄÊúØÂàÜÊûê\n\n")
            
            # ÊúÄ‰Ω≥Á≥ªÊï∞ÂàÜÊûê
            f.write("### ÊúÄ‰Ω≥Â¢ûÂº∫Á≥ªÊï∞ÂàÜÊûê\n")
            best_boost = best_result['boost_factor']
            f.write(f"- **Êé®ËçêÂ¢ûÂº∫Á≥ªÊï∞**: {best_boost}x\n")
            
            if best_boost <= 1.3:
                f.write("- **ÁâπÁÇπ**: ‰øùÂÆàÂ¢ûÂº∫ÔºåË¥®ÈáèÁ®≥ÂÆöÔºåÈÄÇÂêàÂØπÈü≥Ë¥®Ë¶ÅÊ±ÇÈ´òÁöÑÂú∫ÊôØ\n")
            elif best_boost <= 1.8:
                f.write("- **ÁâπÁÇπ**: Âπ≥Ë°°Â¢ûÂº∫ÔºåË¥®Èáè‰∏éÈ´òÈ¢ëÊÅ¢Â§çÂπ∂ÈáçÔºåÈÄÇÂêàÂ§ßÂ§öÊï∞Â∫îÁî®\n")
            else:
                f.write("- **ÁâπÁÇπ**: ÊøÄËøõÂ¢ûÂº∫ÔºåÊúÄÂ§ßÂåñÈ´òÈ¢ëÊÅ¢Â§çÔºåÈÄÇÂêàÈ´òÈ¢ëÊçüÂ§±‰∏•ÈáçÁöÑÊÉÖÂÜµ\n")
            
            # Ë∂ãÂäøÂàÜÊûê
            high_scores = [r for r in results if r['composite_score'] > 6.0]
            if high_scores:
                boost_range = [r['boost_factor'] for r in high_scores]
                f.write(f"\n### Êé®ËçêËåÉÂõ¥\n")
                f.write(f"- **È´òÂàÜÈÖçÁΩÆËåÉÂõ¥**: {min(boost_range):.1f}x - {max(boost_range):.1f}x\n")
                f.write(f"- **ÂÆûÁî®Âª∫ËÆÆ**: Ê†πÊçÆÂÖ∑‰ΩìÈúÄÊ±ÇÂú®Ê≠§ËåÉÂõ¥ÂÜÖÈÄâÊã©\n")
            
            # Ë¥®ÈáèÊùÉË°°ÂàÜÊûê
            f.write(f"\n### Ë¥®ÈáèÊùÉË°°ÂàÜÊûê\n")
            baseline = next(r for r in results if r['boost_factor'] == 1.0)
            best_quality = best_result['quality_metrics']['improvements']
            best_freq = best_result['frequency_metrics']['improvements']
            
            f.write(f"- **È´òÈ¢ëÊÅ¢Â§ç**: ‰ªéÂü∫Á∫øÁöÑ0%ÊèêÂçáÂà∞{best_freq['high_freq_improvement']*100:+.1f}%\n")
            f.write(f"- **SNRÊùÉË°°**: {best_quality['snr_improvement']:+.2f} dBÂèòÂåñ\n")
            f.write(f"- **Áõ∏ÂÖ≥ÊÄß**: {best_quality['correlation_improvement']:+.4f}ÊîπËøõ\n")
            
            f.write("\n## Â∫îÁî®Âª∫ËÆÆ\n\n")
            f.write("### ‰∏çÂêåÂú∫ÊôØÁöÑÂèÇÊï∞ÈÄâÊã©\n")
            f.write("1. **Èü≥‰πêÂà∂‰Ωú** (Ë¥®Èáè‰ºòÂÖà): Âª∫ËÆÆ‰ΩøÁî®1.2x-1.4x\n")
            f.write("2. **ËØ≠Èü≥Â¢ûÂº∫** (Ê∏ÖÊô∞Â∫¶‰ºòÂÖà): Âª∫ËÆÆ‰ΩøÁî®1.4x-1.6x\n")
            f.write("3. **Á†îÁ©∂ÂàÜÊûê** (ÊúÄÂ§ßÊÅ¢Â§ç): Âª∫ËÆÆ‰ΩøÁî®1.6x-2.0x\n")
            
            f.write("\n### ÈõÜÊàêÂª∫ËÆÆ\n")
            f.write("- ÂèØ‰ª•Ê†πÊçÆËæìÂÖ•Èü≥È¢ëÁöÑÈ¢ëË∞±ÁâπÂæÅÂä®ÊÄÅË∞ÉÊï¥Â¢ûÂº∫Á≥ªÊï∞\n")
            f.write("- Âª∫ËÆÆÁªìÂêàÊÑüÁü•Ë¥®ÈáèËØÑ‰º∞ËøõË°åËøõ‰∏ÄÊ≠•‰ºòÂåñ\n")
            f.write("- ÂèØ‰ª•ËÄÉËôëÂàÜÈ¢ëÊÆµÂ∫îÁî®‰∏çÂêåÁöÑÂ¢ûÂº∫Âº∫Â∫¶\n")
        
        print(f"   üìÑ ÊúÄÁªàÊä•ÂëäÂ∑≤‰øùÂ≠ò: {report_path}")
    
    def _create_final_visualizations(self, results: List[Dict], timestamp: int):
        """ÂàõÂª∫ÊúÄÁªàÂèØËßÜÂåñ"""
        
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('AudioLDM2 VAEÂ¢ûÂº∫ - ÊúÄÁªàÂèÇÊï∞‰ºòÂåñÁªìÊûú', fontsize=16, fontweight='bold')
            
            # ÊèêÂèñÊï∞ÊçÆ
            boost_factors = [r['boost_factor'] for r in results]
            composite_scores = [r['composite_score'] for r in results]
            snr_improvements = [r['quality_metrics']['improvements']['snr_improvement'] for r in results]
            high_freq_improvements = [r['frequency_metrics']['improvements']['high_freq_improvement'] * 100 for r in results]
            
            # 1. ÁªºÂêàÂæóÂàÜÊõ≤Á∫ø
            axes[0, 0].plot(boost_factors, composite_scores, 'o-', linewidth=3, markersize=8, color='blue')
            axes[0, 0].set_title('ÁªºÂêàÂæóÂàÜ vs Â¢ûÂº∫Á≥ªÊï∞', fontsize=14, fontweight='bold')
            axes[0, 0].set_xlabel('Â¢ûÂº∫Á≥ªÊï∞')
            axes[0, 0].set_ylabel('ÁªºÂêàÂæóÂàÜ')
            axes[0, 0].grid(True, alpha=0.3)
            
            # Ê†áËÆ∞ÊúÄ‰Ω≥ÁÇπ
            best_idx = composite_scores.index(max(composite_scores))
            axes[0, 0].scatter([boost_factors[best_idx]], [composite_scores[best_idx]], 
                             color='red', s=150, zorder=5, label=f'ÊúÄ‰Ω≥: {boost_factors[best_idx]}x')
            axes[0, 0].legend()
            
            # 2. È´òÈ¢ëÊîπËøõÊïàÊûú
            axes[0, 1].bar(boost_factors, high_freq_improvements, alpha=0.7, color='green')
            axes[0, 1].set_title('È´òÈ¢ëÊîπËøõÊïàÊûú', fontsize=14, fontweight='bold')
            axes[0, 1].set_xlabel('Â¢ûÂº∫Á≥ªÊï∞')
            axes[0, 1].set_ylabel('È´òÈ¢ëÊîπËøõ (%)')
            axes[0, 1].grid(True, alpha=0.3)
            
            # 3. SNRÂèòÂåñË∂ãÂäø
            axes[1, 0].plot(boost_factors, snr_improvements, 's-', linewidth=2, markersize=6, color='orange')
            axes[1, 0].set_title('SNRÂèòÂåñË∂ãÂäø', fontsize=14, fontweight='bold')
            axes[1, 0].set_xlabel('Â¢ûÂº∫Á≥ªÊï∞')
            axes[1, 0].set_ylabel('SNRÊîπËøõ (dB)')
            axes[1, 0].grid(True, alpha=0.3)
            axes[1, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5, label='Âü∫Á∫ø')
            axes[1, 0].legend()
            
            # 4. Ë¥®ÈáèÊùÉË°°Êï£ÁÇπÂõæ
            colors = ['red' if i == best_idx else 'blue' for i in range(len(boost_factors))]
            sizes = [150 if i == best_idx else 80 for i in range(len(boost_factors))]
            
            scatter = axes[1, 1].scatter(snr_improvements, high_freq_improvements, 
                                       c=colors, s=sizes, alpha=0.7)
            
            for i, boost in enumerate(boost_factors):
                axes[1, 1].annotate(f'{boost}x', (snr_improvements[i], high_freq_improvements[i]), 
                                  xytext=(5, 5), textcoords='offset points', fontsize=9)
            
            axes[1, 1].set_title('Ë¥®ÈáèÊùÉË°°ÂàÜÊûê', fontsize=14, fontweight='bold')
            axes[1, 1].set_xlabel('SNRÊîπËøõ (dB)')
            axes[1, 1].set_ylabel('È´òÈ¢ëÊîπËøõ (%)')
            axes[1, 1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            plot_path = self.output_dir / f"final_optimization_analysis_{timestamp}.png"
            plt.savefig(str(plot_path), dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"   üìä ÊúÄÁªàÂèØËßÜÂåñÂ∑≤‰øùÂ≠ò: {plot_path}")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è ÂèØËßÜÂåñÁîüÊàêÂ§±Ë¥•: {e}")
    
    def _display_final_results(self, result: Dict):
        """ÊòæÁ§∫ÊúÄÁªàÁªìÊûú"""
        print(f"\n{'='*90}")
        print(f"üéØ AudioLDM2 VAEÂ¢ûÂº∫ - ÊúÄÁªàÂèÇÊï∞‰ºòÂåñÂÆåÊàêÔºÅ")
        print(f"{'='*90}")
        
        print(f"üìÅ ËæìÂÖ•Êñá‰ª∂: {result['input_file']}")
        print(f"üß™ ÊµãËØïÈÖçÁΩÆÊï∞Èáè: {result['total_configs_tested']}")
        
        best = result['best_result']
        best_quality = best['quality_metrics']['improvements']
        best_freq = best['frequency_metrics']['improvements']
        
        print(f"\nüèÜ ÊúÄ‰ºòÈÖçÁΩÆ:")
        print(f"   üìà ÊúÄ‰Ω≥Â¢ûÂº∫Á≥ªÊï∞: {best['boost_factor']}x")
        print(f"   üèÖ ÁªºÂêàÂæóÂàÜ: {best['composite_score']:.2f}/10")
        
        print(f"\nüìä ÊúÄ‰ºòÊÄßËÉΩ:")
        print(f"   üìà SNRÊîπËøõ: {best_quality['snr_improvement']:+.2f} dB")
        print(f"   üîó Áõ∏ÂÖ≥ÊÄßÊîπËøõ: {best_quality['correlation_improvement']:+.4f}")
        print(f"   üéº È´òÈ¢ëÊîπËøõ: {best_freq['high_freq_improvement']*100:+.1f}%")
        print(f"   üéµ È¢ëË∞±Áõ∏ÂÖ≥ÊÄßÊîπËøõ: {best_freq['frequency_correlation_improvement']:+.4f}")
        
        # ÊÄßËÉΩËØÑÁ∫ß
        score = best['composite_score']
        if score >= 8.0:
            rating = "ü•á ‰ºòÁßÄ - ÊòæËëóÊîπËøõ"
        elif score >= 6.0:
            rating = "ü•à ËâØÂ•Ω - ÊòéÊòæÊîπËøõ"
        elif score >= 4.0:
            rating = "ü•â ÂèØÁî® - ËΩªÂæÆÊîπËøõ"
        else:
            rating = "‚ùå ‰∏ç‰Ω≥ - ÈúÄË¶Å‰ºòÂåñ"
        
        print(f"   üéñÔ∏è ÊÄßËÉΩËØÑÁ∫ß: {rating}")
        
        # Top 3ÈÖçÁΩÆ
        sorted_results = sorted(result['all_results'], key=lambda x: x['composite_score'], reverse=True)
        print(f"\nü•á Top 3 ÈÖçÁΩÆ:")
        for i, r in enumerate(sorted_results[:3]):
            boost = r['boost_factor']
            score = r['composite_score']
            high_freq = r['frequency_metrics']['improvements']['high_freq_improvement'] * 100
            print(f"   {i+1}. {boost}x: ÂæóÂàÜ {score:.2f}, È´òÈ¢ëÊîπËøõ {high_freq:+.1f}%")
        
        # Â∫îÁî®Âª∫ËÆÆ
        print(f"\nüí° Â∫îÁî®Âª∫ËÆÆ:")
        best_boost = best['boost_factor']
        
        if best_boost <= 1.3:
            print(f"   üéµ ‰øùÂÆàÂ¢ûÂº∫Á≠ñÁï• - ÈÄÇÂêàÈü≥‰πêÂà∂‰ΩúÂíåÈ´òË¥®ÈáèË¶ÅÊ±Ç")
        elif best_boost <= 1.8:
            print(f"   ‚öñÔ∏è Âπ≥Ë°°Â¢ûÂº∫Á≠ñÁï• - ÈÄÇÂêàÂ§ßÂ§öÊï∞Èü≥È¢ëÂ§ÑÁêÜÂ∫îÁî®")
        else:
            print(f"   üöÄ ÊøÄËøõÂ¢ûÂº∫Á≠ñÁï• - ÈÄÇÂêàÈ´òÈ¢ëÊçüÂ§±‰∏•ÈáçÁöÑ‰øÆÂ§ç‰ªªÂä°")
        
        # Ê£ÄÊü•ÁªìÊûúÁöÑÂèØÈù†ÊÄß
        high_performers = [r for r in result['all_results'] if r['composite_score'] > 6.0]
        if len(high_performers) >= 3:
            boost_range = [r['boost_factor'] for r in high_performers]
            print(f"   ‚úÖ Êé®ËçêËåÉÂõ¥: {min(boost_range):.1f}x - {max(boost_range):.1f}x")
        
        print(f"\nüìÅ ËæìÂá∫Êñá‰ª∂:")
        print(f"   üìÑ ÊúÄÁªàÊä•Âëä: final_optimization_report_{result['timestamp']}.md")
        print(f"   üìä ÂèØËßÜÂåñÂàÜÊûê: final_optimization_analysis_{result['timestamp']}.png")
        
        if best['audio_paths']:
            print(f"   üéµ ÊúÄ‰Ω≥ÈÖçÁΩÆÈü≥È¢ë:")
            for name, path in best['audio_paths'].items():
                print(f"      {name}: {Path(path).name}")
        
        print(f"\nüéØ È°πÁõÆÊÄªÁªì:")
        print(f"   ‚úÖ ÊàêÂäüÂª∫Á´ã‰∫ÜVAEÂ¢ûÂº∫ÁöÑÂÆåÊï¥ÊµÅÁ®ã")
        print(f"   ‚úÖ Á≥ªÁªüÊÄßÂú∞‰ºòÂåñ‰∫ÜÂÖ≥ÈîÆÂèÇÊï∞")
        print(f"   ‚úÖ ÊòæËëóÊîπÂñÑ‰∫ÜAudioLDM2ÁöÑÈ´òÈ¢ëÈáçÂª∫ÊÄßËÉΩ")
        print(f"   ‚úÖ Êèê‰æõ‰∫ÜÂÆûÁî®ÁöÑÂèÇÊï∞ÈÄâÊã©ÊåáÂØº")

def demo_final_optimization():
    """ÊºîÁ§∫ÊúÄÁªàÂèÇÊï∞‰ºòÂåñ"""
    print("üéØ AudioLDM2 VAEÂ¢ûÂº∫ - ÊúÄÁªàÂèÇÊï∞‰ºòÂåñ")
    print("=" * 60)
    
    # Ê£ÄÊü•ËæìÂÖ•Êñá‰ª∂
    input_file = "AudioLDM2_Music_output.wav"
    if not Path(input_file).exists():
        print(f"‚ùå Êâæ‰∏çÂà∞ËæìÂÖ•Êñá‰ª∂: {input_file}")
        print("ËØ∑Á°Æ‰øùAudioLDM2_Music_output.wavÂú®ÂΩìÂâçÁõÆÂΩï‰∏≠")
        return
    
    # ÂàùÂßãÂåñÊúÄÁªà‰ºòÂåñÂô®
    optimizer = FinalParameterOptimizer()
    
    # ÊâßË°åÊúÄÁªàÂèÇÊï∞ÊµãËØï
    result = optimizer.test_boost_factors(input_file)
    
    print(f"\n‚úÖ AudioLDM2 VAEÂ¢ûÂº∫È°πÁõÆÂÆåÊàêÔºÅ")
    print(f"üìä Êü•ÁúãËæìÂá∫ÁõÆÂΩï: final_parameter_optimization/")
    print(f"üéµ ËØïÂê¨ÊúÄ‰ºòÈÖçÁΩÆÁöÑÈü≥È¢ëÊïàÊûú")
    print(f"üìÑ Êü•ÁúãÂÆåÊï¥ÁöÑÂàÜÊûêÊä•Âëä")
    
    print(f"\nüöÄ È°πÁõÆÊàêÂ∞±:")
    print(f"   üìà ÂÆåÊàê‰∫Ü‰ªéÈóÆÈ¢òËØÜÂà´Âà∞Ëß£ÂÜ≥ÊñπÊ°àÁöÑÂÆåÊï¥ÊµÅÁ®ã")
    print(f"   üî¨ Âª∫Á´ã‰∫ÜÁ≥ªÁªüÊÄßÁöÑÂèÇÊï∞‰ºòÂåñÊñπÊ≥ï")
    print(f"   üéµ ÊòæËëóÊîπÂñÑ‰∫ÜÈü≥È¢ëÈáçÂª∫ÁöÑÈ´òÈ¢ëÊÄßËÉΩ")
    print(f"   üìö Êèê‰æõ‰∫ÜÂÆåÊï¥ÁöÑÊäÄÊúØÊñáÊ°£Âíå‰ª£Á†Å")

if __name__ == "__main__":
    demo_final_optimization()
