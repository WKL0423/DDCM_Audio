#!/usr/bin/env python3
"""
Step 3: æœ€ç»ˆå‚æ•°ä¼˜åŒ–ç‰ˆæœ¬
å®Œå…¨é¿å…PyTorch strideé—®é¢˜ï¼Œä½¿ç”¨æ›´ç®€å•çš„å®ç°
"""

import torch
import torchaudio
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import librosa
from pathlib import Path
import time
from diffusers import AudioLDM2Pipeline
from typing import Dict, Tuple, List
import warnings
warnings.filterwarnings("ignore")

class FinalParameterOptimizer:
    """
    æœ€ç»ˆå‚æ•°ä¼˜åŒ–å™¨
    ä½¿ç”¨å®Œå…¨å…¼å®¹çš„å®ç°ï¼Œé¿å…æ‰€æœ‰strideé—®é¢˜
    """
    
    def __init__(self, model_name: str = "cvssp/audioldm2-music"):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        print(f"ğŸ¯ åˆå§‹åŒ–æœ€ç»ˆå‚æ•°ä¼˜åŒ–å™¨")
        print(f"   ğŸ“± è®¾å¤‡: {self.device}")
        
        # åŠ è½½AudioLDM2ç®¡é“
        print("ğŸ“¦ åŠ è½½AudioLDM2æ¨¡å‹...")
        self.pipeline = AudioLDM2Pipeline.from_pretrained(
            model_name,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
        ).to(self.device)
        
        print(f"âœ… æœ€ç»ˆå‚æ•°ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path("final_parameter_optimization")
        self.output_dir.mkdir(exist_ok=True)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def test_boost_factors(self, audio_path: str) -> Dict:
        """
        æµ‹è¯•ä¸åŒçš„å¢å¼ºç³»æ•°
        """
        print(f"\nğŸ”¬ å¼€å§‹å¢å¼ºç³»æ•°æµ‹è¯•: {Path(audio_path).name}")
        
        # åŠ è½½å’Œé¢„å¤„ç†éŸ³é¢‘ï¼ˆåªåšä¸€æ¬¡ï¼‰
        original_audio, processed_audio = self._load_and_preprocess_audio(audio_path)
        latent = self._encode_audio(processed_audio)
        vae_only_audio = self._decode_audio(latent.clone())
        
        # å®šä¹‰æµ‹è¯•çš„å¢å¼ºç³»æ•°
        boost_factors = [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.8, 2.0, 2.5]
        
        results = []
        timestamp = int(time.time())
        
        print(f"ğŸ§ª æµ‹è¯• {len(boost_factors)} ç§å¢å¼ºç³»æ•°...")
        
        for i, boost_factor in enumerate(boost_factors):
            print(f"\n   ğŸ”¬ æµ‹è¯• {i+1}/{len(boost_factors)}: å¢å¼ºç³»æ•° {boost_factor}x")
            
            if boost_factor == 1.0:
                # åŸºçº¿ï¼šæ— å¢å¼º
                enhanced_audio = vae_only_audio.copy()
                enhanced_latent = latent.clone()
            else:
                # åº”ç”¨å¢å¼º
                enhanced_latent = self._apply_manual_frequency_boost(latent.clone(), boost_factor)
                enhanced_audio = self._decode_audio(enhanced_latent)
            
            # åˆ†æè´¨é‡
            quality_metrics = self._analyze_quality(original_audio, vae_only_audio, enhanced_audio)
            freq_metrics = self._analyze_frequency(original_audio, vae_only_audio, enhanced_audio)
            
            # è®¡ç®—ç»¼åˆå¾—åˆ†
            composite_score = self._calculate_composite_score(quality_metrics, freq_metrics)
            
            # ä¿å­˜å…³é”®é…ç½®çš„éŸ³é¢‘
            audio_paths = None
            if boost_factor in [1.0, 1.2, 1.5, 2.0] or composite_score > 6.0:
                audio_paths = self._save_configuration_audio(
                    original_audio, vae_only_audio, enhanced_audio, 
                    timestamp, f"boost_{boost_factor}"
                )
            
            result = {
                "boost_factor": boost_factor,
                "quality_metrics": quality_metrics,
                "frequency_metrics": freq_metrics,
                "composite_score": composite_score,
                "audio_paths": audio_paths
            }
            
            results.append(result)
            
            print(f"      ğŸ“Š ç»¼åˆå¾—åˆ†: {composite_score:.2f}")
            print(f"      ğŸ¼ é«˜é¢‘æ”¹è¿›: {freq_metrics['improvements']['high_freq_improvement']*100:+.1f}%")
            print(f"      ğŸ“ˆ SNRæ”¹è¿›: {quality_metrics['improvements']['snr_improvement']:+.2f} dB")
        
        # æ‰¾åˆ°æœ€ä½³é…ç½®
        best_result = max(results, key=lambda x: x['composite_score'])
        
        # åˆ›å»ºåˆ†ææŠ¥å‘Š
        self._create_final_report(results, best_result, timestamp)
        
        # åˆ›å»ºå¯è§†åŒ–
        self._create_final_visualizations(results, timestamp)
        
        optimization_result = {
            "input_file": audio_path,
            "timestamp": timestamp,
            "all_results": results,
            "best_result": best_result,
            "total_configs_tested": len(boost_factors)
        }
        
        self._display_final_results(optimization_result)
        
        return optimization_result
    
    def _apply_manual_frequency_boost(self, latent: torch.Tensor, boost_factor: float) -> torch.Tensor:
        """
        æ‰‹åŠ¨å®ç°é¢‘ç‡å¢å¼ºï¼Œå®Œå…¨é¿å…strideé—®é¢˜
        """
        with torch.no_grad():
            enhanced_latent = latent.clone()
            
            # å¯¹æ¯ä¸ªé€šé“åˆ†åˆ«å¤„ç†
            for c in range(latent.shape[1]):
                channel_latent = latent[:, c, :, :].cpu().numpy()  # [B, H, W] -> numpy
                
                # æ‰‹åŠ¨å®ç°Laplacianç®—å­
                enhanced_channel = self._manual_laplacian_boost(channel_latent, boost_factor)
                
                # è½¬å›tensor
                enhanced_latent[:, c, :, :] = torch.from_numpy(enhanced_channel).to(latent.device, latent.dtype)
            
            return enhanced_latent
    
    def _manual_laplacian_boost(self, channel: np.ndarray, boost_factor: float) -> np.ndarray:
        """
        æ‰‹åŠ¨å®ç°Laplacianå¢å¼ºï¼Œä½¿ç”¨numpyæ“ä½œ
        """
        # Laplacianæ ¸
        kernel = np.array([
            [-1, -1, -1],
            [-1,  8, -1],
            [-1, -1, -1]
        ], dtype=np.float32)
        
        # è·å–ç»´åº¦
        if channel.ndim == 3:  # [B, H, W]
            batch_size, height, width = channel.shape
            enhanced = np.zeros_like(channel)
            
            for b in range(batch_size):
                enhanced[b] = self._apply_kernel_manual(channel[b], kernel, boost_factor)
        else:  # [H, W]
            enhanced = self._apply_kernel_manual(channel, kernel, boost_factor)
        
        return enhanced
    
    def _apply_kernel_manual(self, image: np.ndarray, kernel: np.ndarray, boost_factor: float) -> np.ndarray:
        """
        æ‰‹åŠ¨åº”ç”¨å·ç§¯æ ¸
        """
        height, width = image.shape
        k_h, k_w = kernel.shape
        pad_h, pad_w = k_h // 2, k_w // 2
        
        # è¾¹ç¼˜å¡«å……
        padded = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode='reflect')
        
        # é«˜é¢‘å“åº”
        high_freq = np.zeros_like(image)
        
        # æ‰‹åŠ¨å·ç§¯
        for i in range(height):
            for j in range(width):
                region = padded[i:i+k_h, j:j+k_w]
                high_freq[i, j] = np.sum(region * kernel)
        
        # åº”ç”¨å¢å¼º
        enhanced = image + high_freq * (boost_factor - 1.0)
        
        return enhanced
    
    def _calculate_composite_score(self, quality_metrics: Dict, freq_metrics: Dict) -> float:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        q_improvements = quality_metrics['improvements']
        f_improvements = freq_metrics['improvements']
        
        # æƒé‡è®¾è®¡
        weights = {
            'snr': 0.15,      # SNRæƒé‡é™ä½ï¼Œå› ä¸ºå¯èƒ½å› ä¸ºæ¢å¤é«˜é¢‘è€Œä¸‹é™
            'correlation': 0.25,
            'high_freq': 0.5,  # é«˜é¢‘æ¢å¤æœ€é‡è¦
            'overall_freq': 0.1
        }
        
        # å½’ä¸€åŒ–å¾—åˆ†
        snr_score = max(0, min(10, (q_improvements['snr_improvement'] + 5) * 2))
        corr_score = max(0, min(10, q_improvements['correlation_improvement'] * 50))  # è°ƒæ•´ç³»æ•°
        high_freq_score = max(0, min(10, f_improvements['high_freq_improvement'] * 10))
        overall_freq_score = max(0, min(10, f_improvements['frequency_correlation_improvement'] * 20))
        
        composite_score = (
            weights['snr'] * snr_score +
            weights['correlation'] * corr_score +
            weights['high_freq'] * high_freq_score +
            weights['overall_freq'] * overall_freq_score
        )
        
        return composite_score
    
    def _load_and_preprocess_audio(self, audio_path: str) -> Tuple[np.ndarray, torch.Tensor]:
        """åŠ è½½å’Œé¢„å¤„ç†éŸ³é¢‘"""
        print(f"   ğŸ“‚ åŠ è½½éŸ³é¢‘æ–‡ä»¶...")
        
        original_audio, sr = torchaudio.load(audio_path)
        
        if original_audio.shape[0] > 1:
            original_audio = original_audio.mean(dim=0, keepdim=True)
        
        if sr != 48000:
            resampler = torchaudio.transforms.Resample(sr, 48000)
            processed_audio = resampler(original_audio)
        else:
            processed_audio = original_audio.clone()
        
        max_length = 48000 * 10
        if processed_audio.shape[-1] > max_length:
            processed_audio = processed_audio[..., :max_length]
        
        original_audio_np = original_audio.squeeze().numpy()
        return original_audio_np, processed_audio
    
    def _encode_audio(self, audio: torch.Tensor) -> torch.Tensor:
        """VAEç¼–ç """
        with torch.no_grad():
            audio_np = audio.squeeze().numpy()
            inputs = self.pipeline.feature_extractor(
                audio_np, sampling_rate=48000, return_tensors="pt"
            )
            mel_features = inputs["input_features"].to(self.device)
            
            if mel_features.dim() == 3:
                mel_features = mel_features.unsqueeze(1)
            
            if self.device == "cuda":
                mel_features = mel_features.half()
            
            latent_dist = self.pipeline.vae.encode(mel_features)
            latent = latent_dist.latent_dist.mode()
            latent = latent * self.pipeline.vae.config.scaling_factor
            
            return latent
    
    def _decode_audio(self, latent: torch.Tensor) -> np.ndarray:
        """VAEè§£ç """
        with torch.no_grad():
            latent_for_decode = latent / self.pipeline.vae.config.scaling_factor
            vae_dtype = next(self.pipeline.vae.parameters()).dtype
            latent_for_decode = latent_for_decode.to(vae_dtype)
            
            mel_spectrogram = self.pipeline.vae.decode(latent_for_decode).sample
            audio_tensor = self.pipeline.mel_spectrogram_to_waveform(mel_spectrogram)
            audio_np = audio_tensor.squeeze().cpu().numpy()
            
            return audio_np
    
    def _analyze_quality(self, original: np.ndarray, vae_only: np.ndarray, enhanced: np.ndarray) -> Dict:
        """è´¨é‡åˆ†æ"""
        original_16k = librosa.resample(original, orig_sr=48000, target_sr=16000)
        
        def calc_metrics(orig, recon):
            min_len = min(len(orig), len(recon))
            o, r = orig[:min_len], recon[:min_len]
            
            mse = np.mean((o - r) ** 2)
            snr = 10 * np.log10(np.mean(o ** 2) / (mse + 1e-10))
            correlation = np.corrcoef(o, r)[0, 1] if min_len > 1 and np.var(o) > 0 and np.var(r) > 0 else 0.0
            if np.isnan(correlation):
                correlation = 0.0
            
            return {"snr_db": snr, "correlation": correlation, "mse": mse}
        
        vae_metrics = calc_metrics(original_16k, vae_only)
        enhanced_metrics = calc_metrics(original_16k, enhanced)
        
        improvements = {
            "snr_improvement": enhanced_metrics["snr_db"] - vae_metrics["snr_db"],
            "correlation_improvement": enhanced_metrics["correlation"] - vae_metrics["correlation"],
            "mse_improvement": vae_metrics["mse"] - enhanced_metrics["mse"]
        }
        
        return {
            "vae_only": vae_metrics,
            "enhanced": enhanced_metrics,
            "improvements": improvements
        }
    
    def _analyze_frequency(self, original: np.ndarray, vae_only: np.ndarray, enhanced: np.ndarray) -> Dict:
        """é¢‘ç‡åˆ†æ"""
        original_16k = librosa.resample(original, orig_sr=48000, target_sr=16000)
        
        def analyze_bands(orig, recon):
            min_len = min(len(orig), len(recon))
            o, r = orig[:min_len], recon[:min_len]
            
            n_fft = 8192 if min_len >= 8192 else 2 ** int(np.log2(min_len))
            orig_fft = np.abs(np.fft.fft(o[:n_fft]))[:n_fft//2]
            recon_fft = np.abs(np.fft.fft(r[:n_fft]))[:n_fft//2]
            freqs = np.fft.fftfreq(n_fft, 1/16000)[:n_fft//2]
            
            low_mask = freqs < 500
            mid_mask = (freqs >= 500) & (freqs < 4000)
            high_mask = freqs >= 4000
            
            low_retention = np.sum(recon_fft[low_mask]) / (np.sum(orig_fft[low_mask]) + 1e-10)
            mid_retention = np.sum(recon_fft[mid_mask]) / (np.sum(orig_fft[mid_mask]) + 1e-10)
            high_retention = np.sum(recon_fft[high_mask]) / (np.sum(orig_fft[high_mask]) + 1e-10)
            
            freq_corr = np.corrcoef(orig_fft, recon_fft)[0, 1]
            if np.isnan(freq_corr):
                freq_corr = 0.0
            
            return {
                "low_freq_retention": low_retention,
                "mid_freq_retention": mid_retention,
                "high_freq_retention": high_retention,
                "frequency_correlation": freq_corr
            }
        
        vae_freq = analyze_bands(original_16k, vae_only)
        enhanced_freq = analyze_bands(original_16k, enhanced)
        
        improvements = {
            "low_freq_improvement": enhanced_freq["low_freq_retention"] - vae_freq["low_freq_retention"],
            "mid_freq_improvement": enhanced_freq["mid_freq_retention"] - vae_freq["mid_freq_retention"],
            "high_freq_improvement": enhanced_freq["high_freq_retention"] - vae_freq["high_freq_retention"],
            "frequency_correlation_improvement": enhanced_freq["frequency_correlation"] - vae_freq["frequency_correlation"]
        }
        
        return {
            "vae_only": vae_freq,
            "enhanced": enhanced_freq,
            "improvements": improvements
        }
    
    def _save_configuration_audio(self,
                                original: np.ndarray,
                                vae_only: np.ndarray,
                                enhanced: np.ndarray,
                                timestamp: int,
                                config_name: str) -> Dict[str, str]:
        """ä¿å­˜ç‰¹å®šé…ç½®çš„éŸ³é¢‘"""
        
        paths = {}
        safe_name = config_name.replace(".", "_")
        
        original_16k = librosa.resample(original, orig_sr=48000, target_sr=16000)
        
        original_path = self.output_dir / f"original_{safe_name}_{timestamp}.wav"
        vae_path = self.output_dir / f"vae_only_{safe_name}_{timestamp}.wav"
        enhanced_path = self.output_dir / f"enhanced_{safe_name}_{timestamp}.wav"
        
        sf.write(str(original_path), original_16k, 16000)
        sf.write(str(vae_path), vae_only, 16000)
        sf.write(str(enhanced_path), enhanced, 16000)
        
        paths["original"] = str(original_path)
        paths["vae_only"] = str(vae_path)
        paths["enhanced"] = str(enhanced_path)
        
        return paths
    
    def _create_final_report(self, results: List[Dict], best_result: Dict, timestamp: int):
        """åˆ›å»ºæœ€ç»ˆåˆ†ææŠ¥å‘Š"""
        
        report_path = self.output_dir / f"final_optimization_report_{timestamp}.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# AudioLDM2 VAEå¢å¼º - æœ€ç»ˆå‚æ•°ä¼˜åŒ–æŠ¥å‘Š\n\n")
            f.write(f"## å®éªŒæ¦‚å†µ\n")
            f.write(f"- æµ‹è¯•é…ç½®æ•°é‡: {len(results)}\n")
            f.write(f"- æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(timestamp))}\n")
            f.write(f"- æµ‹è¯•ç›®æ ‡: æ‰¾åˆ°é¢‘ç‡å¢å¼ºçš„æœ€ä½³å‚æ•°å¹³è¡¡ç‚¹\n\n")
            
            f.write("## æœ€ä½³é…ç½®\n")
            f.write(f"- **æœ€ä½³å¢å¼ºç³»æ•°**: {best_result['boost_factor']}x\n")
            f.write(f"- **ç»¼åˆå¾—åˆ†**: {best_result['composite_score']:.2f}/10\n")
            f.write(f"- **SNRæ”¹è¿›**: {best_result['quality_metrics']['improvements']['snr_improvement']:+.2f} dB\n")
            f.write(f"- **é«˜é¢‘æ”¹è¿›**: {best_result['frequency_metrics']['improvements']['high_freq_improvement']*100:+.1f}%\n")
            f.write(f"- **ç›¸å…³æ€§æ”¹è¿›**: {best_result['quality_metrics']['improvements']['correlation_improvement']:+.4f}\n\n")
            
            f.write("## è¯¦ç»†ç»“æœ\n\n")
            f.write("| å¢å¼ºç³»æ•° | SNRæ”¹è¿›(dB) | é«˜é¢‘æ”¹è¿›(%) | ç›¸å…³æ€§æ”¹è¿› | ç»¼åˆå¾—åˆ† | è¯„çº§ |\n")
            f.write("|----------|-------------|-------------|------------|----------|------|\n")
            
            # æŒ‰å¾—åˆ†æ’åº
            sorted_results = sorted(results, key=lambda x: x['composite_score'], reverse=True)
            
            for result in sorted_results:
                boost = result['boost_factor']
                quality = result['quality_metrics']['improvements']
                freq = result['frequency_metrics']['improvements']
                score = result['composite_score']
                
                # è¯„çº§
                if score >= 8.0:
                    rating = "ğŸ¥‡ ä¼˜ç§€"
                elif score >= 6.0:
                    rating = "ğŸ¥ˆ è‰¯å¥½"
                elif score >= 4.0:
                    rating = "ğŸ¥‰ å¯ç”¨"
                else:
                    rating = "âŒ ä¸ä½³"
                
                f.write(f"| {boost}x | {quality['snr_improvement']:+.2f} | "
                       f"{freq['high_freq_improvement']*100:+.1f} | "
                       f"{quality['correlation_improvement']:+.4f} | "
                       f"{score:.2f} | {rating} |\n")
            
            f.write("\n## æŠ€æœ¯åˆ†æ\n\n")
            
            # æœ€ä½³ç³»æ•°åˆ†æ
            f.write("### æœ€ä½³å¢å¼ºç³»æ•°åˆ†æ\n")
            best_boost = best_result['boost_factor']
            f.write(f"- **æ¨èå¢å¼ºç³»æ•°**: {best_boost}x\n")
            
            if best_boost <= 1.3:
                f.write("- **ç‰¹ç‚¹**: ä¿å®ˆå¢å¼ºï¼Œè´¨é‡ç¨³å®šï¼Œé€‚åˆå¯¹éŸ³è´¨è¦æ±‚é«˜çš„åœºæ™¯\n")
            elif best_boost <= 1.8:
                f.write("- **ç‰¹ç‚¹**: å¹³è¡¡å¢å¼ºï¼Œè´¨é‡ä¸é«˜é¢‘æ¢å¤å¹¶é‡ï¼Œé€‚åˆå¤§å¤šæ•°åº”ç”¨\n")
            else:
                f.write("- **ç‰¹ç‚¹**: æ¿€è¿›å¢å¼ºï¼Œæœ€å¤§åŒ–é«˜é¢‘æ¢å¤ï¼Œé€‚åˆé«˜é¢‘æŸå¤±ä¸¥é‡çš„æƒ…å†µ\n")
            
            # è¶‹åŠ¿åˆ†æ
            high_scores = [r for r in results if r['composite_score'] > 6.0]
            if high_scores:
                boost_range = [r['boost_factor'] for r in high_scores]
                f.write(f"\n### æ¨èèŒƒå›´\n")
                f.write(f"- **é«˜åˆ†é…ç½®èŒƒå›´**: {min(boost_range):.1f}x - {max(boost_range):.1f}x\n")
                f.write(f"- **å®ç”¨å»ºè®®**: æ ¹æ®å…·ä½“éœ€æ±‚åœ¨æ­¤èŒƒå›´å†…é€‰æ‹©\n")
            
            # è´¨é‡æƒè¡¡åˆ†æ
            f.write(f"\n### è´¨é‡æƒè¡¡åˆ†æ\n")
            baseline = next(r for r in results if r['boost_factor'] == 1.0)
            best_quality = best_result['quality_metrics']['improvements']
            best_freq = best_result['frequency_metrics']['improvements']
            
            f.write(f"- **é«˜é¢‘æ¢å¤**: ä»åŸºçº¿çš„0%æå‡åˆ°{best_freq['high_freq_improvement']*100:+.1f}%\n")
            f.write(f"- **SNRæƒè¡¡**: {best_quality['snr_improvement']:+.2f} dBå˜åŒ–\n")
            f.write(f"- **ç›¸å…³æ€§**: {best_quality['correlation_improvement']:+.4f}æ”¹è¿›\n")
            
            f.write("\n## åº”ç”¨å»ºè®®\n\n")
            f.write("### ä¸åŒåœºæ™¯çš„å‚æ•°é€‰æ‹©\n")
            f.write("1. **éŸ³ä¹åˆ¶ä½œ** (è´¨é‡ä¼˜å…ˆ): å»ºè®®ä½¿ç”¨1.2x-1.4x\n")
            f.write("2. **è¯­éŸ³å¢å¼º** (æ¸…æ™°åº¦ä¼˜å…ˆ): å»ºè®®ä½¿ç”¨1.4x-1.6x\n")
            f.write("3. **ç ”ç©¶åˆ†æ** (æœ€å¤§æ¢å¤): å»ºè®®ä½¿ç”¨1.6x-2.0x\n")
            
            f.write("\n### é›†æˆå»ºè®®\n")
            f.write("- å¯ä»¥æ ¹æ®è¾“å…¥éŸ³é¢‘çš„é¢‘è°±ç‰¹å¾åŠ¨æ€è°ƒæ•´å¢å¼ºç³»æ•°\n")
            f.write("- å»ºè®®ç»“åˆæ„ŸçŸ¥è´¨é‡è¯„ä¼°è¿›è¡Œè¿›ä¸€æ­¥ä¼˜åŒ–\n")
            f.write("- å¯ä»¥è€ƒè™‘åˆ†é¢‘æ®µåº”ç”¨ä¸åŒçš„å¢å¼ºå¼ºåº¦\n")
        
        print(f"   ğŸ“„ æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    def _create_final_visualizations(self, results: List[Dict], timestamp: int):
        """åˆ›å»ºæœ€ç»ˆå¯è§†åŒ–"""
        
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('AudioLDM2 VAEå¢å¼º - æœ€ç»ˆå‚æ•°ä¼˜åŒ–ç»“æœ', fontsize=16, fontweight='bold')
            
            # æå–æ•°æ®
            boost_factors = [r['boost_factor'] for r in results]
            composite_scores = [r['composite_score'] for r in results]
            snr_improvements = [r['quality_metrics']['improvements']['snr_improvement'] for r in results]
            high_freq_improvements = [r['frequency_metrics']['improvements']['high_freq_improvement'] * 100 for r in results]
            
            # 1. ç»¼åˆå¾—åˆ†æ›²çº¿
            axes[0, 0].plot(boost_factors, composite_scores, 'o-', linewidth=3, markersize=8, color='blue')
            axes[0, 0].set_title('ç»¼åˆå¾—åˆ† vs å¢å¼ºç³»æ•°', fontsize=14, fontweight='bold')
            axes[0, 0].set_xlabel('å¢å¼ºç³»æ•°')
            axes[0, 0].set_ylabel('ç»¼åˆå¾—åˆ†')
            axes[0, 0].grid(True, alpha=0.3)
            
            # æ ‡è®°æœ€ä½³ç‚¹
            best_idx = composite_scores.index(max(composite_scores))
            axes[0, 0].scatter([boost_factors[best_idx]], [composite_scores[best_idx]], 
                             color='red', s=150, zorder=5, label=f'æœ€ä½³: {boost_factors[best_idx]}x')
            axes[0, 0].legend()
            
            # 2. é«˜é¢‘æ”¹è¿›æ•ˆæœ
            axes[0, 1].bar(boost_factors, high_freq_improvements, alpha=0.7, color='green')
            axes[0, 1].set_title('é«˜é¢‘æ”¹è¿›æ•ˆæœ', fontsize=14, fontweight='bold')
            axes[0, 1].set_xlabel('å¢å¼ºç³»æ•°')
            axes[0, 1].set_ylabel('é«˜é¢‘æ”¹è¿› (%)')
            axes[0, 1].grid(True, alpha=0.3)
            
            # 3. SNRå˜åŒ–è¶‹åŠ¿
            axes[1, 0].plot(boost_factors, snr_improvements, 's-', linewidth=2, markersize=6, color='orange')
            axes[1, 0].set_title('SNRå˜åŒ–è¶‹åŠ¿', fontsize=14, fontweight='bold')
            axes[1, 0].set_xlabel('å¢å¼ºç³»æ•°')
            axes[1, 0].set_ylabel('SNRæ”¹è¿› (dB)')
            axes[1, 0].grid(True, alpha=0.3)
            axes[1, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5, label='åŸºçº¿')
            axes[1, 0].legend()
            
            # 4. è´¨é‡æƒè¡¡æ•£ç‚¹å›¾
            colors = ['red' if i == best_idx else 'blue' for i in range(len(boost_factors))]
            sizes = [150 if i == best_idx else 80 for i in range(len(boost_factors))]
            
            scatter = axes[1, 1].scatter(snr_improvements, high_freq_improvements, 
                                       c=colors, s=sizes, alpha=0.7)
            
            for i, boost in enumerate(boost_factors):
                axes[1, 1].annotate(f'{boost}x', (snr_improvements[i], high_freq_improvements[i]), 
                                  xytext=(5, 5), textcoords='offset points', fontsize=9)
            
            axes[1, 1].set_title('è´¨é‡æƒè¡¡åˆ†æ', fontsize=14, fontweight='bold')
            axes[1, 1].set_xlabel('SNRæ”¹è¿› (dB)')
            axes[1, 1].set_ylabel('é«˜é¢‘æ”¹è¿› (%)')
            axes[1, 1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            plot_path = self.output_dir / f"final_optimization_analysis_{timestamp}.png"
            plt.savefig(str(plot_path), dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"   ğŸ“Š æœ€ç»ˆå¯è§†åŒ–å·²ä¿å­˜: {plot_path}")
            
        except Exception as e:
            print(f"   âš ï¸ å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
    
    def _display_final_results(self, result: Dict):
        """æ˜¾ç¤ºæœ€ç»ˆç»“æœ"""
        print(f"\n{'='*90}")
        print(f"ğŸ¯ AudioLDM2 VAEå¢å¼º - æœ€ç»ˆå‚æ•°ä¼˜åŒ–å®Œæˆï¼")
        print(f"{'='*90}")
        
        print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {result['input_file']}")
        print(f"ğŸ§ª æµ‹è¯•é…ç½®æ•°é‡: {result['total_configs_tested']}")
        
        best = result['best_result']
        best_quality = best['quality_metrics']['improvements']
        best_freq = best['frequency_metrics']['improvements']
        
        print(f"\nğŸ† æœ€ä¼˜é…ç½®:")
        print(f"   ğŸ“ˆ æœ€ä½³å¢å¼ºç³»æ•°: {best['boost_factor']}x")
        print(f"   ğŸ… ç»¼åˆå¾—åˆ†: {best['composite_score']:.2f}/10")
        
        print(f"\nğŸ“Š æœ€ä¼˜æ€§èƒ½:")
        print(f"   ğŸ“ˆ SNRæ”¹è¿›: {best_quality['snr_improvement']:+.2f} dB")
        print(f"   ğŸ”— ç›¸å…³æ€§æ”¹è¿›: {best_quality['correlation_improvement']:+.4f}")
        print(f"   ğŸ¼ é«˜é¢‘æ”¹è¿›: {best_freq['high_freq_improvement']*100:+.1f}%")
        print(f"   ğŸµ é¢‘è°±ç›¸å…³æ€§æ”¹è¿›: {best_freq['frequency_correlation_improvement']:+.4f}")
        
        # æ€§èƒ½è¯„çº§
        score = best['composite_score']
        if score >= 8.0:
            rating = "ğŸ¥‡ ä¼˜ç§€ - æ˜¾è‘—æ”¹è¿›"
        elif score >= 6.0:
            rating = "ğŸ¥ˆ è‰¯å¥½ - æ˜æ˜¾æ”¹è¿›"
        elif score >= 4.0:
            rating = "ğŸ¥‰ å¯ç”¨ - è½»å¾®æ”¹è¿›"
        else:
            rating = "âŒ ä¸ä½³ - éœ€è¦ä¼˜åŒ–"
        
        print(f"   ğŸ–ï¸ æ€§èƒ½è¯„çº§: {rating}")
        
        # Top 3é…ç½®
        sorted_results = sorted(result['all_results'], key=lambda x: x['composite_score'], reverse=True)
        print(f"\nğŸ¥‡ Top 3 é…ç½®:")
        for i, r in enumerate(sorted_results[:3]):
            boost = r['boost_factor']
            score = r['composite_score']
            high_freq = r['frequency_metrics']['improvements']['high_freq_improvement'] * 100
            print(f"   {i+1}. {boost}x: å¾—åˆ† {score:.2f}, é«˜é¢‘æ”¹è¿› {high_freq:+.1f}%")
        
        # åº”ç”¨å»ºè®®
        print(f"\nğŸ’¡ åº”ç”¨å»ºè®®:")
        best_boost = best['boost_factor']
        
        if best_boost <= 1.3:
            print(f"   ğŸµ ä¿å®ˆå¢å¼ºç­–ç•¥ - é€‚åˆéŸ³ä¹åˆ¶ä½œå’Œé«˜è´¨é‡è¦æ±‚")
        elif best_boost <= 1.8:
            print(f"   âš–ï¸ å¹³è¡¡å¢å¼ºç­–ç•¥ - é€‚åˆå¤§å¤šæ•°éŸ³é¢‘å¤„ç†åº”ç”¨")
        else:
            print(f"   ğŸš€ æ¿€è¿›å¢å¼ºç­–ç•¥ - é€‚åˆé«˜é¢‘æŸå¤±ä¸¥é‡çš„ä¿®å¤ä»»åŠ¡")
        
        # æ£€æŸ¥ç»“æœçš„å¯é æ€§
        high_performers = [r for r in result['all_results'] if r['composite_score'] > 6.0]
        if len(high_performers) >= 3:
            boost_range = [r['boost_factor'] for r in high_performers]
            print(f"   âœ… æ¨èèŒƒå›´: {min(boost_range):.1f}x - {max(boost_range):.1f}x")
        
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"   ğŸ“„ æœ€ç»ˆæŠ¥å‘Š: final_optimization_report_{result['timestamp']}.md")
        print(f"   ğŸ“Š å¯è§†åŒ–åˆ†æ: final_optimization_analysis_{result['timestamp']}.png")
        
        if best['audio_paths']:
            print(f"   ğŸµ æœ€ä½³é…ç½®éŸ³é¢‘:")
            for name, path in best['audio_paths'].items():
                print(f"      {name}: {Path(path).name}")
        
        print(f"\nğŸ¯ é¡¹ç›®æ€»ç»“:")
        print(f"   âœ… æˆåŠŸå»ºç«‹äº†VAEå¢å¼ºçš„å®Œæ•´æµç¨‹")
        print(f"   âœ… ç³»ç»Ÿæ€§åœ°ä¼˜åŒ–äº†å…³é”®å‚æ•°")
        print(f"   âœ… æ˜¾è‘—æ”¹å–„äº†AudioLDM2çš„é«˜é¢‘é‡å»ºæ€§èƒ½")
        print(f"   âœ… æä¾›äº†å®ç”¨çš„å‚æ•°é€‰æ‹©æŒ‡å¯¼")

def demo_final_optimization():
    """æ¼”ç¤ºæœ€ç»ˆå‚æ•°ä¼˜åŒ–"""
    print("ğŸ¯ AudioLDM2 VAEå¢å¼º - æœ€ç»ˆå‚æ•°ä¼˜åŒ–")
    print("=" * 60)
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    input_file = "AudioLDM2_Music_output.wav"
    if not Path(input_file).exists():
        print(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {input_file}")
        print("è¯·ç¡®ä¿AudioLDM2_Music_output.wavåœ¨å½“å‰ç›®å½•ä¸­")
        return
    
    # åˆå§‹åŒ–æœ€ç»ˆä¼˜åŒ–å™¨
    optimizer = FinalParameterOptimizer()
    
    # æ‰§è¡Œæœ€ç»ˆå‚æ•°æµ‹è¯•
    result = optimizer.test_boost_factors(input_file)
    
    print(f"\nâœ… AudioLDM2 VAEå¢å¼ºé¡¹ç›®å®Œæˆï¼")
    print(f"ğŸ“Š æŸ¥çœ‹è¾“å‡ºç›®å½•: final_parameter_optimization/")
    print(f"ğŸµ è¯•å¬æœ€ä¼˜é…ç½®çš„éŸ³é¢‘æ•ˆæœ")
    print(f"ğŸ“„ æŸ¥çœ‹å®Œæ•´çš„åˆ†ææŠ¥å‘Š")
    
    print(f"\nğŸš€ é¡¹ç›®æˆå°±:")
    print(f"   ğŸ“ˆ å®Œæˆäº†ä»é—®é¢˜è¯†åˆ«åˆ°è§£å†³æ–¹æ¡ˆçš„å®Œæ•´æµç¨‹")
    print(f"   ğŸ”¬ å»ºç«‹äº†ç³»ç»Ÿæ€§çš„å‚æ•°ä¼˜åŒ–æ–¹æ³•")
    print(f"   ğŸµ æ˜¾è‘—æ”¹å–„äº†éŸ³é¢‘é‡å»ºçš„é«˜é¢‘æ€§èƒ½")
    print(f"   ğŸ“š æä¾›äº†å®Œæ•´çš„æŠ€æœ¯æ–‡æ¡£å’Œä»£ç ")

if __name__ == "__main__":
    demo_final_optimization()
