#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AudioLDM2 VAEå™ªå£°é—®é¢˜æ·±åº¦è¯Šæ–­
==========================

æµ‹è¯•ä¸åŒçš„melé¢‘è°±é¢„å¤„ç†å‚æ•°ï¼Œæ‰¾åˆ°æœ€æ¥è¿‘AudioLDM2è®­ç»ƒæ—¶çš„è®¾ç½®
"""

import torch
import numpy as np
import librosa
import soundfile as sf
from pathlib import Path
from diffusers import AudioLDM2Pipeline
import time
import matplotlib.pyplot as plt


def save_audio_compatible(audio: np.ndarray, filepath: str, sample_rate: int = 16000):
    """å…¼å®¹æ€§éŸ³é¢‘ä¿å­˜"""
    try:
        audio = np.clip(audio, -1.0, 1.0)
        sf.write(filepath, audio, sample_rate, subtype='PCM_16')
        print(f"âœ… ä¿å­˜: {Path(filepath).name}")
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")


def test_mel_preprocessing_variants(audio_path: str, max_length: float = 3.0):
    """
    æµ‹è¯•ä¸åŒçš„melé¢‘è°±é¢„å¤„ç†å‚æ•°
    """
    print(f"\nğŸ”¬ AudioLDM2 Melé¢‘è°±é¢„å¤„ç†å‚æ•°æµ‹è¯•")
    print(f"ğŸ¯ ç›®æ ‡: æ‰¾åˆ°æœ€ä½³çš„melé¢‘è°±é¢„å¤„ç†å‚æ•°")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ“± è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    pipeline = AudioLDM2Pipeline.from_pretrained(
        "cvssp/audioldm2-music",
        torch_dtype=torch.float16 if device == "cuda" else torch.float32
    ).to(device)
    
    vae = pipeline.vae
    vocoder = pipeline.vocoder
    sample_rate = 16000
    
    # åŠ è½½éŸ³é¢‘
    audio, sr = librosa.load(audio_path, sr=sample_rate, duration=max_length)
    print(f"ğŸ“ éŸ³é¢‘: {len(audio)/sr:.2f}ç§’")
    
    # æµ‹è¯•ä¸åŒçš„melé¢‘è°±å‚æ•°ç»„åˆ
    test_configs = [
        {
            'name': 'Current',
            'n_mels': 64,
            'hop_length': 160,
            'n_fft': 1024,
            'win_length': 1024,
            'normalization': 'div_20',
            'db_ref': 'max'
        },
        {
            'name': 'Standard_16k',
            'n_mels': 64,
            'hop_length': 160,
            'n_fft': 1024,
            'win_length': 1024,
            'normalization': 'div_80_plus_1',
            'db_ref': 'max'
        },
        {
            'name': 'TacoCentric',
            'n_mels': 64,
            'hop_length': 160,
            'n_fft': 1024,
            'win_length': 1024,
            'normalization': 'minmax_sym',
            'db_ref': 'max'
        },
        {
            'name': 'AudioLDM_Style',
            'n_mels': 64,
            'hop_length': 160,
            'n_fft': 1024,
            'win_length': 1024,
            'normalization': 'minmax_0_1',
            'db_ref': 'max'
        },
        {
            'name': 'No_Normalization',
            'n_mels': 64,
            'hop_length': 160,
            'n_fft': 1024,
            'win_length': 1024,
            'normalization': 'none',
            'db_ref': 'max'
        }
    ]
    
    results = []
    output_dir = Path("mel_preprocessing_test")
    output_dir.mkdir(exist_ok=True)
    
    print(f"\nğŸ§ª å¼€å§‹æµ‹è¯• {len(test_configs)} ç§é…ç½®...")
    
    for i, config in enumerate(test_configs, 1):
        print(f"\n--- æµ‹è¯• {i}/{len(test_configs)}: {config['name']} ---")
        
        try:
            # åˆ›å»ºmelé¢‘è°±
            mel_spec = librosa.feature.melspectrogram(
                y=audio,
                sr=sample_rate,
                n_mels=config['n_mels'],
                hop_length=config['hop_length'],
                n_fft=config['n_fft'],
                win_length=config['win_length'],
                window='hann',
                center=True,
                pad_mode='reflect'
            )
            
            # è½¬æ¢ä¸ºdB
            if config['db_ref'] == 'max':
                mel_db = librosa.power_to_db(mel_spec, ref=np.max)
            else:
                mel_db = librosa.power_to_db(mel_spec)
            
            print(f"   åŸå§‹melèŒƒå›´: [{mel_db.min():.1f}, {mel_db.max():.1f}] dB")
            
            # åº”ç”¨ä¸åŒçš„å½’ä¸€åŒ–æ–¹æ³•
            if config['normalization'] == 'div_20':
                mel_norm = mel_db / 20.0
                mel_norm = np.clip(mel_norm, -1, 1)
            elif config['normalization'] == 'div_80_plus_1':
                mel_norm = (mel_db + 80) / 80
                mel_norm = mel_norm * 2 - 1  # è½¬æ¢åˆ°[-1, 1]
            elif config['normalization'] == 'minmax_sym':
                mel_min, mel_max = mel_db.min(), mel_db.max()
                mel_norm = 2 * (mel_db - mel_min) / (mel_max - mel_min) - 1
            elif config['normalization'] == 'minmax_0_1':
                mel_min, mel_max = mel_db.min(), mel_db.max()
                mel_norm = (mel_db - mel_min) / (mel_max - mel_min)
            elif config['normalization'] == 'none':
                mel_norm = mel_db
            
            print(f"   å½’ä¸€åŒ–å: [{mel_norm.min():.3f}, {mel_norm.max():.3f}]")
            
            # è½¬æ¢ä¸ºtensor
            mel_tensor = torch.from_numpy(mel_norm).to(device)
            if device == "cuda":
                mel_tensor = mel_tensor.half()
            
            mel_input = mel_tensor.unsqueeze(0).unsqueeze(0)
            
            # VAEå¤„ç†
            with torch.no_grad():
                # ç¼–ç 
                latent_dist = vae.encode(mel_input)
                if hasattr(latent_dist, 'latent_dist'):
                    latent = latent_dist.latent_dist.sample()
                else:
                    latent = latent_dist.sample()
                
                latent = latent * vae.config.scaling_factor
                
                # è§£ç 
                latent_for_decode = latent / vae.config.scaling_factor
                reconstructed_mel = vae.decode(latent_for_decode).sample
            
            # HiFiGANå¤„ç†
            vocoder_input = reconstructed_mel.squeeze(1).transpose(1, 2)
            vocoder_dtype = next(vocoder.parameters()).dtype
            vocoder_input = vocoder_input.to(vocoder_dtype)
            
            waveform = vocoder(vocoder_input)
            reconstructed_audio = waveform.squeeze().detach().cpu().float().numpy()
            
            # è®¡ç®—è´¨é‡æŒ‡æ ‡
            min_len = min(len(audio), len(reconstructed_audio))
            audio_aligned = audio[:min_len]
            recon_aligned = reconstructed_audio[:min_len]
            
            mse = np.mean((audio_aligned - recon_aligned) ** 2)
            correlation = np.corrcoef(audio_aligned, recon_aligned)[0, 1]
            signal_power = np.mean(audio_aligned ** 2)
            noise_power = np.mean((audio_aligned - recon_aligned) ** 2)
            snr = 10 * np.log10(signal_power / (noise_power + 1e-10))
            
            print(f"   ç»“æœ: MSE={mse:.6f}, SNR={snr:.2f}dB, ç›¸å…³æ€§={correlation:.4f}")
            
            # ä¿å­˜ç»“æœ
            timestamp = int(time.time())
            output_path = output_dir / f"{config['name']}_snr{snr:.1f}_{timestamp}.wav"
            save_audio_compatible(reconstructed_audio, str(output_path))
            
            results.append({
                'config': config['name'],
                'mse': mse,
                'snr': snr,
                'correlation': correlation,
                'output_path': output_path
            })
            
        except Exception as e:
            print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
            results.append({
                'config': config['name'],
                'mse': float('inf'),
                'snr': float('-inf'),
                'correlation': 0,
                'output_path': None
            })
    
    # åˆ†æç»“æœ
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"{'é…ç½®':<20} {'SNR(dB)':<10} {'MSE':<12} {'ç›¸å…³æ€§':<10}")
    print("-" * 55)
    
    best_snr = float('-inf')
    best_config = None
    
    for result in results:
        snr_str = f"{result['snr']:.2f}" if result['snr'] != float('-inf') else "FAIL"
        mse_str = f"{result['mse']:.6f}" if result['mse'] != float('inf') else "FAIL"
        corr_str = f"{result['correlation']:.4f}" if result['correlation'] != 0 else "FAIL"
        
        print(f"{result['config']:<20} {snr_str:<10} {mse_str:<12} {corr_str:<10}")
        
        if result['snr'] > best_snr:
            best_snr = result['snr']
            best_config = result
    
    print(f"\nğŸ† æœ€ä½³é…ç½®:")
    print(f"   é…ç½®: {best_config['config']}")
    print(f"   SNR: {best_config['snr']:.2f} dB")
    print(f"   MSE: {best_config['mse']:.6f}")
    print(f"   ç›¸å…³æ€§: {best_config['correlation']:.4f}")
    
    if best_config['output_path']:
        print(f"   è¾“å‡º: {best_config['output_path']}")
    
    # åˆ›å»ºè¯¦ç»†æŠ¥å‘Š
    report = f"""
AudioLDM2 Melé¢‘è°±é¢„å¤„ç†å‚æ•°æµ‹è¯•æŠ¥å‘Š
================================

æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
è¾“å…¥éŸ³é¢‘: {Path(audio_path).name}
éŸ³é¢‘é•¿åº¦: {len(audio)/sr:.2f}ç§’

æµ‹è¯•ç»“æœ:
"""
    
    for result in results:
        report += f"""
{result['config']}:
  SNR: {result['snr']:.2f} dB
  MSE: {result['mse']:.6f}
  ç›¸å…³æ€§: {result['correlation']:.4f}
  è¾“å‡º: {result['output_path']}
"""
    
    report += f"""
æœ€ä½³é…ç½®: {best_config['config']}
æœ€ä½³SNR: {best_config['snr']:.2f} dB

ç»“è®º:
"""
    
    if best_snr > -5:
        report += "- æ‰¾åˆ°äº†ç›¸å¯¹è¾ƒå¥½çš„é¢„å¤„ç†å‚æ•°\n"
    elif best_snr > -10:
        report += "- é¢„å¤„ç†å‚æ•°æœ‰æ‰€æ”¹å–„ï¼Œä½†ä»éœ€ä¼˜åŒ–\n"
    else:
        report += "- é¢„å¤„ç†å‚æ•°æ”¹å–„æœ‰é™ï¼Œå¯èƒ½éœ€è¦æ›´æ·±å±‚çš„ä¿®å¤\n"
    
    report += "- å»ºè®®è¿›ä¸€æ­¥ç ”ç©¶AudioLDM2çš„è®­ç»ƒä»£ç å’Œè®ºæ–‡\n"
    report += "- è€ƒè™‘ä½¿ç”¨AudioLDM2çš„å†…ç½®é¢„å¤„ç†æ–¹æ³•\n"
    
    report_path = output_dir / f"mel_preprocessing_report_{int(time.time())}.txt"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")
    
    return results, best_config


def main():
    """ä¸»å‡½æ•°"""
    audio_files = []
    for ext in ['*.wav', '*.mp3', '*.flac']:
        audio_files.extend(Path('.').glob(ext))
    
    if not audio_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
        return
    
    print("æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶:")
    for i, file in enumerate(audio_files, 1):
        print(f"{i}. {file.name}")
    
    try:
        choice = int(input("é€‰æ‹©æ–‡ä»¶:"))
        audio_path = str(audio_files[choice - 1])
        
        results, best_config = test_mel_preprocessing_variants(audio_path)
        
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“ˆ æœ€ä½³é…ç½®: {best_config['config']}")
        print(f"ğŸ“Š æœ€ä½³SNR: {best_config['snr']:.2f} dB")
        
        if best_config['snr'] > -5:
            print(f"ğŸ† å–å¾—äº†æ˜¾è‘—æ”¹å–„ï¼")
        elif best_config['snr'] > -10:
            print(f"âœ… æœ‰æ‰€æ”¹å–„ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–")
        else:
            print(f"âš ï¸ æ”¹å–„æœ‰é™ï¼Œéœ€è¦æ›´æ·±å±‚çš„ä¿®å¤")
            
    except (ValueError, IndexError):
        print("âŒ æ— æ•ˆé€‰æ‹©")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
