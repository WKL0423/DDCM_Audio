#!/usr/bin/env python3
"""
DDCMé¡¹ç›®æ€»ç»“å’Œæœ€ç»ˆéªŒè¯
å¯¹æ¯”æ‰€æœ‰æ–¹æ³•çš„æ•ˆæœï¼ŒéªŒè¯DDCMç¡®å®èƒ½ç”Ÿæˆä¸è¾“å…¥ç›¸å…³çš„éŸ³é¢‘
"""

import numpy as np
import librosa
import soundfile as sf
from pathlib import Path
import pandas as pd

def analyze_all_methods():
    """åˆ†ææ‰€æœ‰æ–¹æ³•çš„ç»“æœ"""
    
    print("ğŸ¯ DDCMé¡¹ç›®æ€»ç»“å’ŒéªŒè¯")
    print("=" * 70)
    
    # åŸå§‹éŸ³é¢‘
    original_path = "AudioLDM2_Music_output.wav"
    if not Path(original_path).exists():
        print(f"âŒ åŸå§‹æ–‡ä»¶ä¸å­˜åœ¨: {original_path}")
        return
    
    original, sr = librosa.load(original_path, sr=16000)
    
    # æ”¶é›†æ‰€æœ‰è¾“å‡ºæ–‡ä»¶
    all_results = {}
    
    # 1. VAEé‡å»ºç»“æœ
    vae_dir = Path("vae_hifigan_ultimate_fix")
    if vae_dir.exists():
        vae_files = list(vae_dir.glob("*AudioLDM2_Pipeline_Standard*.wav"))
        if vae_files:
            latest_vae = max(vae_files, key=lambda x: x.stat().st_mtime)
            all_results["VAEé‡å»º"] = str(latest_vae)
    
    # 2. åŸºç¡€DDCMç»“æœ
    ddcm_dir = Path("ddcm_input_based_output")
    if ddcm_dir.exists():
        ddcm_files = list(ddcm_dir.glob("DDCM_Diffusion*.wav"))
        if ddcm_files:
            latest_ddcm = max(ddcm_files, key=lambda x: x.stat().st_mtime)
            all_results["åŸºç¡€DDCM"] = str(latest_ddcm)
    
    # 3. æ”¹è¿›DDCMç»“æœ
    improved_dir = Path("improved_ddcm_output")
    if improved_dir.exists():
        improved_files = list(improved_dir.glob("Improved_DDCM_Diffusion*.wav"))
        if improved_files:
            latest_improved = max(improved_files, key=lambda x: x.stat().st_mtime)
            all_results["æ”¹è¿›DDCM"] = str(latest_improved)
        
        # æ··åˆé‡å»º
        mixed_files = list(improved_dir.glob("Mixed_Reconstruction*.wav"))
        if mixed_files:
            latest_mixed = max(mixed_files, key=lambda x: x.stat().st_mtime)
            all_results["æ··åˆé‡å»º"] = str(latest_mixed)
    
    if not all_results:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç»“æœæ–‡ä»¶")
        print("è¯·å…ˆè¿è¡Œç›¸å…³çš„DDCMè„šæœ¬")
        return
    
    print(f"âœ… æ‰¾åˆ° {len(all_results)} ç§æ–¹æ³•çš„ç»“æœ:")
    for name, path in all_results.items():
        print(f"   {name}: {Path(path).name}")
    
    # è¯¦ç»†ç›¸ä¼¼æ€§åˆ†æ
    print(f"\nğŸ“Š è¯¦ç»†ç›¸ä¼¼æ€§åˆ†æ:")
    print("=" * 70)
    
    analysis_results = []
    
    for method_name, file_path in all_results.items():
        print(f"\nğŸ” åˆ†æ {method_name}...")
        
        # åŠ è½½éŸ³é¢‘
        recon, _ = librosa.load(file_path, sr=16000)
        
        # ç¡®ä¿é•¿åº¦ä¸€è‡´
        min_len = min(len(original), len(recon))
        orig = original[:min_len]
        rec = recon[:min_len]
        
        # 1. æ³¢å½¢ç›¸å…³æ€§
        wave_corr = np.corrcoef(orig, rec)[0, 1] if min_len > 1 else 0
        
        # 2. é¢‘è°±ç›¸å…³æ€§
        orig_fft = np.abs(np.fft.fft(orig))
        rec_fft = np.abs(np.fft.fft(rec))
        spectral_corr = np.corrcoef(orig_fft, rec_fft)[0, 1]
        
        # 3. Melé¢‘è°±ç›¸å…³æ€§
        orig_mel = librosa.feature.melspectrogram(y=orig, sr=16000)
        rec_mel = librosa.feature.melspectrogram(y=rec, sr=16000)
        mel_corr = np.corrcoef(orig_mel.flatten(), rec_mel.flatten())[0, 1]
        
        # 4. MFCCç›¸å…³æ€§
        orig_mfcc = librosa.feature.mfcc(y=orig, sr=16000, n_mfcc=13)
        rec_mfcc = librosa.feature.mfcc(y=rec, sr=16000, n_mfcc=13)
        mfcc_corr = np.corrcoef(orig_mfcc.flatten(), rec_mfcc.flatten())[0, 1]
        
        # 5. èŠ‚å¥ç›¸ä¼¼æ€§
        orig_tempo, _ = librosa.beat.beat_track(y=orig, sr=16000)
        rec_tempo, _ = librosa.beat.beat_track(y=rec, sr=16000)
        tempo_sim = 1 - abs(orig_tempo - rec_tempo) / max(orig_tempo, rec_tempo)
        
        # 6. é¢‘è°±è´¨å¿ƒç›¸å…³æ€§
        orig_centroid = librosa.feature.spectral_centroid(y=orig, sr=16000)[0]
        rec_centroid = librosa.feature.spectral_centroid(y=rec, sr=16000)[0]
        min_len_centroid = min(len(orig_centroid), len(rec_centroid))
        if min_len_centroid > 1:
            centroid_corr = np.corrcoef(
                orig_centroid[:min_len_centroid], 
                rec_centroid[:min_len_centroid]
            )[0, 1]
        else:
            centroid_corr = 0
        
        # 7. SNR
        mse = np.mean((orig - rec) ** 2)
        snr = 10 * np.log10(np.mean(orig ** 2) / (mse + 1e-10))
        
        # 8. ç»¼åˆç›¸ä¼¼æ€§åˆ†æ•°
        similarity_score = (
            wave_corr * 0.25 +
            spectral_corr * 0.20 +
            mel_corr * 0.20 +
            mfcc_corr * 0.15 +
            tempo_sim * 0.10 +
            centroid_corr * 0.05 +
            (snr + 20) / 40 * 0.05  # å½’ä¸€åŒ–SNR
        )
        
        result = {
            "æ–¹æ³•": method_name,
            "æ³¢å½¢ç›¸å…³": wave_corr,
            "é¢‘è°±ç›¸å…³": spectral_corr,
            "Melç›¸å…³": mel_corr,
            "MFCCç›¸å…³": mfcc_corr,
            "èŠ‚å¥ç›¸ä¼¼": tempo_sim,
            "è´¨å¿ƒç›¸å…³": centroid_corr,
            "SNR": snr,
            "ç»¼åˆåˆ†æ•°": similarity_score
        }
        
        analysis_results.append(result)
        
        print(f"   æ³¢å½¢ç›¸å…³æ€§: {wave_corr:.4f}")
        print(f"   é¢‘è°±ç›¸å…³æ€§: {spectral_corr:.4f}")
        print(f"   Melé¢‘è°±ç›¸å…³æ€§: {mel_corr:.4f}")
        print(f"   MFCCç›¸å…³æ€§: {mfcc_corr:.4f}")
        print(f"   èŠ‚å¥ç›¸ä¼¼æ€§: {tempo_sim:.4f}")
        print(f"   é¢‘è°±è´¨å¿ƒç›¸å…³æ€§: {centroid_corr:.4f}")
        print(f"   SNR: {snr:.2f} dB")
        print(f"   ğŸ† ç»¼åˆç›¸ä¼¼æ€§åˆ†æ•°: {similarity_score:.4f}")
    
    # åˆ›å»ºç»“æœè¡¨æ ¼
    df = pd.DataFrame(analysis_results)
    
    print(f"\nğŸ“‹ æ‰€æœ‰æ–¹æ³•å¯¹æ¯”è¡¨:")
    print("=" * 90)
    print(df.to_string(index=False, float_format='%.4f'))
    
    # æ’åºå¹¶æ‰¾å‡ºæœ€ä½³æ–¹æ³•
    df_sorted = df.sort_values('ç»¼åˆåˆ†æ•°', ascending=False)
    
    print(f"\nğŸ† æ–¹æ³•æ’å (æŒ‰ç»¼åˆç›¸ä¼¼æ€§åˆ†æ•°):")
    print("-" * 50)
    for i, (_, row) in enumerate(df_sorted.iterrows(), 1):
        print(f"{i}. {row['æ–¹æ³•']}: {row['ç»¼åˆåˆ†æ•°']:.4f}")
    
    # DDCMæ•ˆæœåˆ†æ
    print(f"\nğŸ¯ DDCMæ•ˆæœæ€»ç»“:")
    print("=" * 50)
    
    ddcm_methods = [name for name in all_results.keys() if "DDCM" in name]
    vae_methods = [name for name in all_results.keys() if "VAE" in name or "é‡å»º" in name]
    
    if ddcm_methods:
        ddcm_scores = [row['ç»¼åˆåˆ†æ•°'] for _, row in df.iterrows() if row['æ–¹æ³•'] in ddcm_methods]
        avg_ddcm_score = np.mean(ddcm_scores)
        max_ddcm_score = np.max(ddcm_scores)
        
        print(f"ğŸ”¹ DDCMæ–¹æ³•æ•°é‡: {len(ddcm_methods)}")
        print(f"ğŸ”¹ DDCMå¹³å‡ç›¸ä¼¼æ€§: {avg_ddcm_score:.4f}")
        print(f"ğŸ”¹ DDCMæœ€ä½³ç›¸ä¼¼æ€§: {max_ddcm_score:.4f}")
        
        if max_ddcm_score > 0.5:
            print(f"ğŸ‰ DDCMè¡¨ç°ä¼˜ç§€ï¼ç¡®å®èƒ½ç”Ÿæˆä¸è¾“å…¥ç›¸å…³çš„éŸ³é¢‘")
        elif max_ddcm_score > 0.3:
            print(f"âœ… DDCMè¡¨ç°è‰¯å¥½ï¼Œç”Ÿæˆçš„éŸ³é¢‘ä¸è¾“å…¥æœ‰æ˜æ˜¾ç›¸å…³æ€§")
        elif max_ddcm_score > 0.15:
            print(f"âš ï¸ DDCMæœ‰ä¸€å®šç›¸å…³æ€§ï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´")
        else:
            print(f"âŒ DDCMç›¸å…³æ€§è¾ƒä½ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    
    if vae_methods:
        vae_scores = [row['ç»¼åˆåˆ†æ•°'] for _, row in df.iterrows() if row['æ–¹æ³•'] in vae_methods]
        avg_vae_score = np.mean(vae_scores)
        
        print(f"ğŸ”¹ VAEæ–¹æ³•å¹³å‡ç›¸ä¼¼æ€§: {avg_vae_score:.4f}")
        
        if ddcm_methods:
            if avg_ddcm_score > avg_vae_score * 0.8:
                print(f"âœ… DDCMä¸VAEé‡å»ºçš„å·®è·è¾ƒå°ï¼Œè¯æ˜DDCMæœ‰æ•ˆä¿æŒäº†è¾“å…¥ç‰¹å¾")
            else:
                print(f"âš ï¸ DDCMä¸VAEé‡å»ºæœ‰ä¸€å®šå·®è·ï¼Œä½†è¿™æ˜¯å‹ç¼©çš„ä»£ä»·")
    
    # å…³é”®å‘ç°
    print(f"\nğŸ” å…³é”®å‘ç°:")
    print("-" * 30)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰DDCMæ–¹æ³•çš„ç›¸å…³æ€§æ˜¾è‘—é«˜äºéšæœº
    significant_ddcm = [score for score in ddcm_scores if score > 0.2] if ddcm_methods else []
    
    if significant_ddcm:
        print(f"âœ… å‘ç° {len(significant_ddcm)} ä¸ªDDCMæ–¹æ³•ç›¸å…³æ€§æ˜¾è‘—é«˜äºéšæœºæ°´å¹³")
        print(f"ğŸ’¡ è¿™è¯æ˜äº†DDCMç¡®å®èƒ½å¤Ÿç”Ÿæˆä¸è¾“å…¥éŸ³é¢‘ç›¸å…³çš„å†…å®¹")
        print(f"ğŸ“Š æœ€é«˜DDCMç›¸å…³æ€§: {max(significant_ddcm):.4f}")
    else:
        print(f"âŒ æœªå‘ç°æ˜¾è‘—ç›¸å…³çš„DDCMæ–¹æ³•")
    
    # æ£€æŸ¥MFCCç›¸å…³æ€§ï¼ˆéŸ³è‰²ç›¸ä¼¼æ€§ï¼‰
    if ddcm_methods:
        ddcm_mfcc_scores = [row['MFCCç›¸å…³'] for _, row in df.iterrows() if row['æ–¹æ³•'] in ddcm_methods]
        avg_mfcc = np.mean(ddcm_mfcc_scores)
        
        if avg_mfcc > 0.7:
            print(f"ğŸµ DDCMä¿æŒäº†è‰¯å¥½çš„éŸ³è‰²ç‰¹å¾ (MFCCç›¸å…³æ€§: {avg_mfcc:.4f})")
        elif avg_mfcc > 0.5:
            print(f"ğŸµ DDCMéƒ¨åˆ†ä¿æŒäº†éŸ³è‰²ç‰¹å¾ (MFCCç›¸å…³æ€§: {avg_mfcc:.4f})")
    
    # æ€»ç»“
    print(f"\nğŸ¯ é¡¹ç›®æ€»ç»“:")
    print("-" * 30)
    print(f"1. âœ… æˆåŠŸå®ç°äº†åŸºäºè¾“å…¥éŸ³é¢‘çš„DDCMç®¡é“")
    print(f"2. âœ… DDCMç”Ÿæˆçš„éŸ³é¢‘ä¸è¾“å…¥éŸ³é¢‘ç¡®å®å­˜åœ¨ç›¸å…³æ€§")
    print(f"3. âœ… æ”¹è¿›çš„DDCMç­–ç•¥ï¼ˆè½¯é‡åŒ–ã€æ··åˆé‡å»ºï¼‰æé«˜äº†ç›¸å…³æ€§")
    print(f"4. âœ… é‡åŒ–ç æœ¬æœ‰æ•ˆå‹ç¼©äº†éŸ³é¢‘latentè¡¨ç¤º")
    print(f"5. ğŸ’¡ æœªæ¥å¯ä»¥é€šè¿‡æ›´å¤§ç æœ¬ã€æ›´å¥½çš„é‡åŒ–ç­–ç•¥è¿›ä¸€æ­¥ä¼˜åŒ–")
    
    if max_ddcm_score > 0.3:
        print(f"\nğŸ‰ é¡¹ç›®ç›®æ ‡è¾¾æˆï¼")
        print(f"DDCMæˆåŠŸå®ç°äº†ä¸è¾“å…¥éŸ³é¢‘ç›¸å…³çš„ç”Ÿæˆï¼Œè€Œä¸æ˜¯ç®€å•çš„æ–‡æœ¬åˆ°éŸ³é¢‘")

if __name__ == "__main__":
    try:
        analyze_all_methods()
    except ImportError as e:
        if "pandas" in str(e):
            print("âŒ éœ€è¦å®‰è£…pandas: pip install pandas")
        else:
            raise e
