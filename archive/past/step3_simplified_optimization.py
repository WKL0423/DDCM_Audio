#!/usr/bin/env python3
"""
Step 3: ÁÆÄÂåñÁöÑÂèÇÊï∞‰ºòÂåñ
‰øÆÂ§ç‰∫ÜPyTorchÂÖºÂÆπÊÄßÈóÆÈ¢òÁöÑÁâàÊú¨Ôºå‰∏ìÊ≥®‰∫éÊ†∏ÂøÉÁöÑÂèÇÊï∞ÊµãËØï
"""

import torch
import torch.nn.functional as F
import torchaudio
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import librosa
from pathlib import Path
import time
from diffusers import AudioLDM2Pipeline
from typing import Dict, Tuple, List
import warnings
warnings.filterwarnings("ignore")

class SimpleParameterOptimizer:
    """
    ÁÆÄÂåñÁöÑÂèÇÊï∞‰ºòÂåñÂô®
    ÈÅøÂÖçÂ§çÊùÇÁöÑPyTorchÊìç‰ΩúÔºå‰∏ìÊ≥®‰∫éÊ†∏ÂøÉÂäüËÉΩ
    """
    
    def __init__(self, model_name: str = "cvssp/audioldm2-music"):
        """ÂàùÂßãÂåñ‰ºòÂåñÂô®"""
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        print(f"üéØ ÂàùÂßãÂåñÁÆÄÂåñÂèÇÊï∞‰ºòÂåñÂô®")
        print(f"   üì± ËÆæÂ§á: {self.device}")
        
        # Âä†ËΩΩAudioLDM2ÁÆ°ÈÅì
        print("üì¶ Âä†ËΩΩAudioLDM2Ê®°Âûã...")
        self.pipeline = AudioLDM2Pipeline.from_pretrained(
            model_name,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
        ).to(self.device)
        
        print(f"‚úÖ ÁÆÄÂåñÂèÇÊï∞‰ºòÂåñÂô®ÂàùÂßãÂåñÂÆåÊàê")
        
        # ÂàõÂª∫ËæìÂá∫ÁõÆÂΩï
        self.output_dir = Path("simplified_parameter_optimization")
        self.output_dir.mkdir(exist_ok=True)
        print(f"üìÅ ËæìÂá∫ÁõÆÂΩï: {self.output_dir}")
    
    def optimize_frequency_boost_parameters(self, audio_path: str) -> Dict:
        """
        ‰ºòÂåñÈ¢ëÁéáÂ¢ûÂº∫ÂèÇÊï∞
        ÊµãËØï‰∏çÂêåÁöÑÂ¢ûÂº∫Á≥ªÊï∞ÔºåÊâæÂà∞ÊúÄ‰Ω≥Âπ≥Ë°°ÁÇπ
        """
        print(f"\nüî¨ ÂºÄÂßãÈ¢ëÁéáÂ¢ûÂº∫ÂèÇÊï∞‰ºòÂåñ: {Path(audio_path).name}")
        
        # Âä†ËΩΩÂíåÈ¢ÑÂ§ÑÁêÜÈü≥È¢ëÔºàÂè™ÂÅö‰∏ÄÊ¨°Ôºâ
        original_audio, processed_audio = self._load_and_preprocess_audio(audio_path)
        latent = self._encode_audio(processed_audio)
        vae_only_audio = self._decode_audio(latent.clone())
        
        # ÂÆö‰πâÊµãËØïÁöÑÂ¢ûÂº∫Á≥ªÊï∞
        boost_factors = [1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.8, 2.0, 2.5, 3.0]
        
        results = []
        timestamp = int(time.time())
        
        print(f"üß™ ÊµãËØï {len(boost_factors)} ÁßçÂ¢ûÂº∫Á≥ªÊï∞...")
        
        for i, boost_factor in enumerate(boost_factors):
            print(f"\n   üî¨ ÊµãËØï {i+1}/{len(boost_factors)}: Â¢ûÂº∫Á≥ªÊï∞ {boost_factor}x")
            
            # Â∫îÁî®Â¢ûÂº∫
            enhanced_latent = self._apply_simple_frequency_boost(latent.clone(), boost_factor)
            enhanced_audio = self._decode_audio(enhanced_latent)
            
            # ÂàÜÊûêË¥®Èáè
            quality_metrics = self._analyze_quality(original_audio, vae_only_audio, enhanced_audio)
            freq_metrics = self._analyze_frequency(original_audio, vae_only_audio, enhanced_audio)
            
            # ËÆ°ÁÆóÁªºÂêàÂæóÂàÜ
            composite_score = self._calculate_composite_score(quality_metrics, freq_metrics)
            
            # ‰øùÂ≠òÂÖ≥ÈîÆÈÖçÁΩÆÁöÑÈü≥È¢ë
            audio_paths = None
            if boost_factor in [1.2, 1.5, 2.0] or composite_score > 6.0:  # ‰øùÂ≠òÂÖ≥ÈîÆÈÖçÁΩÆ
                audio_paths = self._save_configuration_audio(
                    original_audio, vae_only_audio, enhanced_audio, 
                    timestamp, f"boost_{boost_factor}"
                )
            
            result = {
                "boost_factor": boost_factor,
                "quality_metrics": quality_metrics,
                "frequency_metrics": freq_metrics,
                "composite_score": composite_score,
                "audio_paths": audio_paths
            }
            
            results.append(result)
            
            print(f"      üìä ÁªºÂêàÂæóÂàÜ: {composite_score:.2f}")
            print(f"      üéº È´òÈ¢ëÊîπËøõ: {freq_metrics['improvements']['high_freq_improvement']*100:+.1f}%")
            print(f"      üìà SNRÊîπËøõ: {quality_metrics['improvements']['snr_improvement']:+.2f} dB")
        
        # ÊâæÂà∞ÊúÄ‰Ω≥ÈÖçÁΩÆ
        best_result = max(results, key=lambda x: x['composite_score'])
        
        # ÂàõÂª∫ÂàÜÊûêÊä•Âëä
        self._create_analysis_report(results, best_result, timestamp)
        
        # ÂàõÂª∫ÂèØËßÜÂåñ
        self._create_analysis_visualizations(results, timestamp)
        
        optimization_result = {
            "input_file": audio_path,
            "timestamp": timestamp,
            "all_results": results,
            "best_result": best_result,
            "total_configs_tested": len(boost_factors)
        }
        
        self._display_results(optimization_result)
        
        return optimization_result
    
    def _apply_simple_frequency_boost(self, latent: torch.Tensor, boost_factor: float) -> torch.Tensor:
        """
        Â∫îÁî®ÁÆÄÂçïÁöÑÈ¢ëÁéáÂ¢ûÂº∫
        ‰ΩøÁî®Âü∫Á°ÄÁöÑLaplacianÁÆóÂ≠êÔºåÈÅøÂÖçÂ§çÊùÇÁöÑstrideÊìç‰Ωú
        """
        with torch.no_grad():
            # ÁÆÄÂçïÁöÑLaplacianÊ†∏
            laplacian = torch.tensor([
                [[-1, -1, -1],
                 [-1,  8, -1],
                 [-1, -1, -1]]
            ], dtype=latent.dtype, device=latent.device).unsqueeze(0).unsqueeze(0)
            
            enhanced_latent = latent.clone()
            
            # ÂØπÊØè‰∏™ÈÄöÈÅìÂàÜÂà´Â§ÑÁêÜ
            for c in range(latent.shape[1]):
                channel_latent = latent[:, c:c+1, :, :]  # [B, 1, H, W]
                
                # Â∫îÁî®È´òÈ¢ëÊ£ÄÊµãÔºàÁÆÄÂåñÁâàÔºåÈÅøÂÖçstrideÈóÆÈ¢òÔºâ
                # ÊâãÂä®ÂÆûÁé∞padding
                padded_channel = F.pad(channel_latent, (1, 1, 1, 1), mode='reflect')
                
                # ÊâãÂä®Âç∑ÁßØÔºàÈÅøÂÖçstrideÂèÇÊï∞ÈóÆÈ¢òÔºâ
                high_freq_response = F.conv2d(padded_channel, laplacian, padding=0)
                
                # Á°Æ‰øùËæìÂá∫Â∞∫ÂØ∏Ê≠£Á°Æ
                if high_freq_response.shape != channel_latent.shape:
                    high_freq_response = F.interpolate(
                        high_freq_response, 
                        size=channel_latent.shape[-2:], 
                        mode='bilinear', 
                        align_corners=False
                    )
                
                # Â∫îÁî®Â¢ûÂº∫
                enhanced_channel = channel_latent + high_freq_response * (boost_factor - 1.0)
                enhanced_latent[:, c:c+1, :, :] = enhanced_channel
            
            return enhanced_latent
    
    def _calculate_composite_score(self, quality_metrics: Dict, freq_metrics: Dict) -> float:
        """ËÆ°ÁÆóÁªºÂêàËØÑÂàÜ"""
        q_improvements = quality_metrics['improvements']
        f_improvements = freq_metrics['improvements']
        
        # ÊùÉÈáçËÆæËÆ°ÔºàÈ´òÈ¢ëÊÅ¢Â§çÊúÄÈáçË¶ÅÔºâ
        weights = {
            'snr': 0.2,
            'correlation': 0.3,
            'high_freq': 0.4,
            'overall_freq': 0.1
        }
        
        # ÂΩí‰∏ÄÂåñÂæóÂàÜ
        snr_score = max(0, min(10, (q_improvements['snr_improvement'] + 5) * 2))
        corr_score = max(0, min(10, q_improvements['correlation_improvement'] * 100))
        high_freq_score = max(0, min(10, f_improvements['high_freq_improvement'] * 10))
        overall_freq_score = max(0, min(10, f_improvements['frequency_correlation_improvement'] * 20))
        
        composite_score = (
            weights['snr'] * snr_score +
            weights['correlation'] * corr_score +
            weights['high_freq'] * high_freq_score +
            weights['overall_freq'] * overall_freq_score
        )
        
        return composite_score
    
    def _load_and_preprocess_audio(self, audio_path: str) -> Tuple[np.ndarray, torch.Tensor]:
        """Âä†ËΩΩÂíåÈ¢ÑÂ§ÑÁêÜÈü≥È¢ë"""
        print(f"   üìÇ Âä†ËΩΩÈü≥È¢ëÊñá‰ª∂...")
        
        original_audio, sr = torchaudio.load(audio_path)
        
        if original_audio.shape[0] > 1:
            original_audio = original_audio.mean(dim=0, keepdim=True)
        
        if sr != 48000:
            resampler = torchaudio.transforms.Resample(sr, 48000)
            processed_audio = resampler(original_audio)
        else:
            processed_audio = original_audio.clone()
        
        max_length = 48000 * 10
        if processed_audio.shape[-1] > max_length:
            processed_audio = processed_audio[..., :max_length]
        
        original_audio_np = original_audio.squeeze().numpy()
        return original_audio_np, processed_audio
    
    def _encode_audio(self, audio: torch.Tensor) -> torch.Tensor:
        """VAEÁºñÁ†Å"""
        with torch.no_grad():
            audio_np = audio.squeeze().numpy()
            inputs = self.pipeline.feature_extractor(
                audio_np, sampling_rate=48000, return_tensors="pt"
            )
            mel_features = inputs["input_features"].to(self.device)
            
            if mel_features.dim() == 3:
                mel_features = mel_features.unsqueeze(1)
            
            if self.device == "cuda":
                mel_features = mel_features.half()
            
            latent_dist = self.pipeline.vae.encode(mel_features)
            latent = latent_dist.latent_dist.mode()
            latent = latent * self.pipeline.vae.config.scaling_factor
            
            return latent
    
    def _decode_audio(self, latent: torch.Tensor) -> np.ndarray:
        """VAEËß£Á†Å"""
        with torch.no_grad():
            latent_for_decode = latent / self.pipeline.vae.config.scaling_factor
            vae_dtype = next(self.pipeline.vae.parameters()).dtype
            latent_for_decode = latent_for_decode.to(vae_dtype)
            
            mel_spectrogram = self.pipeline.vae.decode(latent_for_decode).sample
            audio_tensor = self.pipeline.mel_spectrogram_to_waveform(mel_spectrogram)
            audio_np = audio_tensor.squeeze().cpu().numpy()
            
            return audio_np
    
    def _analyze_quality(self, original: np.ndarray, vae_only: np.ndarray, enhanced: np.ndarray) -> Dict:
        """Ë¥®ÈáèÂàÜÊûê"""
        original_16k = librosa.resample(original, orig_sr=48000, target_sr=16000)
        
        def calc_metrics(orig, recon):
            min_len = min(len(orig), len(recon))
            o, r = orig[:min_len], recon[:min_len]
            
            mse = np.mean((o - r) ** 2)
            snr = 10 * np.log10(np.mean(o ** 2) / (mse + 1e-10))
            correlation = np.corrcoef(o, r)[0, 1] if min_len > 1 else 0.0
            if np.isnan(correlation):
                correlation = 0.0
            
            return {"snr_db": snr, "correlation": correlation, "mse": mse}
        
        vae_metrics = calc_metrics(original_16k, vae_only)
        enhanced_metrics = calc_metrics(original_16k, enhanced)
        
        improvements = {
            "snr_improvement": enhanced_metrics["snr_db"] - vae_metrics["snr_db"],
            "correlation_improvement": enhanced_metrics["correlation"] - vae_metrics["correlation"],
            "mse_improvement": vae_metrics["mse"] - enhanced_metrics["mse"]
        }
        
        return {
            "vae_only": vae_metrics,
            "enhanced": enhanced_metrics,
            "improvements": improvements
        }
    
    def _analyze_frequency(self, original: np.ndarray, vae_only: np.ndarray, enhanced: np.ndarray) -> Dict:
        """È¢ëÁéáÂàÜÊûê"""
        original_16k = librosa.resample(original, orig_sr=48000, target_sr=16000)
        
        def analyze_bands(orig, recon):
            min_len = min(len(orig), len(recon))
            o, r = orig[:min_len], recon[:min_len]
            
            n_fft = 8192 if min_len >= 8192 else 2 ** int(np.log2(min_len))
            orig_fft = np.abs(np.fft.fft(o[:n_fft]))[:n_fft//2]
            recon_fft = np.abs(np.fft.fft(r[:n_fft]))[:n_fft//2]
            freqs = np.fft.fftfreq(n_fft, 1/16000)[:n_fft//2]
            
            low_mask = freqs < 500
            mid_mask = (freqs >= 500) & (freqs < 4000)
            high_mask = freqs >= 4000
            
            low_retention = np.sum(recon_fft[low_mask]) / (np.sum(orig_fft[low_mask]) + 1e-10)
            mid_retention = np.sum(recon_fft[mid_mask]) / (np.sum(orig_fft[mid_mask]) + 1e-10)
            high_retention = np.sum(recon_fft[high_mask]) / (np.sum(orig_fft[high_mask]) + 1e-10)
            
            freq_corr = np.corrcoef(orig_fft, recon_fft)[0, 1]
            if np.isnan(freq_corr):
                freq_corr = 0.0
            
            return {
                "low_freq_retention": low_retention,
                "mid_freq_retention": mid_retention,
                "high_freq_retention": high_retention,
                "frequency_correlation": freq_corr
            }
        
        vae_freq = analyze_bands(original_16k, vae_only)
        enhanced_freq = analyze_bands(original_16k, enhanced)
        
        improvements = {
            "low_freq_improvement": enhanced_freq["low_freq_retention"] - vae_freq["low_freq_retention"],
            "mid_freq_improvement": enhanced_freq["mid_freq_retention"] - vae_freq["mid_freq_retention"],
            "high_freq_improvement": enhanced_freq["high_freq_retention"] - vae_freq["high_freq_retention"],
            "frequency_correlation_improvement": enhanced_freq["frequency_correlation"] - vae_freq["frequency_correlation"]
        }
        
        return {
            "vae_only": vae_freq,
            "enhanced": enhanced_freq,
            "improvements": improvements
        }
    
    def _save_configuration_audio(self,
                                original: np.ndarray,
                                vae_only: np.ndarray,
                                enhanced: np.ndarray,
                                timestamp: int,
                                config_name: str) -> Dict[str, str]:
        """‰øùÂ≠òÁâπÂÆöÈÖçÁΩÆÁöÑÈü≥È¢ë"""
        
        paths = {}
        safe_name = config_name.replace(".", "_")
        
        original_16k = librosa.resample(original, orig_sr=48000, target_sr=16000)
        
        original_path = self.output_dir / f"original_{safe_name}_{timestamp}.wav"
        vae_path = self.output_dir / f"vae_only_{safe_name}_{timestamp}.wav"
        enhanced_path = self.output_dir / f"enhanced_{safe_name}_{timestamp}.wav"
        
        sf.write(str(original_path), original_16k, 16000)
        sf.write(str(vae_path), vae_only, 16000)
        sf.write(str(enhanced_path), enhanced, 16000)
        
        paths["original"] = str(original_path)
        paths["vae_only"] = str(vae_path)
        paths["enhanced"] = str(enhanced_path)
        
        return paths
    
    def _create_analysis_report(self, results: List[Dict], best_result: Dict, timestamp: int):
        """ÂàõÂª∫ÂàÜÊûêÊä•Âëä"""
        
        report_path = self.output_dir / f"boost_factor_analysis_{timestamp}.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# È¢ëÁéáÂ¢ûÂº∫Á≥ªÊï∞‰ºòÂåñÊä•Âëä\n\n")
            f.write(f"## ÊµãËØïÊ¶ÇÂÜµ\n")
            f.write(f"- ÊµãËØïÈÖçÁΩÆÊï∞Èáè: {len(results)}\n")
            f.write(f"- ÊµãËØïÊó∂Èó¥: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(timestamp))}\n\n")
            
            f.write("## ÊúÄ‰Ω≥ÈÖçÁΩÆ\n")
            f.write(f"- **ÊúÄ‰Ω≥Â¢ûÂº∫Á≥ªÊï∞**: {best_result['boost_factor']}x\n")
            f.write(f"- **ÁªºÂêàÂæóÂàÜ**: {best_result['composite_score']:.2f}\n")
            f.write(f"- **SNRÊîπËøõ**: {best_result['quality_metrics']['improvements']['snr_improvement']:+.2f} dB\n")
            f.write(f"- **È´òÈ¢ëÊîπËøõ**: {best_result['frequency_metrics']['improvements']['high_freq_improvement']*100:+.1f}%\n\n")
            
            f.write("## ÊâÄÊúâÈÖçÁΩÆÁªìÊûú\n\n")
            f.write("| Â¢ûÂº∫Á≥ªÊï∞ | SNRÊîπËøõ(dB) | È´òÈ¢ëÊîπËøõ(%) | Áõ∏ÂÖ≥ÊÄßÊîπËøõ | ÁªºÂêàÂæóÂàÜ |\n")
            f.write("|----------|-------------|-------------|------------|----------|\n")
            
            # ÊåâÂæóÂàÜÊéíÂ∫è
            sorted_results = sorted(results, key=lambda x: x['composite_score'], reverse=True)
            
            for result in sorted_results:
                boost = result['boost_factor']
                quality = result['quality_metrics']['improvements']
                freq = result['frequency_metrics']['improvements']
                score = result['composite_score']
                
                f.write(f"| {boost}x | {quality['snr_improvement']:+.2f} | "
                       f"{freq['high_freq_improvement']*100:+.1f} | "
                       f"{quality['correlation_improvement']:+.4f} | "
                       f"{score:.2f} |\n")
            
            f.write("\n## ÂÖ≥ÈîÆÂèëÁé∞\n\n")
            
            # ÊâæÂà∞ÊúÄ‰Ω≥ËåÉÂõ¥
            high_scores = [r for r in results if r['composite_score'] > 6.0]
            if high_scores:
                boost_range = [r['boost_factor'] for r in high_scores]
                f.write(f"### ÊúÄ‰Ω≥Â¢ûÂº∫Á≥ªÊï∞ËåÉÂõ¥\n")
                f.write(f"- È´òÂàÜÈÖçÁΩÆÁöÑÂ¢ûÂº∫Á≥ªÊï∞ËåÉÂõ¥: {min(boost_range):.1f}x - {max(boost_range):.1f}x\n")
                f.write(f"- Âª∫ËÆÆ‰ΩøÁî®: {best_result['boost_factor']}x (ÊúÄÈ´òÂæóÂàÜ)\n\n")
            
            # Ë∂ãÂäøÂàÜÊûê
            f.write("### Ë∂ãÂäøÂàÜÊûê\n")
            boost_factors = [r['boost_factor'] for r in results]
            scores = [r['composite_score'] for r in results]
            
            # ÊâæÂà∞ÂæóÂàÜÁöÑÂ≥∞ÂÄº
            max_score_idx = scores.index(max(scores))
            optimal_boost = boost_factors[max_score_idx]
            
            f.write(f"- ÊúÄ‰ºòÂ¢ûÂº∫Á≥ªÊï∞: {optimal_boost}x\n")
            
            # ÂàÜÊûêËøáÂ∫¶Â¢ûÂº∫
            over_enhanced = [r for r in results if r['boost_factor'] > optimal_boost and r['composite_score'] < best_result['composite_score']]
            if over_enhanced:
                f.write(f"- ËøáÂ∫¶Â¢ûÂº∫ÈòàÂÄº: >{optimal_boost}x ÂêéÊÄßËÉΩ‰∏ãÈôç\n")
            
        print(f"   üìÑ ÂàÜÊûêÊä•ÂëäÂ∑≤‰øùÂ≠ò: {report_path}")
    
    def _create_analysis_visualizations(self, results: List[Dict], timestamp: int):
        """ÂàõÂª∫ÂàÜÊûêÂèØËßÜÂåñ"""
        
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('È¢ëÁéáÂ¢ûÂº∫Á≥ªÊï∞‰ºòÂåñÂàÜÊûê', fontsize=16, fontweight='bold')
            
            # ÊèêÂèñÊï∞ÊçÆ
            boost_factors = [r['boost_factor'] for r in results]
            composite_scores = [r['composite_score'] for r in results]
            snr_improvements = [r['quality_metrics']['improvements']['snr_improvement'] for r in results]
            high_freq_improvements = [r['frequency_metrics']['improvements']['high_freq_improvement'] * 100 for r in results]
            
            # 1. ÁªºÂêàÂæóÂàÜ vs Â¢ûÂº∫Á≥ªÊï∞
            axes[0, 0].plot(boost_factors, composite_scores, 'o-', linewidth=2, markersize=8)
            axes[0, 0].set_title('ÁªºÂêàÂæóÂàÜ vs Â¢ûÂº∫Á≥ªÊï∞')
            axes[0, 0].set_xlabel('Â¢ûÂº∫Á≥ªÊï∞')
            axes[0, 0].set_ylabel('ÁªºÂêàÂæóÂàÜ')
            axes[0, 0].grid(True, alpha=0.3)
            
            # Ê†áËÆ∞ÊúÄ‰Ω≥ÁÇπ
            best_idx = composite_scores.index(max(composite_scores))
            axes[0, 0].scatter([boost_factors[best_idx]], [composite_scores[best_idx]], 
                             color='red', s=100, zorder=5, label='ÊúÄ‰Ω≥ÈÖçÁΩÆ')
            axes[0, 0].legend()
            
            # 2. SNRÊîπËøõ vs Â¢ûÂº∫Á≥ªÊï∞
            axes[0, 1].plot(boost_factors, snr_improvements, 's-', linewidth=2, markersize=6, color='orange')
            axes[0, 1].set_title('SNRÊîπËøõ vs Â¢ûÂº∫Á≥ªÊï∞')
            axes[0, 1].set_xlabel('Â¢ûÂº∫Á≥ªÊï∞')
            axes[0, 1].set_ylabel('SNRÊîπËøõ (dB)')
            axes[0, 1].grid(True, alpha=0.3)
            axes[0, 1].axhline(y=0, color='red', linestyle='--', alpha=0.5)
            
            # 3. È´òÈ¢ëÊîπËøõ vs Â¢ûÂº∫Á≥ªÊï∞
            axes[1, 0].plot(boost_factors, high_freq_improvements, '^-', linewidth=2, markersize=6, color='green')
            axes[1, 0].set_title('È´òÈ¢ëÊîπËøõ vs Â¢ûÂº∫Á≥ªÊï∞')
            axes[1, 0].set_xlabel('Â¢ûÂº∫Á≥ªÊï∞')
            axes[1, 0].set_ylabel('È´òÈ¢ëÊîπËøõ (%)')
            axes[1, 0].grid(True, alpha=0.3)
            
            # 4. SNR vs È´òÈ¢ëÊîπËøõÊï£ÁÇπÂõæ
            axes[1, 1].scatter(snr_improvements, high_freq_improvements, s=100, alpha=0.7)
            for i, boost in enumerate(boost_factors):
                axes[1, 1].annotate(f'{boost}x', (snr_improvements[i], high_freq_improvements[i]), 
                                  xytext=(5, 5), textcoords='offset points', fontsize=8)
            axes[1, 1].set_title('SNRÊîπËøõ vs È´òÈ¢ëÊîπËøõ')
            axes[1, 1].set_xlabel('SNRÊîπËøõ (dB)')
            axes[1, 1].set_ylabel('È´òÈ¢ëÊîπËøõ (%)')
            axes[1, 1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            plot_path = self.output_dir / f"boost_factor_analysis_{timestamp}.png"
            plt.savefig(str(plot_path), dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"   üìä ÂàÜÊûêÂèØËßÜÂåñÂ∑≤‰øùÂ≠ò: {plot_path}")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è ÂèØËßÜÂåñÁîüÊàêÂ§±Ë¥•: {e}")
    
    def _display_results(self, result: Dict):
        """ÊòæÁ§∫ÁªìÊûú"""
        print(f"\n{'='*80}")
        print(f"üéØ È¢ëÁéáÂ¢ûÂº∫Á≥ªÊï∞‰ºòÂåñÂÆåÊàêÔºÅ")
        print(f"{'='*80}")
        
        print(f"üìÅ ËæìÂÖ•Êñá‰ª∂: {result['input_file']}")
        print(f"üß™ ÊµãËØïÈÖçÁΩÆÊï∞Èáè: {result['total_configs_tested']}")
        
        best = result['best_result']
        best_quality = best['quality_metrics']['improvements']
        best_freq = best['frequency_metrics']['improvements']
        
        print(f"\nüèÜ ÊúÄ‰Ω≥ÈÖçÁΩÆ:")
        print(f"   üìà ÊúÄ‰Ω≥Â¢ûÂº∫Á≥ªÊï∞: {best['boost_factor']}x")
        print(f"   üèÖ ÁªºÂêàÂæóÂàÜ: {best['composite_score']:.2f}/10")
        
        print(f"\nüìä ÊúÄ‰Ω≥ÈÖçÁΩÆÊÄßËÉΩ:")
        print(f"   üìà SNRÊîπËøõ: {best_quality['snr_improvement']:+.2f} dB")
        print(f"   üîó Áõ∏ÂÖ≥ÊÄßÊîπËøõ: {best_quality['correlation_improvement']:+.4f}")
        print(f"   üéº È´òÈ¢ëÊîπËøõ: {best_freq['high_freq_improvement']*100:+.1f}%")
        
        # Top 3ÈÖçÁΩÆ
        sorted_results = sorted(result['all_results'], key=lambda x: x['composite_score'], reverse=True)
        print(f"\nü•á Top 3 Â¢ûÂº∫Á≥ªÊï∞:")
        for i, r in enumerate(sorted_results[:3]):
            boost = r['boost_factor']
            score = r['composite_score']
            high_freq = r['frequency_metrics']['improvements']['high_freq_improvement'] * 100
            print(f"   {i+1}. {boost}x: ÂæóÂàÜ {score:.2f}, È´òÈ¢ëÊîπËøõ {high_freq:+.1f}%")
        
        # Ë∂ãÂäøÂàÜÊûê
        print(f"\nüìà Ë∂ãÂäøÂàÜÊûê:")
        
        high_performers = [r for r in result['all_results'] if r['composite_score'] > 6.0]
        if high_performers:
            boost_range = [r['boost_factor'] for r in high_performers]
            print(f"   ‚úÖ Êé®ËçêÂ¢ûÂº∫Á≥ªÊï∞ËåÉÂõ¥: {min(boost_range):.1f}x - {max(boost_range):.1f}x")
        
        # Ê£ÄÊü•ËøáÂ∫¶Â¢ûÂº∫
        best_boost = best['boost_factor']
        over_enhanced = [r for r in result['all_results'] 
                        if r['boost_factor'] > best_boost and 
                        r['composite_score'] < best['composite_score'] * 0.9]
        
        if over_enhanced:
            min_over = min([r['boost_factor'] for r in over_enhanced])
            print(f"   ‚ö†Ô∏è ËøáÂ∫¶Â¢ûÂº∫ÈòàÂÄº: >{min_over:.1f}x ÂêéÊïàÊûú‰∏ãÈôç")
        
        print(f"\nüìÅ ËæìÂá∫Êñá‰ª∂:")
        print(f"   üìÑ ÂàÜÊûêÊä•Âëä: boost_factor_analysis_{result['timestamp']}.md")
        print(f"   üìä ÂèØËßÜÂåñÂõæË°®: boost_factor_analysis_{result['timestamp']}.png")
        
        if best['audio_paths']:
            print(f"   üéµ ÊúÄ‰Ω≥ÈÖçÁΩÆÈü≥È¢ë:")
            for name, path in best['audio_paths'].items():
                print(f"      {name}: {Path(path).name}")

def demo_simplified_optimization():
    """ÊºîÁ§∫ÁÆÄÂåñÂèÇÊï∞‰ºòÂåñ"""
    print("üéØ Step 3: ÁÆÄÂåñÂèÇÊï∞‰ºòÂåñ")
    print("=" * 50)
    
    # Ê£ÄÊü•ËæìÂÖ•Êñá‰ª∂
    input_file = "AudioLDM2_Music_output.wav"
    if not Path(input_file).exists():
        print(f"‚ùå Êâæ‰∏çÂà∞ËæìÂÖ•Êñá‰ª∂: {input_file}")
        print("ËØ∑Á°Æ‰øùAudioLDM2_Music_output.wavÂú®ÂΩìÂâçÁõÆÂΩï‰∏≠")
        return
    
    # ÂàùÂßãÂåñÁÆÄÂåñ‰ºòÂåñÂô®
    optimizer = SimpleParameterOptimizer()
    
    # ÊâßË°åÈ¢ëÁéáÂ¢ûÂº∫ÂèÇÊï∞‰ºòÂåñ
    result = optimizer.optimize_frequency_boost_parameters(input_file)
    
    print(f"\n‚úÖ ÁÆÄÂåñÂèÇÊï∞‰ºòÂåñÂÆåÊàêÔºÅ")
    print(f"üìä Êü•ÁúãËæìÂá∫ÁõÆÂΩï: simplified_parameter_optimization/")
    print(f"üéµ ËØïÂê¨‰∏çÂêåÂ¢ûÂº∫Á≥ªÊï∞ÁöÑÈü≥È¢ëÊïàÊûú")
    print(f"üìÑ Êü•ÁúãËØ¶ÁªÜÁöÑÂàÜÊûêÊä•Âëä")
    
    print(f"\nüí° ÊÄªÁªì:")
    print(f"   üéØ Êàë‰ª¨Á≥ªÁªüÊÄßÂú∞ÊµãËØï‰∫Ü‰∏çÂêåÁöÑÈ¢ëÁéáÂ¢ûÂº∫Á≥ªÊï∞")
    print(f"   üìà ÊâæÂà∞‰∫ÜË¥®ÈáèÂíåÈ´òÈ¢ëÊÅ¢Â§çÁöÑÊúÄ‰Ω≥Âπ≥Ë°°ÁÇπ")
    print(f"   üîß Áé∞Âú®ÂèØ‰ª•‰ΩøÁî®ÊúÄ‰Ω≥ÂèÇÊï∞ÈÖçÁΩÆÂ§ÑÁêÜÈü≥È¢ë")

if __name__ == "__main__":
    demo_simplified_optimization()
