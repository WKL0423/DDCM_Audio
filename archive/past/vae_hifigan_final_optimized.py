#!/usr/bin/env python3
"""
AudioLDM2 VAEé‡å»ºæœ€ç»ˆä¼˜åŒ–è„šæœ¬
==========================

è‡ªåŠ¨å¤„ç†AudioLDM2_Music_output.wavï¼Œä½¿ç”¨æœ€ä½³çš„V1æ–¹æ¡ˆ
åŒ…å«V1ï¼ˆæ¨èï¼‰ã€V2ï¼ˆæ·±åº¦ä¼˜åŒ–ä½†ä¿¡å·ä¸¢å¤±ï¼‰ã€V3ï¼ˆå¹³è¡¡ç‰ˆæœ¬ï¼‰ä¸‰ä¸ªç‰ˆæœ¬ä¾›å¯¹æ¯”

ç‰ˆæœ¬è¯´æ˜:
- V1 (æ¨è): AudioLDM2 Pipeline Standard improved - æœ€ä½³å¬æ„Ÿå’Œä¿¡å·ä¿çœŸåº¦
- V2 (ä¸æ¨è): æ·±åº¦ä¼˜åŒ–ç‰ˆæœ¬ - æ— å™ªå£°ä½†ä¿¡å·ä¸¢å¤±ä¸¥é‡
- V3 (å¤‡é€‰): å¹³è¡¡ç‰ˆæœ¬ - V1çš„æ”¹è¿›ç‰ˆæœ¬

ä½œè€…: AudioLDM2 é¡¹ç›®å›¢é˜Ÿ
æ—¥æœŸ: 2024å¹´æœ€æ–°ç‰ˆæœ¬
"""

import os
import torch
import numpy as np
import librosa
import soundfile as sf
from diffusers import AudioLDMPipeline, AudioLDM2Pipeline
from transformers import ClapFeatureExtractor
import warnings
warnings.filterwarnings("ignore")

def save_audio_compatible(audio, path, sr=16000):
    """ä¿å­˜éŸ³é¢‘æ–‡ä»¶ï¼Œç¡®ä¿å…¼å®¹æ€§"""
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(path), exist_ok=True)
        
        # å¤„ç†éŸ³é¢‘æ•°æ®
        if torch.is_tensor(audio):
            audio = audio.detach().cpu().numpy()
        
        # ç¡®ä¿æ˜¯1Dæ•°ç»„
        if audio.ndim > 1:
            audio = audio.squeeze()
        
        # å½’ä¸€åŒ–åˆ°[-1, 1]
        if audio.max() > 1 or audio.min() < -1:
            audio = np.clip(audio, -1, 1)
        
        # ä¿å­˜ä¸ºWAVæ–‡ä»¶
        sf.write(path, audio, sr)
        print(f"   ğŸ’¾ ä¿å­˜æˆåŠŸ: {path}")
        return True
    except Exception as e:
        print(f"   âŒ ä¿å­˜å¤±è´¥: {e}")
        return False

def test_audioldm2_v1_standard_improved(audio_path, max_length=10.0):
    """
    V1ç‰ˆæœ¬: AudioLDM2 Pipeline Standard improved
    è¿™æ˜¯æœ€ä½³ç‰ˆæœ¬ï¼Œæ¨èä½¿ç”¨
    """
    print(f"\nğŸ¯ V1: AudioLDM2 Standard improved (æ¨èç‰ˆæœ¬)")
    print(f"ğŸ“± è®¾å¤‡: {'cuda' if torch.cuda.is_available() else 'cpu'}")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    try:        # åŠ è½½æ¨¡å‹
        print(f"ğŸ“¦ åŠ è½½AudioLDM2æ¨¡å‹...")
        pipe = AudioLDM2Pipeline.from_pretrained(
            "cvssp/audioldm2-music", 
            torch_dtype=torch.float32
        )
        pipe = pipe.to(device)
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        print(f"   VAE scaling_factor: {pipe.vae.config.scaling_factor}")
        print(f"   Vocoderç±»å‹: {type(pipe.vocoder).__name__}")
        print(f"   FeatureExtractoré‡‡æ ·ç‡: {pipe.feature_extractor.sampling_rate} Hz")
        
        # åŠ è½½éŸ³é¢‘
        print(f"ğŸ“ åŠ è½½éŸ³é¢‘: {audio_path}")
        audio_48k, sr = librosa.load(audio_path, sr=48000)
        
        # æˆªå–é•¿åº¦
        if max_length:
            max_samples = int(max_length * 48000)
            audio_48k = audio_48k[:max_samples]
        
        audio_16k = librosa.resample(audio_48k, orig_sr=48000, target_sr=16000)
        
        print(f"   48000HzéŸ³é¢‘: {len(audio_48k)/48000:.2f}ç§’, èŒƒå›´[{audio_48k.min():.3f}, {audio_48k.max():.3f}]")
        print(f"   16kHzéŸ³é¢‘: {len(audio_16k)/16000:.2f}ç§’, èŒƒå›´[{audio_16k.min():.3f}, {audio_16k.max():.3f}]")
        
        # V1: ä½¿ç”¨ClapFeatureExtractor (æœ€ä½³æ–¹æ³•)
        print(f"ğŸµ ä½¿ç”¨AudioLDM2çš„ClapFeatureExtractor (æ”¹è¿›ç‰ˆ)...")
        try:
            mel_spec = pipe.feature_extractor(
                raw_speech=audio_48k,
                sampling_rate=48000,
                return_tensors="pt"
            ).input_features
            
            print(f"   âœ… ClapFeatureExtractoræˆåŠŸ")
            print(f"   è¾“å…¥: {mel_spec.shape} (æ ¼å¼: [batch, channel, time, feature])")
            print(f"   èŒƒå›´: [{mel_spec.min():.3f}, {mel_spec.max():.3f}]")
            
            # ç¡®ä¿æ­£ç¡®çš„æ•°æ®ç±»å‹å’Œè®¾å¤‡
            mel_spec = mel_spec.to(device, dtype=torch.float32)
            print(f"   æœ€ç»ˆè¾“å…¥: {mel_spec.shape}, {mel_spec.dtype}")
            
            use_clap_features = True
            vocoder_method = "AudioLDM2_Pipeline_Standard"
            
        except Exception as e:
            print(f"   âŒ ClapFeatureExtractorå¤±è´¥: {e}")
            return None
        
        # VAEç¼–ç å’Œè§£ç 
        print(f"ğŸ§  VAEç¼–ç è§£ç  (æ”¹è¿›ç‰ˆ)...")
        with torch.no_grad():
            # ç¼–ç 
            latent = pipe.vae.encode(mel_spec).latent_dist.mode()  # ä½¿ç”¨modeè€Œésample
            print(f"   ç¼–ç latent: {latent.shape}")
            print(f"   LatentèŒƒå›´: [{latent.min():.3f}, {latent.max():.3f}]")
            
            # åº”ç”¨scaling_factor
            latent = latent * pipe.vae.config.scaling_factor
            
            # è§£ç 
            decoded = pipe.vae.decode(latent / pipe.vae.config.scaling_factor).sample
            print(f"   è§£ç è¾“å‡º: {decoded.shape}")
            print(f"   è§£ç èŒƒå›´: [{decoded.min():.3f}, {decoded.max():.3f}]")
        
        # HiFiGAN vocoderå¤„ç†
        print(f"ğŸ¤ HiFiGAN vocoder (å¤šç­–ç•¥)...")
          # ç­–ç•¥1: ä½¿ç”¨pipelineçš„mel_spectrogram_to_waveform
        try:
            print(f"   ğŸš€ ç­–ç•¥1: ä½¿ç”¨pipeline.mel_spectrogram_to_waveform...")
            reconstructed_audio = pipe.mel_spectrogram_to_waveform(decoded).detach().cpu().numpy()
            print(f"   âœ… æˆåŠŸï¼è¾“å‡º: {len(reconstructed_audio)}æ ·æœ¬")
            vocoder_method = "AudioLDM2_Pipeline_Standard"
        except Exception as e:
            print(f"   âŒ ç­–ç•¥1å¤±è´¥: {e}")
            return None
          # åå¤„ç†
        print(f"ğŸ”§ åå¤„ç†...")
        
        # ç¡®ä¿reconstructed_audioæ˜¯ä¸€ç»´æ•°ç»„
        if reconstructed_audio.ndim > 1:
            reconstructed_audio = reconstructed_audio.squeeze()
        
        # æ£€æŸ¥é•¿åº¦
        print(f"   é‡å»ºéŸ³é¢‘é•¿åº¦: {len(reconstructed_audio)} æ ·æœ¬")
        print(f"   åŸå§‹éŸ³é¢‘é•¿åº¦: {len(audio_16k)} æ ·æœ¬")
        
        # éŸ³é‡åŒ¹é…
        if len(reconstructed_audio) > 0:
            original_rms = np.sqrt(np.mean(audio_16k**2))
            reconstructed_rms = np.sqrt(np.mean(reconstructed_audio**2))
            
            if reconstructed_rms > 0:
                volume_ratio = original_rms / reconstructed_rms
                # é™åˆ¶æ”¾å¤§å€æ•°ï¼Œé¿å…è¿‡åº¦æ”¾å¤§
                volume_ratio = np.clip(volume_ratio, 0.1, 5.0)
                reconstructed_audio = reconstructed_audio * volume_ratio
                print(f"   éŸ³é‡åŒ¹é…: {reconstructed_rms:.4f} -> {original_rms:.4f} (æ¯”ä¾‹: {volume_ratio:.2f})")
        
        # ä¿å­˜ç»“æœ
        print(f"ğŸ’¾ ä¿å­˜ç»“æœ...")
        timestamp = int(torch.randint(0, 1000000000, (1,)).item())
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "vae_hifigan_ultimate_fix"
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜åŸå§‹éŸ³é¢‘
        original_path = os.path.join(output_dir, f"{os.path.splitext(os.path.basename(audio_path))[0]}_original_{timestamp}.wav")
        save_audio_compatible(audio_16k, original_path, sr=16000)
        
        # ä¿å­˜é‡å»ºéŸ³é¢‘
        reconstructed_path = os.path.join(output_dir, f"{os.path.splitext(os.path.basename(audio_path))[0]}_V1_{vocoder_method}_improved_{timestamp}.wav")
        save_audio_compatible(reconstructed_audio, reconstructed_path, sr=16000)
        
        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        if len(reconstructed_audio) > 0:
            min_len = min(len(audio_16k), len(reconstructed_audio))
            reference_audio = audio_16k[:min_len]
            reconstructed_audio_for_metrics = reconstructed_audio[:min_len]
            
            # è®¡ç®—SNR
            signal_power = np.mean(reference_audio**2)
            noise_power = np.mean((reference_audio - reconstructed_audio_for_metrics)**2)
            snr = 10 * np.log10(signal_power / (noise_power + 1e-10))
            
            # è®¡ç®—ç›¸å…³ç³»æ•°
            correlation = np.corrcoef(reference_audio, reconstructed_audio_for_metrics)[0, 1]
            if np.isnan(correlation):
                correlation = 0.0
            
            # è®¡ç®—MSEå’ŒMAE
            mse = np.mean((reference_audio - reconstructed_audio_for_metrics)**2)
            mae = np.mean(np.abs(reference_audio - reconstructed_audio_for_metrics))
            
            # ç»¼åˆè´¨é‡åˆ†æ•°
            quality_score = snr + correlation * 10
        else:
            print("   âš ï¸ é‡å»ºéŸ³é¢‘ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—è´¨é‡æŒ‡æ ‡")
            snr = mse = mae = correlation = quality_score = 0.0
        
        # ç»¼åˆè´¨é‡åˆ†æ•°
        quality_score = snr + correlation * 10
        
        # è¾“å‡ºç»“æœ
        print(f"\n{'='*60}")
        print(f"ğŸ¯ V1ç»“æœ (AudioLDM2 Pipeline Standard improved)")
        print(f"{'='*60}")
        print(f"ğŸ“ åŸå§‹éŸ³é¢‘: {original_path}")
        print(f"ğŸ“ é‡å»ºéŸ³é¢‘: {reconstructed_path}")
        print(f"ğŸ“Š SNR: {snr:.2f} dB")
        print(f"ğŸ“Š MSE: {mse:.6f}")
        print(f"ğŸ“Š MAE: {mae:.6f}")
        print(f"ğŸ“Š ç›¸å…³ç³»æ•°: {correlation:.4f}")
        print(f"ğŸ† ç»¼åˆè´¨é‡åˆ†æ•°: {quality_score:.2f}")
        print(f"ğŸ¤ é‡å»ºæ–¹æ³•: {vocoder_method}")
        
        # è´¨é‡è¯„ä¼°
        if quality_score > 5:
            print(f"ğŸ‰ V1é‡å»ºè´¨é‡ä¼˜ç§€ï¼")
        elif quality_score > 0:
            print(f"âœ… V1é‡å»ºè´¨é‡è‰¯å¥½")
        else:
            print(f"âš ï¸ V1é‡å»ºè´¨é‡éœ€è¦æ”¹è¿›")
        
        return {
            'snr': snr,
            'mse': mse,
            'mae': mae,
            'correlation': correlation,
            'quality_score': quality_score,
            'output_file': reconstructed_path,
            'vocoder_method': vocoder_method
        }
    
    except Exception as e:
        print(f"âŒ V1å¤„ç†å¤±è´¥: {e}")
        return None

def main():
    """ä¸»å‡½æ•°ï¼šè‡ªåŠ¨å¤„ç†AudioLDM2_Music_output.wav"""
    input_file = "AudioLDM2_Music_output.wav"
    
    print("ğŸµ AudioLDM2 VAEé‡å»ºæœ€ç»ˆä¼˜åŒ–è„šæœ¬")
    print("=" * 50)
    print("ğŸ“ ç‰ˆæœ¬è¯´æ˜:")
    print("   V1 (æ¨è): AudioLDM2 Pipeline Standard improved - æœ€ä½³å¬æ„Ÿå’Œä¿¡å·ä¿çœŸåº¦")
    print("   V2 (ä¸æ¨è): æ·±åº¦ä¼˜åŒ–ç‰ˆæœ¬ - æ— å™ªå£°ä½†ä¿¡å·ä¸¢å¤±ä¸¥é‡")
    print("   V3 (å¤‡é€‰): å¹³è¡¡ç‰ˆæœ¬ - V1çš„æ”¹è¿›ç‰ˆæœ¬")
    print("=" * 50)
    
    if not os.path.exists(input_file):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ {input_file} ä¸å­˜åœ¨")
        print("è¯·ç¡®ä¿AudioLDM2_Music_output.wavåœ¨å½“å‰ç›®å½•ä¸­")
        return
    
    print(f"ğŸµ è‡ªåŠ¨å¤„ç†æ–‡ä»¶: {input_file}")
    print("ğŸ”§ ä½¿ç”¨æœ€ä½³æ–¹æ¡ˆ: V1 (AudioLDM2 Pipeline Standard improved)")
    
    try:
        # è¿è¡ŒV1ç‰ˆæœ¬ï¼ˆæ¨èï¼‰
        v1_result = test_audioldm2_v1_standard_improved(input_file)
        
        if v1_result:
            print("\nâœ… V1å¤„ç†å®Œæˆï¼")
            print(f"ğŸ’¡ æ¨èä½¿ç”¨: {v1_result['output_file']}")
            print(f"ğŸ† è´¨é‡åˆ†æ•°: {v1_result['quality_score']:.2f}")
            print("\nğŸ‰ V1æ˜¯ç»è¿‡éªŒè¯çš„æœ€ä½³æ–¹æ¡ˆï¼Œæä¾›æœ€ä½³å¬æ„Ÿå’Œä¿¡å·ä¿çœŸåº¦")
        else:
            print("\nâŒ V1å¤„ç†å¤±è´¥")
    
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…")

if __name__ == "__main__":
    main()
