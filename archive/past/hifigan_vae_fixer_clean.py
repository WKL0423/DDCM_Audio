"""
AudioLDM2 VAE + HiFiGAN ä¸“é¡¹ä¿®å¤
================================

é’ˆå¯¹HiFiGANç»´åº¦ä¸åŒ¹é…é—®é¢˜çš„ä¸“é—¨è§£å†³æ–¹æ¡ˆ
ç›®æ ‡: æˆåŠŸé›†æˆç¥ç»vocoderï¼Œçªç ´Griffin-Limçš„92%ä¿¡æ¯æŸå¤±ç“¶é¢ˆ
"""

import torch
import torchaudio
import librosa
import numpy as np
import time
from pathlib import Path
from typing import Dict, Optional
from diffusers import AudioLDM2Pipeline
from transformers import SpeechT5HifiGan
import scipy.io.wavfile
import warnings

warnings.filterwarnings("ignore")

class HiFiGANVAEFixer:
    """HiFiGAN + VAE ä¸“é¡¹ä¿®å¤å™¨"""
    
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ¯ HiFiGAN + VAE ä¸“é¡¹ä¿®å¤å™¨")
        print(f"ğŸ“± è®¾å¤‡: {self.device}")
        
        # åŠ è½½AudioLDM2
        print("ğŸ“¦ åŠ è½½AudioLDM2...")
        self.pipe = AudioLDM2Pipeline.from_pretrained(
            "cvssp/audioldm2-music",
            torch_dtype=torch.float32 if self.device.type == "cpu" else torch.float16
        ).to(self.device)
        
        self.vae = self.pipe.vae
        
        # åŠ è½½HiFiGAN
        print("ğŸ¤ åŠ è½½HiFiGAN...")
        self.hifigan = SpeechT5HifiGan.from_pretrained(
            "microsoft/speecht5_hifigan"
        ).to(self.device)
        
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def load_audio(self, audio_path: str, duration: float = 5.0) -> tuple:
        """åŠ è½½éŸ³é¢‘"""
        audio, sr = librosa.load(audio_path, sr=16000, duration=duration)
        print(f"ğŸ“Š éŸ³é¢‘: {len(audio)/sr:.2f}ç§’")
        return audio, sr
    
    def create_hifigan_compatible_mel(self, audio: np.ndarray, sr: int) -> torch.Tensor:
        """åˆ›å»ºHiFiGANå…¼å®¹çš„80ç»´melé¢‘è°±"""
        # HiFiGANä¸“ç”¨å‚æ•° (åŸºäºSpeechT5çš„æ ‡å‡†é…ç½®)
        mel_spec = librosa.feature.melspectrogram(
            y=audio,
            sr=sr,
            n_mels=80,  # HiFiGANæ ‡å‡†
            n_fft=1024,
            hop_length=256,
            win_length=1024,
            fmin=0,
            fmax=8000
        )
        
        # è½¬æ¢ä¸ºå¯¹æ•°å°ºåº¦
        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)
        
        # å½’ä¸€åŒ–åˆ°[-1, 1] (AudioLDM2 VAEæ ‡å‡†)
        mel_spec = 2.0 * (mel_spec - mel_spec.min()) / (mel_spec.max() - mel_spec.min()) - 1.0
        
        # è½¬æ¢ä¸ºtensor
        mel_tensor = torch.from_numpy(mel_spec).float().unsqueeze(0).unsqueeze(0)
        print(f"ğŸ¼ åˆ›å»º80ç»´mel: {mel_tensor.shape}")
        
        return mel_tensor.to(self.device)
    
    def vae_process(self, mel_tensor: torch.Tensor) -> torch.Tensor:
        """VAEç¼–ç è§£ç """
        with torch.no_grad():
            # æ•°æ®ç±»å‹åŒ¹é…
            if next(self.vae.parameters()).dtype == torch.float16:
                mel_tensor = mel_tensor.half()
            
            # ç¡®ä¿å°ºå¯¸æ˜¯4çš„å€æ•° (VAEè¦æ±‚)
            if mel_tensor.shape[-1] % 4 != 0:
                pad_length = 4 - (mel_tensor.shape[-1] % 4)
                mel_tensor = torch.nn.functional.pad(mel_tensor, (0, pad_length))
            
            # VAEç¼–ç è§£ç 
            latent = self.vae.encode(mel_tensor).latent_dist.sample()
            reconstructed = self.vae.decode(latent).sample
            
            print(f"ğŸ”„ VAEé‡å»º: {mel_tensor.shape} â†’ {latent.shape} â†’ {reconstructed.shape}")
            return reconstructed.float()
    
    def hifigan_vocoder_fixed(self, mel_tensor: torch.Tensor) -> np.ndarray:
        """ä¿®å¤çš„HiFiGAN vocoderè°ƒç”¨"""
        with torch.no_grad():
            # ä»VAEè¾“å‡ºæ ¼å¼è½¬æ¢ä¸ºHiFiGANè¾“å…¥æ ¼å¼
            mel_data = mel_tensor.squeeze()  # [1, 1, 80, time] â†’ [80, time]
            
            if mel_data.dim() == 3:
                mel_data = mel_data.squeeze(0)  # [1, 80, time] â†’ [80, time]
            
            print(f"ğŸ”§ HiFiGANè¾“å…¥å‡†å¤‡: {mel_data.shape}")
            
            # ç¡®ä¿æ˜¯80ç»´
            if mel_data.shape[0] != 80:
                print(f"âš ï¸ ç»´åº¦è°ƒæ•´: {mel_data.shape[0]} â†’ 80")
                mel_data = torch.nn.functional.interpolate(
                    mel_data.unsqueeze(0).unsqueeze(0),
                    size=(80, mel_data.shape[1]),
                    mode='bilinear',
                    align_corners=False
                ).squeeze(0).squeeze(0)
            
            # åå½’ä¸€åŒ– (ä»[-1,1]æ¢å¤åˆ°melå°ºåº¦)
            mel_data = (mel_data + 1.0) / 2.0  # [0, 1]
            mel_data = mel_data * 80 - 80  # [-80, 0] dBèŒƒå›´
            
            # HiFiGANéœ€è¦batchç»´åº¦: [batch, mel_bins, time]
            mel_input = mel_data.unsqueeze(0)
            print(f"ğŸ¤ HiFiGANè¾“å…¥: {mel_input.shape}")
            
            # ä½¿ç”¨HiFiGANç”ŸæˆéŸ³é¢‘
            audio_tensor = self.hifigan(mel_input)
            audio = audio_tensor.squeeze().cpu().numpy()
            
            print(f"ğŸµ HiFiGANè¾“å‡º: {audio.shape}")
            return audio
    
    def griffin_lim_baseline(self, mel_tensor: torch.Tensor, sr: int) -> np.ndarray:
        """Griffin-LimåŸºçº¿å¯¹æ¯”"""
        mel_np = mel_tensor.squeeze().cpu().numpy()
        
        # åå½’ä¸€åŒ–
        mel_np = (mel_np + 1.0) / 2.0
        mel_np = mel_np * 80 - 80  # æ¢å¤dBèŒƒå›´
        mel_linear = librosa.db_to_power(mel_np)
        
        # Griffin-Limé‡å»º
        audio = librosa.feature.inverse.mel_to_audio(
            mel_linear,
            sr=sr,
            n_iter=64,
            hop_length=256,
            win_length=1024,
            n_fft=1024
        )
        
        return audio
    
    def calculate_metrics(self, original: np.ndarray, reconstructed: np.ndarray) -> Dict:
        """è®¡ç®—éŸ³é¢‘è´¨é‡æŒ‡æ ‡"""
        min_len = min(len(original), len(reconstructed))
        orig = original[:min_len]
        recon = reconstructed[:min_len]
        
        mse = np.mean((orig - recon) ** 2)
        snr = 10 * np.log10(np.mean(orig ** 2) / (mse + 1e-8))
        correlation = np.corrcoef(orig, recon)[0, 1] if len(orig) > 1 else 0.0
        
        return {
            'mse': float(mse),
            'snr': float(snr),
            'correlation': float(correlation if not np.isnan(correlation) else 0)
        }
    
    def comprehensive_comparison(self, audio_path: str) -> Dict:
        """å…¨é¢å¯¹æ¯”æµ‹è¯•"""
        print("\nğŸ¯ HiFiGAN vs Griffin-Lim å…¨é¢å¯¹æ¯”æµ‹è¯•")
        print("="*60)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path("hifigan_vae_fix_test")
        output_dir.mkdir(exist_ok=True)
        
        # åŠ è½½éŸ³é¢‘
        audio, sr = self.load_audio(audio_path)
        
        # ä¿å­˜åŸå§‹éŸ³é¢‘
        audio_name = Path(audio_path).stem
        timestamp = int(time.time())
        original_path = output_dir / f"{audio_name}_original_{timestamp}.wav"
        scipy.io.wavfile.write(original_path, sr, (audio * 32767).astype(np.int16))
        
        results = {}
        
        print("\nğŸ§ª å¼€å§‹æµ‹è¯•æµç¨‹...")
        
        try:
            # åˆ›å»º80ç»´mel (HiFiGANå…¼å®¹)
            mel_tensor = self.create_hifigan_compatible_mel(audio, sr)
            
            # VAEé‡å»º
            print("\nğŸ”„ æ‰§è¡ŒVAEé‡å»º...")
            vae_reconstructed_mel = self.vae_process(mel_tensor)
            
            # æµ‹è¯•1: Griffin-Limé‡å»º
            print("\nğŸ“Š æµ‹è¯•1: Griffin-Limé‡å»º")
            try:
                griffin_audio = self.griffin_lim_baseline(vae_reconstructed_mel, sr)
                griffin_audio = griffin_audio / (np.max(np.abs(griffin_audio)) + 1e-8)
                griffin_metrics = self.calculate_metrics(audio, griffin_audio)
                
                griffin_file = output_dir / f"{audio_name}_griffin_lim_{timestamp}.wav"
                scipy.io.wavfile.write(griffin_file, sr, (griffin_audio * 32767).astype(np.int16))
                
                results['griffin_lim'] = {
                    'metrics': griffin_metrics,
                    'file': str(griffin_file)
                }
                
                print(f"   âœ… Griffin-Lim: SNR={griffin_metrics['snr']:.2f}dB, ç›¸å…³æ€§={griffin_metrics['correlation']:.4f}")
                
            except Exception as e:
                print(f"   âŒ Griffin-Limå¤±è´¥: {e}")
            
            # æµ‹è¯•2: HiFiGANé‡å»º
            print("\nğŸ¤ æµ‹è¯•2: HiFiGANé‡å»º")
            try:
                hifigan_audio = self.hifigan_vocoder_fixed(vae_reconstructed_mel)
                hifigan_audio = hifigan_audio / (np.max(np.abs(hifigan_audio)) + 1e-8)
                hifigan_metrics = self.calculate_metrics(audio, hifigan_audio)
                
                hifigan_file = output_dir / f"{audio_name}_hifigan_{timestamp}.wav"
                scipy.io.wavfile.write(hifigan_file, sr, (hifigan_audio * 32767).astype(np.int16))
                
                results['hifigan'] = {
                    'metrics': hifigan_metrics,
                    'file': str(hifigan_file)
                }
                
                print(f"   âœ… HiFiGAN: SNR={hifigan_metrics['snr']:.2f}dB, ç›¸å…³æ€§={hifigan_metrics['correlation']:.4f}")
                
            except Exception as e:
                print(f"   âŒ HiFiGANå¤±è´¥: {e}")
            
        except Exception as e:
            print(f"âŒ æ•´ä½“æµç¨‹å¤±è´¥: {e}")
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        self._generate_comparison_report(results, output_dir)
        
        return results
    
    def _generate_comparison_report(self, results: Dict, output_dir: Path):
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ¯ HiFiGAN vs Griffin-Lim å¯¹æ¯”ç»“æœ")
        print("="*60)
        
        if not results:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„æµ‹è¯•ç»“æœ")
            return
        
        # åŸºçº¿Griffin-Limç»“æœ
        if 'griffin_lim' in results:
            gl_metrics = results['griffin_lim']['metrics']
            print(f"\nğŸ“Š Griffin-Lim (åŸºçº¿):")
            print(f"   ğŸ“ˆ SNR: {gl_metrics['snr']:.2f}dB")
            print(f"   ğŸ”— ç›¸å…³æ€§: {gl_metrics['correlation']:.4f}")
            print(f"   ğŸ“ æ–‡ä»¶: {Path(results['griffin_lim']['file']).name}")
        
        # HiFiGANç»“æœ
        if 'hifigan' in results:
            hg_metrics = results['hifigan']['metrics']
            print(f"\nğŸ¤ HiFiGAN (ç¥ç»vocoder):")
            print(f"   ğŸ“ˆ SNR: {hg_metrics['snr']:.2f}dB")
            print(f"   ğŸ”— ç›¸å…³æ€§: {hg_metrics['correlation']:.4f}")
            print(f"   ğŸ“ æ–‡ä»¶: {Path(results['hifigan']['file']).name}")
            
            # å¯¹æ¯”åˆ†æ
            if 'griffin_lim' in results:
                snr_improvement = hg_metrics['snr'] - gl_metrics['snr']
                corr_improvement = hg_metrics['correlation'] - gl_metrics['correlation']
                
                print(f"\nğŸš€ HiFiGAN vs Griffin-Lim æ”¹è¿›:")
                print(f"   ğŸ“ˆ SNRæ”¹è¿›: {snr_improvement:+.2f}dB")
                print(f"   ğŸ”— ç›¸å…³æ€§æ”¹è¿›: {corr_improvement:+.4f}")
                
                if snr_improvement > 5:
                    print("   âœ… æ˜¾è‘—æ”¹å–„ï¼ç¥ç»vocoderæ•ˆæœæ˜æ˜¾")
                elif snr_improvement > 1:
                    print("   âœ… æœ‰æ‰€æ”¹å–„ï¼Œç¥ç»vocoderæœ‰æ•ˆ")
                else:
                    print("   âš ï¸ æ”¹å–„æœ‰é™ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        print(f"\nğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {output_dir}")
        print("ğŸ§ å»ºè®®æ’­æ”¾å¯¹æ¯”éŸ³é¢‘è¿›è¡Œä¸»è§‚è¯„ä¼°")
        
        # ä¸‹ä¸€æ­¥å»ºè®®
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        if 'hifigan' in results and results['hifigan']['metrics']['snr'] > -5:
            print("   âœ… HiFiGANé›†æˆæˆåŠŸï¼Œå¯æ¢ç´¢æ›´å¤šç¥ç»vocoder")
        else:
            print("   âš ï¸ å°è¯•å…¶ä»–ç¥ç»vocoderæ¨¡å‹")
        print("   ğŸ“ˆ è€ƒè™‘ç«¯åˆ°ç«¯é‡å»ºæ¨¡å‹")
        print("   ğŸ”§ ä¼˜åŒ–VAEå‹ç¼©å‚æ•°")

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python hifigan_vae_fixer.py <éŸ³é¢‘æ–‡ä»¶>")
        
        # åˆ—å‡ºéŸ³é¢‘æ–‡ä»¶
        audio_files = list(Path('.').glob('*.wav'))
        if audio_files:
            print("æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶:")
            for i, file in enumerate(audio_files[:3], 1):
                print(f"{i}. {file.name}")
            
            try:
                choice = int(input("é€‰æ‹©æ–‡ä»¶: "))
                audio_path = str(audio_files[choice-1])
            except:
                print("âŒ æ— æ•ˆé€‰æ‹©")
                return
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
            return
    else:
        audio_path = sys.argv[1]
    
    # è¿è¡Œä¿®å¤æµ‹è¯•
    fixer = HiFiGANVAEFixer()
    results = fixer.comprehensive_comparison(audio_path)
    
    print("\nâœ… HiFiGANä¸“é¡¹ä¿®å¤æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()
