"""
AudioLDM2 VAE ç«‹å³æ”¹è¿›ç‰ˆæœ¬
=========================

åŸºäºç“¶é¢ˆåˆ†æçš„å¿«é€Ÿä¼˜åŒ–æ–¹æ¡ˆ
ç›®æ ‡: åœ¨ç°æœ‰æ¶æ„ä¸‹æœ€å¤§åŒ–é‡å»ºè´¨é‡
"""

import torch
import librosa
import numpy as np
import time
from pathlib import Path
from diffusers import AudioLDM2Pipeline
import scipy.io.wavfile
import scipy.signal
import warnings

warnings.filterwarnings("ignore")

class VAEQuickImprover:
    """VAEå¿«é€Ÿæ”¹è¿›å™¨ - åœ¨ç°æœ‰é™åˆ¶ä¸‹æœ€å¤§åŒ–è´¨é‡"""
    
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"âš¡ VAEå¿«é€Ÿæ”¹è¿›å™¨å¯åŠ¨")
        print(f"ğŸ“± è®¾å¤‡: {self.device}")
        
        # åŠ è½½AudioLDM2
        self.pipe = AudioLDM2Pipeline.from_pretrained(
            "cvssp/audioldm2-music",
            torch_dtype=torch.float32 if self.device.type == "cpu" else torch.float16
        ).to(self.device)
        
        self.vae = self.pipe.vae
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def load_audio(self, audio_path: str, duration: float = 5.0):
        """åŠ è½½éŸ³é¢‘"""
        audio, sr = librosa.load(audio_path, sr=16000, duration=duration)
        print(f"ğŸ“Š éŸ³é¢‘: {len(audio)/sr:.2f}ç§’")
        return audio, sr
    
    def create_optimal_mel(self, audio: np.ndarray, sr: int, enhanced: bool = True):
        """åˆ›å»ºä¼˜åŒ–çš„melé¢‘è°±"""
        if enhanced:
            # é«˜è´¨é‡é…ç½®
            mel_spec = librosa.feature.melspectrogram(
                y=audio, sr=sr, n_mels=80, n_fft=2048,
                hop_length=256, win_length=1024, fmin=0, fmax=8000
            )
        else:
            # æ ‡å‡†é…ç½®
            mel_spec = librosa.feature.melspectrogram(
                y=audio, sr=sr, n_mels=80, n_fft=1024,
                hop_length=256, win_length=1024, fmin=0, fmax=8000
            )
        
        # åŠ¨æ€èŒƒå›´ä¼˜åŒ–
        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)
        
        # æ”¹è¿›çš„å½’ä¸€åŒ–ï¼ˆä¿ç•™æ›´å¤šåŠ¨æ€ä¿¡æ¯ï¼‰
        mel_spec = np.clip(mel_spec, -80, 0)  # é™åˆ¶èŒƒå›´
        mel_spec = 2.0 * (mel_spec + 80) / 80 - 1.0  # å½’ä¸€åŒ–åˆ°[-1,1]
        
        mel_tensor = torch.from_numpy(mel_spec).float().unsqueeze(0).unsqueeze(0)
        return mel_tensor.to(self.device)
    
    def vae_reconstruct(self, mel_tensor):
        """VAEé‡å»º"""
        with torch.no_grad():
            if next(self.vae.parameters()).dtype == torch.float16:
                mel_tensor = mel_tensor.half()
            
            # ç¡®ä¿å°ºå¯¸åŒ¹é…
            if mel_tensor.shape[-1] % 4 != 0:
                pad_length = 4 - (mel_tensor.shape[-1] % 4)
                mel_tensor = torch.nn.functional.pad(mel_tensor, (0, pad_length))
            
            # VAEç¼–ç è§£ç 
            latent = self.vae.encode(mel_tensor).latent_dist.sample()
            reconstructed = self.vae.decode(latent).sample
            
            return reconstructed.float()
    
    def enhanced_griffin_lim(self, mel_tensor, sr: int = 16000, method: str = "advanced"):
        """å¢å¼ºçš„Griffin-Limç®—æ³•"""
        mel_np = mel_tensor.squeeze().cpu().numpy()
        
        # åå½’ä¸€åŒ–ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        mel_np = (mel_np + 1.0) / 2.0 * 80 - 80  # æ¢å¤åˆ°[-80, 0]èŒƒå›´
        mel_linear = librosa.db_to_power(mel_np)
        
        if method == "basic":
            # åŸºç¡€ç‰ˆæœ¬
            audio = librosa.feature.inverse.mel_to_audio(
                mel_linear, sr=sr, n_iter=64,
                hop_length=256, win_length=1024, n_fft=1024
            )
        elif method == "advanced":
            # é«˜çº§ç‰ˆæœ¬ - æ›´å¤šè¿­ä»£
            audio = librosa.feature.inverse.mel_to_audio(
                mel_linear, sr=sr, n_iter=128,
                hop_length=256, win_length=1024, n_fft=1024
            )
        elif method == "premium":
            # é¡¶çº§ç‰ˆæœ¬ - æœ€å¤šè¿­ä»£å’Œæ›´å¥½å‚æ•°
            audio = librosa.feature.inverse.mel_to_audio(
                mel_linear, sr=sr, n_iter=256,
                hop_length=256, win_length=1024, n_fft=2048
            )
        
        return audio
    
    def post_process_audio(self, audio: np.ndarray, method: str = "enhanced"):
        """éŸ³é¢‘åå¤„ç†"""
        if method == "basic":
            # åŸºç¡€åå¤„ç†ï¼šå½’ä¸€åŒ–
            audio = audio / (np.max(np.abs(audio)) + 1e-8)
            
        elif method == "enhanced":
            # å¢å¼ºåå¤„ç†
            # 1. è½¯é™å¹…
            audio = np.tanh(audio * 1.2) * 0.9
            
            # 2. è½»å¾®å»å™ªï¼ˆç»´çº³æ»¤æ³¢ï¼‰
            try:
                audio = scipy.signal.wiener(audio, mysize=5)
            except:
                pass  # å¦‚æœæ»¤æ³¢å¤±è´¥ï¼Œè·³è¿‡
            
            # 3. å½’ä¸€åŒ–
            audio = audio / (np.max(np.abs(audio)) + 1e-8)
            
        elif method == "premium":
            # é¡¶çº§åå¤„ç†
            # 1. åŠ¨æ€èŒƒå›´å‹ç¼©
            audio = np.sign(audio) * np.power(np.abs(audio), 0.8)
            
            # 2. é«˜é€šæ»¤æ³¢ï¼ˆå»é™¤ä½é¢‘å™ªå£°ï¼‰
            try:
                from scipy import signal
                b, a = signal.butter(3, 80, 'high', fs=16000)
                audio = signal.filtfilt(b, a, audio)
            except:
                pass
            
            # 3. è½¯é™å¹…å’Œå½’ä¸€åŒ–
            audio = np.tanh(audio * 1.5) * 0.85
            audio = audio / (np.max(np.abs(audio)) + 1e-8)
        
        return audio
    
    def calculate_metrics(self, original, reconstructed):
        """è®¡ç®—è´¨é‡æŒ‡æ ‡"""
        min_len = min(len(original), len(reconstructed))
        orig = original[:min_len]
        recon = reconstructed[:min_len]
        
        mse = np.mean((orig - recon) ** 2)
        snr = 10 * np.log10(np.mean(orig ** 2) / (mse + 1e-8))
        correlation = np.corrcoef(orig, recon)[0, 1] if len(orig) > 1 else 0.0
        
        return {
            'mse': float(mse),
            'snr': float(snr),
            'correlation': float(correlation if not np.isnan(correlation) else 0)
        }
    
    def comprehensive_improvement_test(self, audio_path: str):
        """å…¨é¢æ”¹è¿›æµ‹è¯•"""
        print("\nâš¡ VAEå¿«é€Ÿæ”¹è¿›æµ‹è¯•")
        print("="*50)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path("vae_quick_improvement_test")
        output_dir.mkdir(exist_ok=True)
        
        # åŠ è½½éŸ³é¢‘
        audio, sr = self.load_audio(audio_path)
        
        # ä¿å­˜åŸå§‹éŸ³é¢‘
        audio_name = Path(audio_path).stem
        timestamp = int(time.time())
        original_path = output_dir / f"{audio_name}_original_{timestamp}.wav"
        scipy.io.wavfile.write(original_path, sr, (audio * 32767).astype(np.int16))
        
        results = {}
        
        # æµ‹è¯•é…ç½®
        test_configs = [
            {"name": "baseline", "mel": False, "griffin": "basic", "post": "basic"},
            {"name": "enhanced_mel", "mel": True, "griffin": "basic", "post": "basic"},
            {"name": "enhanced_griffin", "mel": False, "griffin": "advanced", "post": "basic"},
            {"name": "enhanced_post", "mel": False, "griffin": "basic", "post": "enhanced"},
            {"name": "all_enhanced", "mel": True, "griffin": "advanced", "post": "enhanced"},
            {"name": "premium", "mel": True, "griffin": "premium", "post": "premium"},
        ]
        
        print(f"\nğŸ§ª æµ‹è¯• {len(test_configs)} ç§æ”¹è¿›é…ç½®...")
        
        for i, config in enumerate(test_configs):
            print(f"\nğŸ“Š é…ç½® {i+1}: {config['name']}")
            
            try:
                # åˆ›å»ºmelé¢‘è°±
                mel_tensor = self.create_optimal_mel(audio, sr, config['mel'])
                
                # VAEé‡å»º
                reconstructed_mel = self.vae_reconstruct(mel_tensor)
                
                # Griffin-Limé‡å»º
                audio_recon = self.enhanced_griffin_lim(
                    reconstructed_mel, sr, config['griffin']
                )
                
                # åå¤„ç†
                final_audio = self.post_process_audio(audio_recon, config['post'])
                
                # è®¡ç®—æŒ‡æ ‡
                metrics = self.calculate_metrics(audio, final_audio)
                
                # ä¿å­˜ç»“æœ
                output_file = output_dir / f"{audio_name}_{config['name']}_{timestamp}.wav"
                scipy.io.wavfile.write(output_file, sr, (final_audio * 32767).astype(np.int16))
                
                results[config['name']] = {
                    'metrics': metrics,
                    'file': str(output_file),
                    'config': config
                }
                
                print(f"   âœ… SNR: {metrics['snr']:.2f}dB, ç›¸å…³æ€§: {metrics['correlation']:.4f}")
                
            except Exception as e:
                print(f"   âŒ é…ç½®å¤±è´¥: {e}")
                continue
        
        # ç”Ÿæˆæ”¹è¿›æŠ¥å‘Š
        self._generate_improvement_report(results, output_dir)
        
        return results
    
    def _generate_improvement_report(self, results, output_dir):
        """ç”Ÿæˆæ”¹è¿›æŠ¥å‘Š"""
        print("\n" + "="*50)
        print("âš¡ VAEå¿«é€Ÿæ”¹è¿›æµ‹è¯•ç»“æœ")
        print("="*50)
        
        if not results:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„æµ‹è¯•ç»“æœ")
            return
        
        # æŒ‰SNRæ’åº
        sorted_results = sorted(
            results.items(),
            key=lambda x: x[1]['metrics']['snr'],
            reverse=True
        )
        
        baseline_snr = None
        if 'baseline' in results:
            baseline_snr = results['baseline']['metrics']['snr']
        
        print(f"\nğŸ† æ”¹è¿›æ•ˆæœæ’å:")
        for i, (config_name, data) in enumerate(sorted_results):
            metrics = data['metrics']
            config = data['config']
            
            improvement = metrics['snr'] - baseline_snr if baseline_snr else 0
            
            print(f"   #{i+1} {config_name}")
            print(f"       ğŸ“ˆ SNR: {metrics['snr']:.2f}dB ({improvement:+.2f})")
            print(f"       ğŸ”— ç›¸å…³æ€§: {metrics['correlation']:.4f}")
            print(f"       ğŸ“ æ–‡ä»¶: {Path(data['file']).name}")
        
        # æœ€ä½³æ”¹è¿›åˆ†æ
        if len(sorted_results) > 0:
            best_config = sorted_results[0][1]['config']
            best_snr = sorted_results[0][1]['metrics']['snr']
            
            print(f"\nğŸš€ æœ€ä½³æ”¹è¿›ç»„åˆ: {sorted_results[0][0]}")
            if baseline_snr:
                total_improvement = best_snr - baseline_snr
                print(f"   ğŸ“ˆ æ€»ä½“SNRæå‡: {total_improvement:+.2f}dB")
            
            # åˆ†ææœ‰æ•ˆçš„æ”¹è¿›æ–¹æ³•
            print(f"\nğŸ’¡ æœ‰æ•ˆæ”¹è¿›æ–¹æ³•:")
            if best_config['mel']:
                print("   âœ… é«˜è´¨é‡melé…ç½®æœ‰æ•ˆ")
            if best_config['griffin'] != 'basic':
                print("   âœ… å¢å¼ºGriffin-Limæœ‰æ•ˆ")
            if best_config['post'] != 'basic':
                print("   âœ… éŸ³é¢‘åå¤„ç†æœ‰æ•ˆ")
        
        print(f"\nğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {output_dir}")
        print("ğŸ§ å»ºè®®æ’­æ”¾æœ€ä½³ç»“æœè¿›è¡Œä¸»è§‚è¯„ä¼°")
        
        # ä¸‹ä¸€æ­¥å»ºè®®
        print(f"\nğŸ¯ è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®:")
        best_snr = sorted_results[0][1]['metrics']['snr'] if sorted_results else -10
        if best_snr > 0:
            print("   âœ… å·²è¾¾åˆ°å¯ç”¨æ°´å¹³ï¼Œç»§ç»­ç²¾ç»†è°ƒä¼˜")
        elif best_snr > -3:
            print("   ğŸ”§ æ¥è¿‘å¯ç”¨æ°´å¹³ï¼Œå°è¯•æ›´æ¿€è¿›çš„ä¼˜åŒ–")
        else:
            print("   âš ï¸ ä»éœ€æ¶æ„çº§æ”¹è¿› (ç¥ç»vocoderç­‰)")

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python vae_quick_improver.py <éŸ³é¢‘æ–‡ä»¶>")
        
        audio_files = list(Path('.').glob('*.wav'))
        if audio_files:
            print("æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶:")
            for i, file in enumerate(audio_files[:3], 1):
                print(f"{i}. {file.name}")
            
            try:
                choice = int(input("é€‰æ‹©æ–‡ä»¶: "))
                audio_path = str(audio_files[choice-1])
            except:
                print("âŒ æ— æ•ˆé€‰æ‹©")
                return
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
            return
    else:
        audio_path = sys.argv[1]
    
    # è¿è¡Œæ”¹è¿›æµ‹è¯•
    improver = VAEQuickImprover()
    results = improver.comprehensive_improvement_test(audio_path)
    
    print("\nâœ… VAEå¿«é€Ÿæ”¹è¿›æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()
