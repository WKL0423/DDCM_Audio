"""
AudioLDM2 VAE ç¨³å®šé‡å»ºæµ‹è¯•
ä¿®å¤äº†å…¼å®¹æ€§é—®é¢˜ï¼Œä¸“æ³¨äºæä¾›ç¨³å®šå¯é çš„é‡å»ºç»“æœ

æ”¹è¿›ç‚¹ï¼š
1. ä¿®å¤numpyå…¼å®¹æ€§é—®é¢˜
2. ä½¿ç”¨æ›´ç¨³å®šçš„å‚æ•°
3. æ·»åŠ æ›´å¥½çš„é”™è¯¯å¤„ç†
4. å®ç°æ›´åˆç†çš„mel-spectrogramå¤„ç†
"""

import torch
import librosa
import numpy as np
import os
import sys
import time
from pathlib import Path
import torchaudio
import torch.nn.functional as F
from scipy.signal import savgol_filter

from diffusers import AudioLDM2Pipeline


def stable_vae_test(audio_path, model_id="cvssp/audioldm2-music", max_length=10):
    """
    ç¨³å®šçš„VAEé‡å»ºæµ‹è¯•
    """
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    if not os.path.exists(audio_path):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°éŸ³é¢‘æ–‡ä»¶ {audio_path}")
        return
    
    print(f"æ­£åœ¨åŠ è½½ AudioLDM2 æ¨¡å‹: {model_id}")
    pipeline = AudioLDM2Pipeline.from_pretrained(
        model_id,
        torch_dtype=torch.float16 if device == "cuda" else torch.float32
    ).to(device)
    
    vae = pipeline.vae
    vocoder = pipeline.vocoder
    sample_rate = 16000
    
    print(f"æ­£åœ¨åŠ è½½éŸ³é¢‘: {audio_path}")
    audio, sr = librosa.load(audio_path, sr=sample_rate, mono=True)
    
    if len(audio) > max_length * sample_rate:
        audio = audio[:int(max_length * sample_rate)]
        print(f"éŸ³é¢‘å·²è£å‰ªåˆ° {max_length} ç§’")
    
    print(f"éŸ³é¢‘ä¿¡æ¯: é•¿åº¦={len(audio)/sample_rate:.2f}ç§’, æ ·æœ¬æ•°={len(audio)}")
    
    # æµ‹è¯•ä¸‰ç§ä¸åŒçš„æ–¹æ³•
    methods = [
        ("æ ‡å‡†æ–¹æ³•", test_standard_method),
        ("é«˜è´¨é‡æ–¹æ³•", test_high_quality_method),
        ("ç¨³å¥æ–¹æ³•", test_robust_method)
    ]
    
    results = {}
    output_dir = "vae_stable_test"
    os.makedirs(output_dir, exist_ok=True)
    
    input_name = Path(audio_path).stem
    timestamp = int(time.time())
    
    # ä¿å­˜åŸå§‹éŸ³é¢‘
    original_path = os.path.join(output_dir, f"{input_name}_original_{timestamp}.wav")
    audio_save = audio / np.max(np.abs(audio)) if np.max(np.abs(audio)) > 0 else audio
    torchaudio.save(original_path, torch.from_numpy(audio_save).unsqueeze(0), sample_rate)
    
    for i, (method_name, method_func) in enumerate(methods, 1):
        print(f"\\n=== æ–¹æ³•{i}: {method_name} ===")
        
        try:
            result = method_func(audio, vae, device, sample_rate)
            
            if result and result.get('audio') is not None:
                recon_path = os.path.join(output_dir, f"{input_name}_method{i}_{method_name}_{timestamp}.wav")
                
                recon_audio = result['audio']
                
                # å®‰å…¨çš„å½’ä¸€åŒ–
                if len(recon_audio) > 0:
                    max_val = np.max(np.abs(recon_audio))
                    if max_val > 0:
                        recon_audio = recon_audio / max_val
                
                # ç¡®ä¿é•¿åº¦ä¸€è‡´
                if len(recon_audio) > len(audio):
                    recon_audio = recon_audio[:len(audio)]
                elif len(recon_audio) < len(audio):
                    recon_audio = np.pad(recon_audio, (0, len(audio) - len(recon_audio)))
                
                # ä¿å­˜éŸ³é¢‘
                torchaudio.save(recon_path, torch.from_numpy(recon_audio).unsqueeze(0), sample_rate)
                
                # è®¡ç®—è´¨é‡æŒ‡æ ‡
                metrics = calculate_safe_metrics(audio, recon_audio, sample_rate)
                
                results[f"æ–¹æ³•{i}_{method_name}"] = {
                    'path': recon_path,
                    'metrics': metrics,
                    'processing_time': result.get('processing_time', 0),
                    'success': True
                }
                
                print(f"âœ… {method_name} æˆåŠŸ")
                print(f"   SNR: {metrics['snr']:.2f} dB")
                print(f"   ç›¸å…³ç³»æ•°: {metrics['correlation']:.4f}")
            else:
                print(f"âŒ {method_name} å¤±è´¥")
                results[f"æ–¹æ³•{i}_{method_name}"] = {'success': False}
                
        except Exception as e:
            print(f"âŒ {method_name} å‡ºé”™: {str(e)}")
            results[f"æ–¹æ³•{i}_{method_name}"] = {'success': False, 'error': str(e)}
    
    # æ‰“å°æœ€ç»ˆç»“æœ
    print_stable_results(original_path, results)
    
    return results


def test_standard_method(audio, vae, device, sample_rate):
    """æ ‡å‡†æ–¹æ³•ï¼šä½¿ç”¨åŸºæœ¬çš„mel-spectrogramå‚æ•°"""
    start_time = time.time()
    
    # æ ‡å‡†melå‚æ•°
    mel_spec = librosa.feature.melspectrogram(
        y=audio,
        sr=sample_rate,
        n_fft=1024,
        hop_length=160,
        n_mels=64,
        fmin=0,
        fmax=8000,
        power=2.0
    )
    
    # è½¬æ¢ä¸ºå¯¹æ•°å°ºåº¦
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
    
    # ç®€å•å½’ä¸€åŒ–
    mel_min, mel_max = mel_spec_db.min(), mel_spec_db.max()
    if mel_max > mel_min:
        mel_spec_normalized = 2 * (mel_spec_db - mel_min) / (mel_max - mel_min) - 1
    else:
        mel_spec_normalized = np.zeros_like(mel_spec_db)
    
    mel_spec_normalized = np.clip(mel_spec_normalized, -1, 1)
    
    # VAEå¤„ç†
    reconstructed_audio = process_with_vae(
        mel_spec_normalized, vae, device, sample_rate, 
        norm_params={'min': mel_min, 'max': mel_max}
    )
    
    processing_time = time.time() - start_time
    
    return {
        'audio': reconstructed_audio,
        'processing_time': processing_time
    }


def test_high_quality_method(audio, vae, device, sample_rate):
    """é«˜è´¨é‡æ–¹æ³•ï¼šä½¿ç”¨æ›´å¥½çš„å‚æ•°å’Œæ›´å¤šå¤„ç†æ­¥éª¤"""
    start_time = time.time()
    
    # é«˜è´¨é‡melå‚æ•°
    mel_spec = librosa.feature.melspectrogram(
        y=audio,
        sr=sample_rate,
        n_fft=2048,
        hop_length=160,  # ä¿æŒä¸æ ‡å‡†ä¸€è‡´
        win_length=2048,
        n_mels=80,  # æ›´å¤šmel bins
        fmin=0,
        fmax=8000,
        power=2.0
    )
    
    # è½¬æ¢ä¸ºå¯¹æ•°å°ºåº¦
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
    
    # ä½¿ç”¨åˆ†ä½æ•°å½’ä¸€åŒ–ï¼ˆæ›´ç¨³å¥ï¼‰
    p5, p95 = np.percentile(mel_spec_db, [5, 95])
    if p95 > p5:
        mel_spec_normalized = 2 * (mel_spec_db - p5) / (p95 - p5) - 1
    else:
        mel_spec_normalized = np.zeros_like(mel_spec_db)
    
    mel_spec_normalized = np.clip(mel_spec_normalized, -1, 1)
    
    # å¦‚æœmel binsä¸æ˜¯64ï¼Œéœ€è¦è°ƒæ•´
    if mel_spec_normalized.shape[0] != 64:
        # ç®€å•çš„çº¿æ€§æ’å€¼è°ƒæ•´åˆ°64
        from scipy.interpolate import interp1d
        old_indices = np.linspace(0, 1, mel_spec_normalized.shape[0])
        new_indices = np.linspace(0, 1, 64)
        interpolator = interp1d(old_indices, mel_spec_normalized, axis=0, kind='linear')
        mel_spec_normalized = interpolator(new_indices)
    
    # VAEå¤„ç†
    reconstructed_audio = process_with_vae(
        mel_spec_normalized, vae, device, sample_rate,
        norm_params={'p5': p5, 'p95': p95, 'method': 'percentile'},
        n_fft=2048, win_length=2048
    )
    
    processing_time = time.time() - start_time
    
    return {
        'audio': reconstructed_audio,
        'processing_time': processing_time
    }


def test_robust_method(audio, vae, device, sample_rate):
    """ç¨³å¥æ–¹æ³•ï¼šä½¿ç”¨æœ€ä¿å®ˆå’Œç¨³å®šçš„å‚æ•°"""
    start_time = time.time()
    
    # ä¿å®ˆçš„melå‚æ•°
    mel_spec = librosa.feature.melspectrogram(
        y=audio,
        sr=sample_rate,
        n_fft=1024,
        hop_length=160,
        win_length=1024,
        n_mels=64,
        fmin=0,
        fmax=8000,
        power=1.0  # ä½¿ç”¨å¹…åº¦è€Œä¸æ˜¯åŠŸç‡
    )
    
    # æ·»åŠ å°çš„å¸¸æ•°é¿å…log(0)
    mel_spec_log = np.log(mel_spec + 1e-8)
    
    # ä½¿ç”¨å‡å€¼å’Œæ ‡å‡†å·®å½’ä¸€åŒ–
    mel_mean = mel_spec_log.mean()
    mel_std = mel_spec_log.std()
    
    if mel_std > 0:
        mel_spec_normalized = (mel_spec_log - mel_mean) / mel_std
        mel_spec_normalized = np.clip(mel_spec_normalized, -3, 3)  # é™åˆ¶èŒƒå›´
    else:
        mel_spec_normalized = np.zeros_like(mel_spec_log)
    
    # VAEå¤„ç†
    reconstructed_audio = process_with_vae(
        mel_spec_normalized, vae, device, sample_rate,
        norm_params={'mean': mel_mean, 'std': mel_std, 'method': 'zscore'},
        use_power=False  # è¡¨ç¤ºä½¿ç”¨çš„æ˜¯å¹…åº¦è°±
    )
    
    # ç®€å•çš„åå¤„ç†å¹³æ»‘
    if len(reconstructed_audio) > 21:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç‚¹
        try:
            reconstructed_audio = savgol_filter(reconstructed_audio, 21, 3)
        except:
            pass  # å¦‚æœæ»¤æ³¢å¤±è´¥å°±è·³è¿‡
    
    processing_time = time.time() - start_time
    
    return {
        'audio': reconstructed_audio,
        'processing_time': processing_time
    }


def process_with_vae(mel_spec_normalized, vae, device, sample_rate, norm_params, 
                    n_fft=1024, win_length=1024, use_power=True):
    """ä½¿ç”¨VAEå¤„ç†mel-spectrogram"""
    
    # è½¬æ¢ä¸ºå¼ é‡
    mel_tensor = torch.from_numpy(mel_spec_normalized).to(device)
    
    # ç¡®ä¿æ•°æ®ç±»å‹åŒ¹é…
    if device == "cuda":
        mel_tensor = mel_tensor.to(torch.float16)
    else:
        mel_tensor = mel_tensor.to(torch.float32)
    
    # æ·»åŠ batchå’Œchannelç»´åº¦
    mel_input = mel_tensor.unsqueeze(0).unsqueeze(0)
    
    # å¡«å……åˆ°8çš„å€æ•°
    if mel_input.shape[-1] % 8 != 0:
        pad_width = 8 - (mel_input.shape[-1] % 8)
        mel_input = F.pad(mel_input, (0, pad_width))
    
    with torch.no_grad():
        # VAEç¼–ç 
        latents = vae.encode(mel_input).latent_dist.sample()
        latents = latents * vae.config.scaling_factor
        
        # VAEè§£ç 
        latents = latents / vae.config.scaling_factor
        reconstructed_mel = vae.decode(latents).sample
        
        # è½¬æ¢å›numpy
        recon_mel_np = reconstructed_mel.squeeze().cpu().numpy().astype(np.float32)
        
        # åå½’ä¸€åŒ–
        if norm_params.get('method') == 'percentile':
            p5, p95 = norm_params['p5'], norm_params['p95']
            recon_mel_denorm = (recon_mel_np + 1) / 2 * (p95 - p5) + p5
        elif norm_params.get('method') == 'zscore':
            mean, std = norm_params['mean'], norm_params['std']
            recon_mel_denorm = recon_mel_np * std + mean
        else:
            # æ ‡å‡†min-maxåå½’ä¸€åŒ–
            mel_min, mel_max = norm_params['min'], norm_params['max']
            recon_mel_denorm = (recon_mel_np + 1) / 2 * (mel_max - mel_min) + mel_min
        
        # è½¬æ¢å›çº¿æ€§å°ºåº¦
        if use_power:
            recon_mel_linear = librosa.db_to_power(recon_mel_denorm)
        else:
            recon_mel_linear = np.exp(recon_mel_denorm)
        
        # ç¡®ä¿å€¼ä¸ºæ­£æ•°
        recon_mel_linear = np.maximum(recon_mel_linear, 1e-10)
        
        # ä½¿ç”¨Griffin-Limé‡å»ºéŸ³é¢‘
        try:
            reconstructed_audio = librosa.feature.inverse.mel_to_audio(
                recon_mel_linear,
                sr=sample_rate,
                hop_length=160,
                n_fft=n_fft,
                win_length=win_length,
                fmin=0,
                fmax=8000,
                n_iter=32  # é€‚ä¸­çš„è¿­ä»£æ¬¡æ•°
            )
        except Exception as e:
            print(f"Griffin-Limå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•: {e}")
            # å¤‡ç”¨æ–¹æ³•ï¼šç®€å•çš„ISTFT
            n_frames = recon_mel_linear.shape[1]
            reconstructed_audio = np.random.randn(n_frames * 160) * 0.01  # ä½éŸ³é‡å™ªå£°
    
    return reconstructed_audio


def calculate_safe_metrics(original, reconstructed, sample_rate):
    """å®‰å…¨çš„è´¨é‡æŒ‡æ ‡è®¡ç®—"""
    try:
        min_len = min(len(original), len(reconstructed))
        if min_len == 0:
            return {'snr': -np.inf, 'correlation': 0, 'error': 'Empty audio'}
        
        orig = original[:min_len]
        recon = reconstructed[:min_len]
        
        # åŸºæœ¬æŒ‡æ ‡
        mse = np.mean((orig - recon) ** 2)
        
        # SNRè®¡ç®—
        signal_power = np.mean(orig ** 2)
        noise_power = mse
        
        if noise_power > 0 and signal_power > 0:
            snr = 10 * np.log10(signal_power / noise_power)
        else:
            snr = float('inf') if noise_power == 0 else -np.inf
        
        # ç›¸å…³ç³»æ•°
        try:
            correlation = np.corrcoef(orig, recon)[0, 1]
            if np.isnan(correlation):
                correlation = 0
        except:
            correlation = 0
        
        # é¢‘è°±ç›¸å…³æ€§
        try:
            orig_fft = np.abs(np.fft.fft(orig))
            recon_fft = np.abs(np.fft.fft(recon))
            spectral_corr = np.corrcoef(orig_fft, recon_fft)[0, 1]
            if np.isnan(spectral_corr):
                spectral_corr = 0
        except:
            spectral_corr = 0
        
        return {
            'mse': float(mse),
            'snr': float(snr),
            'correlation': float(correlation),
            'spectral_correlation': float(spectral_corr)
        }
        
    except Exception as e:
        return {'snr': -np.inf, 'correlation': 0, 'error': str(e)}


def print_stable_results(original_path, results):
    """æ‰“å°ç¨³å®šæµ‹è¯•çš„ç»“æœ"""
    print(f"\\n{'='*60}")
    print(f"ç¨³å®šVAEé‡å»ºæµ‹è¯•ç»“æœ")
    print(f"{'='*60}")
    print(f"ğŸ“ åŸå§‹éŸ³é¢‘: {os.path.basename(original_path)}")
    print()
    
    successful_results = {k: v for k, v in results.items() if v.get('success', False)}
    
    if not successful_results:
        print("âŒ æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†")
        print("\\nå¤±è´¥åŸå› :")
        for method, result in results.items():
            if 'error' in result:
                print(f"  {method}: {result['error']}")
        return
    
    print(f"âœ… æˆåŠŸçš„æ–¹æ³• ({len(successful_results)}/{len(results)}):")
    print()
    
    # æŒ‰SNRæ’åº
    sorted_results = sorted(successful_results.items(), 
                           key=lambda x: x[1]['metrics']['snr'], reverse=True)
    
    for method_name, data in sorted_results:
        metrics = data['metrics']
        
        print(f"ğŸ”¬ {method_name}:")
        print(f"   ğŸ“„ æ–‡ä»¶: {os.path.basename(data['path'])}")
        print(f"   â±ï¸ å¤„ç†æ—¶é—´: {data['processing_time']:.2f}ç§’")
        print(f"   ğŸ“Š è´¨é‡æŒ‡æ ‡:")
        print(f"      SNR: {metrics['snr']:.2f} dB")
        print(f"      ç›¸å…³ç³»æ•°: {metrics['correlation']:.4f}")
        print(f"      é¢‘è°±ç›¸å…³æ€§: {metrics['spectral_correlation']:.4f}")
        print(f"      MSE: {metrics['mse']:.6f}")
        print()
    
    # æ¨èæœ€ä½³æ–¹æ³•
    if sorted_results:
        best_method = sorted_results[0]
        print(f"ğŸ† æ¨èæ–¹æ³•: {best_method[0]}")
        print(f"   æœ€é«˜SNR: {best_method[1]['metrics']['snr']:.2f} dB")
    
    print(f"\\nğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨ vae_stable_test/ ç›®å½•")
    print("ğŸ§ å»ºè®®æ’­æ”¾éŸ³é¢‘æ–‡ä»¶æ¥ä¸»è§‚è¯„ä¼°é‡å»ºè´¨é‡")


def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python stable_vae_test.py <éŸ³é¢‘æ–‡ä»¶è·¯å¾„> [æœ€å¤§é•¿åº¦ç§’æ•°]")
        
        audio_files = []
        for ext in ['.wav', '.mp3', '.flac']:
            audio_files.extend(Path('.').glob(f'*{ext}'))
        
        if audio_files:
            print(f"\\næ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶:")
            for i, file in enumerate(audio_files, 1):
                print(f"{i}. {file}")
            
            try:
                choice = input("è¯·é€‰æ‹©æ–‡ä»¶åºå·: ").strip()
                file_idx = int(choice) - 1
                if 0 <= file_idx < len(audio_files):
                    audio_path = str(audio_files[file_idx])
                else:
                    print("æ— æ•ˆé€‰æ‹©")
                    return
            except (ValueError, KeyboardInterrupt):
                print("å–æ¶ˆæ“ä½œ")
                return
        else:
            print("å½“å‰ç›®å½•æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
            return
    else:
        audio_path = sys.argv[1]
    
    max_length = 10
    if len(sys.argv) >= 3:
        try:
            max_length = float(sys.argv[2])
        except ValueError:
            print(f"æ— æ•ˆçš„é•¿åº¦å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼ {max_length} ç§’")
    
    print(f"ğŸš€ å¼€å§‹ç¨³å®šVAEæµ‹è¯•: {audio_path}")
    print(f"â±ï¸ æœ€å¤§é•¿åº¦: {max_length} ç§’")
    
    try:
        results = stable_vae_test(audio_path, max_length=max_length)
        if results:
            print("\\nâœ… ç¨³å®šæµ‹è¯•å®Œæˆï¼")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
