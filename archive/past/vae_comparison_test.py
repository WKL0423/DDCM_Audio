#!/usr/bin/env python3
"""
AudioLDM2 VAEå™ªéŸ³ä¿®å¤å¯¹æ¯”æµ‹è¯•
åŒæ—¶è¿è¡ŒåŸç‰ˆå’Œä¿®å¤ç‰ˆï¼Œç”Ÿæˆå¯¹æ¯”éŸ³é¢‘æ–‡ä»¶

å¯¹æ¯”é¡¹ç›®:
1. åŸç‰ˆsimple_vae_test.pyçš„è¾“å‡º
2. ä¿®å¤ç‰ˆvae_final_noise_fix.pyçš„è¾“å‡º
3. è´¨é‡æŒ‡æ ‡å¯¹æ¯”åˆ†æ
"""

import subprocess
import os
import sys
from pathlib import Path
import time
import pandas as pd
import numpy as np
import torchaudio
import torch


def run_original_test(audio_path, max_length):
    """è¿è¡ŒåŸç‰ˆæµ‹è¯•"""
    print("ğŸ”„ è¿è¡ŒåŸç‰ˆVAEæµ‹è¯•...")
    try:
        result = subprocess.run([
            sys.executable, "simple_vae_test.py", audio_path, str(max_length)
        ], capture_output=True, text=True, cwd=".", timeout=300)
        
        if result.returncode == 0:
            print("âœ… åŸç‰ˆæµ‹è¯•æˆåŠŸ")
            return True, result.stdout
        else:
            print(f"âŒ åŸç‰ˆæµ‹è¯•å¤±è´¥: {result.stderr}")
            return False, result.stderr
    except Exception as e:
        print(f"âŒ åŸç‰ˆæµ‹è¯•å¼‚å¸¸: {e}")
        return False, str(e)


def run_fixed_test(audio_path, max_length):
    """è¿è¡Œä¿®å¤ç‰ˆæµ‹è¯•"""
    print("ğŸ”„ è¿è¡Œä¿®å¤ç‰ˆVAEæµ‹è¯•...")
    try:
        result = subprocess.run([
            sys.executable, "vae_final_noise_fix.py", audio_path, str(max_length)
        ], capture_output=True, text=True, cwd=".", timeout=300)
        
        if result.returncode == 0:
            print("âœ… ä¿®å¤ç‰ˆæµ‹è¯•æˆåŠŸ")
            return True, result.stdout
        else:
            print(f"âŒ ä¿®å¤ç‰ˆæµ‹è¯•å¤±è´¥: {result.stderr}")
            return False, result.stderr
    except Exception as e:
        print(f"âŒ ä¿®å¤ç‰ˆæµ‹è¯•å¼‚å¸¸: {e}")
        return False, str(e)


def extract_metrics_from_output(output_text):
    """ä»è¾“å‡ºæ–‡æœ¬ä¸­æå–è´¨é‡æŒ‡æ ‡"""
    metrics = {}
    lines = output_text.split('\n')
    
    for line in lines:
        line = line.strip()
        if 'MSE:' in line:
            try:
                metrics['mse'] = float(line.split('MSE:')[1].strip())
            except:
                pass
        elif 'SNR:' in line and 'dB' in line:
            try:
                metrics['snr'] = float(line.split('SNR:')[1].split('dB')[0].strip())
            except:
                pass
        elif 'ç›¸å…³ç³»æ•°:' in line:
            try:
                metrics['correlation'] = float(line.split('ç›¸å…³ç³»æ•°:')[1].strip())
            except:
                pass
        elif 'ç¼–ç æ—¶é—´:' in line:
            try:
                metrics['encode_time'] = float(line.split('ç¼–ç æ—¶é—´:')[1].split('ç§’')[0].strip())
            except:
                pass
        elif 'è§£ç æ—¶é—´:' in line:
            try:
                metrics['decode_time'] = float(line.split('è§£ç æ—¶é—´:')[1].split('ç§’')[0].strip())
            except:
                pass
        elif 'å‹ç¼©æ¯”:' in line:
            try:
                metrics['compression_ratio'] = float(line.split('å‹ç¼©æ¯”:')[1].split(':')[0].strip())
            except:
                pass
        elif 'é‡å»ºæ–¹æ³•:' in line:
            try:
                metrics['method'] = line.split('é‡å»ºæ–¹æ³•:')[1].strip()
            except:
                pass
    
    return metrics


def find_latest_outputs():
    """æŸ¥æ‰¾æœ€æ–°çš„è¾“å‡ºæ–‡ä»¶"""
    original_dir = "vae_quick_test"
    fixed_dir = "vae_final_noise_fix"
    
    original_files = {'original': None, 'reconstructed': None}
    fixed_files = {'original': None, 'reconstructed': None}
    
    # æŸ¥æ‰¾åŸç‰ˆè¾“å‡º
    if os.path.exists(original_dir):
        files = list(Path(original_dir).glob("*.wav"))
        files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        for f in files:
            if 'original' in f.name and original_files['original'] is None:
                original_files['original'] = str(f)
            elif 'reconstructed' in f.name and original_files['reconstructed'] is None:
                original_files['reconstructed'] = str(f)
    
    # æŸ¥æ‰¾ä¿®å¤ç‰ˆè¾“å‡º
    if os.path.exists(fixed_dir):
        files = list(Path(fixed_dir).glob("*.wav"))
        files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        for f in files:
            if 'original' in f.name and fixed_files['original'] is None:
                fixed_files['original'] = str(f)
            elif 'final_noisefixed' in f.name and fixed_files['reconstructed'] is None:
                fixed_files['reconstructed'] = str(f)
    
    return original_files, fixed_files


def analyze_audio_quality(file1, file2, label1, label2):
    """åˆ†æä¸¤ä¸ªéŸ³é¢‘æ–‡ä»¶çš„è´¨é‡å·®å¼‚"""
    if not file1 or not file2 or not os.path.exists(file1) or not os.path.exists(file2):
        return None
    
    try:
        # åŠ è½½éŸ³é¢‘
        audio1, sr1 = torchaudio.load(file1)
        audio2, sr2 = torchaudio.load(file2)
        
        # ç¡®ä¿é‡‡æ ·ç‡ä¸€è‡´
        if sr1 != sr2:
            audio2 = torchaudio.functional.resample(audio2, sr2, sr1)
            sr2 = sr1
        
        # è½¬æ¢ä¸ºnumpy
        audio1 = audio1.squeeze().numpy()
        audio2 = audio2.squeeze().numpy()
        
        # ç¡®ä¿é•¿åº¦ä¸€è‡´
        min_len = min(len(audio1), len(audio2))
        audio1 = audio1[:min_len]
        audio2 = audio2[:min_len]
        
        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        mse = np.mean((audio1 - audio2) ** 2)
        
        # RMSåŠŸç‡
        rms1 = np.sqrt(np.mean(audio1 ** 2))
        rms2 = np.sqrt(np.mean(audio2 ** 2))
        
        # åŠ¨æ€èŒƒå›´
        dynamic_range1 = np.max(np.abs(audio1)) - np.min(np.abs(audio1))
        dynamic_range2 = np.max(np.abs(audio2)) - np.min(np.abs(audio2))
        
        # é¢‘è°±ä¸­å¿ƒ
        freqs = np.fft.fftfreq(len(audio1), 1/sr1)
        fft1 = np.abs(np.fft.fft(audio1))
        fft2 = np.abs(np.fft.fft(audio2))
        
        centroid1 = np.sum(freqs[:len(freqs)//2] * fft1[:len(freqs)//2]) / np.sum(fft1[:len(freqs)//2])
        centroid2 = np.sum(freqs[:len(freqs)//2] * fft2[:len(freqs)//2]) / np.sum(fft2[:len(freqs)//2])
        
        return {
            'mse_diff': mse,
            'rms_ratio': rms2 / rms1 if rms1 > 0 else 0,
            'dynamic_range_ratio': dynamic_range2 / dynamic_range1 if dynamic_range1 > 0 else 0,
            'spectral_centroid_diff': abs(centroid2 - centroid1),
            f'{label1}_rms': rms1,
            f'{label2}_rms': rms2,
            f'{label1}_dynamic_range': dynamic_range1,
            f'{label2}_dynamic_range': dynamic_range2
        }
        
    except Exception as e:
        print(f"   âš ï¸ éŸ³é¢‘åˆ†æå¤±è´¥: {e}")
        return None


def generate_comparison_report(original_metrics, fixed_metrics, audio_analysis, original_files, fixed_files):
    """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
    report = []
    report.append("=" * 80)
    report.append("AudioLDM2 VAE å™ªéŸ³ä¿®å¤å¯¹æ¯”æŠ¥å‘Š")
    report.append("=" * 80)
    report.append("")
    
    # æ–‡ä»¶ä¿¡æ¯
    report.append("ğŸ“ æ–‡ä»¶ä¿¡æ¯:")
    report.append(f"   åŸç‰ˆé‡å»ºéŸ³é¢‘: {original_files.get('reconstructed', 'N/A')}")
    report.append(f"   ä¿®å¤ç‰ˆé‡å»ºéŸ³é¢‘: {fixed_files.get('reconstructed', 'N/A')}")
    report.append("")
    
    # è´¨é‡æŒ‡æ ‡å¯¹æ¯”
    report.append("ğŸ“Š è´¨é‡æŒ‡æ ‡å¯¹æ¯”:")
    metrics_comparison = [
        ('MSE', 'mse', 'è¶Šå°è¶Šå¥½'),
        ('SNR (dB)', 'snr', 'è¶Šå¤§è¶Šå¥½'),
        ('ç›¸å…³ç³»æ•°', 'correlation', 'è¶Šæ¥è¿‘1è¶Šå¥½'),
        ('ç¼–ç æ—¶é—´ (ç§’)', 'encode_time', 'è¶Šå°è¶Šå¥½'),
        ('è§£ç æ—¶é—´ (ç§’)', 'decode_time', 'è¶Šå°è¶Šå¥½'),
        ('å‹ç¼©æ¯”', 'compression_ratio', 'ä¿¡æ¯'),
        ('é‡å»ºæ–¹æ³•', 'method', 'ä¿¡æ¯')
    ]
    
    for metric_name, metric_key, note in metrics_comparison:
        orig_val = original_metrics.get(metric_key, 'N/A')
        fixed_val = fixed_metrics.get(metric_key, 'N/A')
        
        report.append(f"   {metric_name:15} | åŸç‰ˆ: {orig_val:>12} | ä¿®å¤ç‰ˆ: {fixed_val:>12} | {note}")
    
    report.append("")
    
    # éŸ³é¢‘åˆ†æ
    if audio_analysis:
        report.append("ğŸµ éŸ³é¢‘è´¨é‡åˆ†æ:")
        report.append(f"   RMSåŠŸç‡æ¯”å€¼: {audio_analysis.get('rms_ratio', 'N/A'):.4f} (ä¿®å¤ç‰ˆ/åŸç‰ˆ)")
        report.append(f"   åŠ¨æ€èŒƒå›´æ¯”å€¼: {audio_analysis.get('dynamic_range_ratio', 'N/A'):.4f} (ä¿®å¤ç‰ˆ/åŸç‰ˆ)")
        report.append(f"   é¢‘è°±ä¸­å¿ƒå·®å¼‚: {audio_analysis.get('spectral_centroid_diff', 'N/A'):.2f} Hz")
        report.append("")
    
    # æ”¹è¿›æ€»ç»“
    report.append("âœ… ä¿®å¤ç‰ˆæ”¹è¿›å†…å®¹:")
    report.append("   1. è§£å†³äº†æ•°å€¼æº¢å‡ºé—®é¢˜ (std=inf)")
    report.append("   2. å¼ºåˆ¶ä½¿ç”¨float32é¿å…ç±»å‹ä¸å…¼å®¹")
    report.append("   3. å¼‚å¸¸å€¼æ£€æµ‹å’Œä¿®å¤ (ç‚¹å‡»å™ªéŸ³)")
    report.append("   4. æ¸å˜æ·¡å…¥æ·¡å‡ºå¤„ç†")
    report.append("   5. é«˜çº§å¸¦é€šæ»¤æ³¢")
    report.append("   6. åŠ¨æ€èŒƒå›´å‹ç¼©")
    report.append("   7. è½»å¾®å¹³æ»‘æ»¤æ³¢")
    report.append("")
    
    # å»ºè®®
    report.append("ğŸ’¡ å»ºè®®:")
    if fixed_metrics.get('snr', 0) > original_metrics.get('snr', 0):
        report.append("   âœ… ä¿®å¤ç‰ˆSNRæ›´é«˜ï¼Œå™ªéŸ³å‡å°‘æ•ˆæœæ˜æ˜¾")
    else:
        report.append("   âš ï¸ ä¿®å¤ç‰ˆSNRæœªæ˜æ˜¾æ”¹å–„ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒä¼˜")
    
    if audio_analysis and audio_analysis.get('rms_ratio', 1) < 0.8:
        report.append("   âš ï¸ ä¿®å¤ç‰ˆéŸ³é‡æ˜¾è‘—é™ä½ï¼Œå¯èƒ½è¿‡åº¦å‹ç¼©")
    elif audio_analysis and audio_analysis.get('rms_ratio', 1) > 1.2:
        report.append("   âš ï¸ ä¿®å¤ç‰ˆéŸ³é‡æ˜¾è‘—å¢åŠ ï¼Œæ³¨æ„å‰Šæ³¢")
    else:
        report.append("   âœ… ä¿®å¤ç‰ˆéŸ³é‡æ§åˆ¶åˆç†")
    
    report.append("")
    report.append("ğŸ§ å¬è§‰æµ‹è¯•å»ºè®®:")
    report.append("   è¯·ç”¨éŸ³é¢‘æ’­æ”¾å™¨æ¯”è¾ƒä¸¤ä¸ªé‡å»ºæ–‡ä»¶ï¼Œé‡ç‚¹å…³æ³¨:")
    report.append("   - ç‚¹å‡»/çˆ†éŸ³å™ªéŸ³æ˜¯å¦å‡å°‘")
    report.append("   - æ•´ä½“éŸ³è´¨æ˜¯å¦æ”¹å–„")
    report.append("   - æ˜¯å¦ä¿æŒäº†åŸå§‹éŸ³é¢‘çš„ç‰¹å¾")
    
    return "\n".join(report)


def run_comparison_test(audio_path, max_length=10):
    """è¿è¡Œå®Œæ•´çš„å¯¹æ¯”æµ‹è¯•"""
    print(f"\nğŸ¯ å¼€å§‹AudioLDM2 VAEå™ªéŸ³ä¿®å¤å¯¹æ¯”æµ‹è¯•")
    print(f"éŸ³é¢‘æ–‡ä»¶: {audio_path}")
    print(f"æœ€å¤§é•¿åº¦: {max_length} ç§’")
    print("=" * 60)
    
    # è¿è¡ŒåŸç‰ˆæµ‹è¯•
    original_success, original_output = run_original_test(audio_path, max_length)
    time.sleep(2)  # ç­‰å¾…æ–‡ä»¶å†™å…¥
    
    # è¿è¡Œä¿®å¤ç‰ˆæµ‹è¯•
    fixed_success, fixed_output = run_fixed_test(audio_path, max_length)
    time.sleep(2)  # ç­‰å¾…æ–‡ä»¶å†™å…¥
    
    if not original_success and not fixed_success:
        print("âŒ ä¸¤ä¸ªæµ‹è¯•éƒ½å¤±è´¥äº†")
        return
    
    # æå–æŒ‡æ ‡
    original_metrics = {}
    fixed_metrics = {}
    
    if original_success:
        original_metrics = extract_metrics_from_output(original_output)
    
    if fixed_success:
        fixed_metrics = extract_metrics_from_output(fixed_output)
    
    # æŸ¥æ‰¾è¾“å‡ºæ–‡ä»¶
    original_files, fixed_files = find_latest_outputs()
    
    # éŸ³é¢‘è´¨é‡åˆ†æ
    audio_analysis = None
    if original_files['reconstructed'] and fixed_files['reconstructed']:
        print("ğŸ” åˆ†æéŸ³é¢‘è´¨é‡å·®å¼‚...")
        audio_analysis = analyze_audio_quality(
            original_files['reconstructed'],
            fixed_files['reconstructed'],
            "original", "fixed"
        )
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generate_comparison_report(
        original_metrics, fixed_metrics, audio_analysis,
        original_files, fixed_files
    )
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = f"vae_noise_fix_comparison_{int(time.time())}.txt"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\n{report}")
    print(f"\nğŸ“ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
    
    return {
        'original_metrics': original_metrics,
        'fixed_metrics': fixed_metrics,
        'audio_analysis': audio_analysis,
        'report_path': report_path
    }


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python vae_comparison_test.py <éŸ³é¢‘æ–‡ä»¶è·¯å¾„> [æœ€å¤§é•¿åº¦ç§’æ•°]")
        
        audio_files = []
        for ext in ['.wav', '.mp3', '.flac']:
            audio_files.extend(Path('.').glob(f'*{ext}'))
        
        if audio_files:
            print(f"\næ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶:")
            for i, file in enumerate(audio_files, 1):
                print(f"{i}. {file}")
            
            try:
                choice = input("è¯·é€‰æ‹©æ–‡ä»¶åºå·: ").strip()
                file_idx = int(choice) - 1
                if 0 <= file_idx < len(audio_files):
                    audio_path = str(audio_files[file_idx])
                else:
                    print("æ— æ•ˆé€‰æ‹©")
                    return
            except (ValueError, KeyboardInterrupt):
                print("å–æ¶ˆæ“ä½œ")
                return
        else:
            print("å½“å‰ç›®å½•æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
            return
    else:
        audio_path = sys.argv[1]
    
    max_length = 10
    if len(sys.argv) >= 3:
        try:
            max_length = float(sys.argv[2])
        except ValueError:
            print(f"æ— æ•ˆé•¿åº¦å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼ {max_length} ç§’")
    
    try:
        result = run_comparison_test(audio_path, max_length)
        if result:
            print(f"\nâœ… å¯¹æ¯”æµ‹è¯•å®Œæˆï¼")
            print(f"è¯·æŸ¥çœ‹æŠ¥å‘Šå¹¶æ’­æ”¾éŸ³é¢‘æ–‡ä»¶è¿›è¡Œä¸»è§‚è¯„ä¼°ã€‚")
    except Exception as e:
        print(f"âŒ å¯¹æ¯”æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
