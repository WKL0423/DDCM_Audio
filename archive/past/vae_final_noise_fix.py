#!/usr/bin/env python3
"""
AudioLDM2 VAE é‡å»ºæµ‹è¯• - æœ€ç»ˆå™ªéŸ³ä¿®å¤ç‰ˆæœ¬
ä¸“é—¨è§£å†³HiFiGANçš„"å’”å“’å’”å“’"å™ªéŸ³é—®é¢˜

ä¸»è¦ä¿®å¤:
1. å¼ºåˆ¶ä½¿ç”¨float32é¿å…æº¢å‡º
2. ç®€åŒ–ä½†æœ‰æ•ˆçš„å½’ä¸€åŒ–ç­–ç•¥
3. é’ˆå¯¹æ€§çš„åå¤„ç†é™å™ª
"""

import torch
import torchaudio
import numpy as np
import librosa
import time
import os
import sys
from pathlib import Path
from diffusers import AudioLDM2Pipeline
import scipy.signal
from scipy.ndimage import gaussian_filter1d

# å°è¯•å¯¼å…¥ soundfile ä»¥è·å¾—æ›´å¥½çš„å…¼å®¹æ€§
try:
    import soundfile as sf
    SOUNDFILE_AVAILABLE = True
except ImportError:
    SOUNDFILE_AVAILABLE = False
    print("âš ï¸ soundfile ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ torchaudio ä¿å­˜ï¼ˆå¯èƒ½å­˜åœ¨å…¼å®¹æ€§é—®é¢˜ï¼‰")


def save_audio_compatible(audio_data, filepath, sample_rate=16000):
    """
    ä¿å­˜éŸ³é¢‘æ–‡ä»¶ï¼Œä¼˜å…ˆä½¿ç”¨ soundfile ä»¥è·å¾—æœ€å¤§å…¼å®¹æ€§
    
    Args:
        audio_data: éŸ³é¢‘æ•°æ® (numpy array)
        filepath: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        sample_rate: é‡‡æ ·ç‡
    """
    # ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯æ­£ç¡®çš„æ ¼å¼
    if isinstance(audio_data, torch.Tensor):
        audio_data = audio_data.detach().cpu().numpy()
    
    # ç¡®ä¿æ˜¯ 1D æ•°ç»„
    if len(audio_data.shape) > 1:
        audio_data = audio_data.flatten()
    
    # æ¸…ç†æ•°æ®
    audio_data = np.nan_to_num(audio_data, nan=0.0, posinf=0.0, neginf=0.0)
    
    # å½’ä¸€åŒ–åˆ° [-1, 1] èŒƒå›´
    if np.max(np.abs(audio_data)) > 0:
        audio_data = audio_data / np.max(np.abs(audio_data))
    
    success = False
    
    if SOUNDFILE_AVAILABLE:
        try:
            # ä½¿ç”¨ soundfile ä¿å­˜ä¸º PCM_16 æ ¼å¼ï¼ˆæœ€é«˜å…¼å®¹æ€§ï¼‰
            sf.write(filepath, audio_data, sample_rate, subtype='PCM_16')
            print(f"   âœ… ä½¿ç”¨ soundfile (PCM_16) ä¿å­˜: {filepath}")
            success = True
        except Exception as e:
            print(f"   âš ï¸ soundfile ä¿å­˜å¤±è´¥: {e}")
    
    if not success:
        try:
            # å›é€€åˆ° torchaudio
            audio_tensor = torch.from_numpy(audio_data).unsqueeze(0).float()
            torchaudio.save(filepath, audio_tensor, sample_rate)
            print(f"   âœ… ä½¿ç”¨ torchaudio ä¿å­˜: {filepath}")
            success = True
        except Exception as e:
            print(f"   âŒ torchaudio ä¿å­˜ä¹Ÿå¤±è´¥: {e}")
    
    return success


def simple_safe_normalize(mel_tensor, target_range=(-10, 10)):
    """ç®€å•è€Œå®‰å…¨çš„å½’ä¸€åŒ–ç­–ç•¥"""
    if isinstance(mel_tensor, torch.Tensor):
        # å¼ºåˆ¶è½¬æ¢ä¸ºfloat32
        mel_float32 = mel_tensor.detach().cpu().numpy().astype(np.float32)
    else:
        mel_float32 = np.array(mel_tensor, dtype=np.float32)
    
    # ç§»é™¤ä»»ä½•æ— æ•ˆå€¼
    mel_float32 = np.nan_to_num(mel_float32, nan=0.0, posinf=0.0, neginf=-50.0)
    
    # ç®€å•çš„min-maxå½’ä¸€åŒ–åˆ°ç›®æ ‡èŒƒå›´
    current_min = np.min(mel_float32)
    current_max = np.max(mel_float32)
    
    print(f"   ç®€å•å½’ä¸€åŒ–: min={current_min:.3f}, max={current_max:.3f}")
    
    if current_max > current_min:
        # å½’ä¸€åŒ–åˆ°[0, 1]ç„¶åæ˜ å°„åˆ°ç›®æ ‡èŒƒå›´
        normalized = (mel_float32 - current_min) / (current_max - current_min)
        normalized = normalized * (target_range[1] - target_range[0]) + target_range[0]
    else:
        # å¦‚æœæ‰€æœ‰å€¼éƒ½ç›¸åŒï¼Œè®¾ç½®ä¸ºç›®æ ‡èŒƒå›´çš„ä¸­ç‚¹
        normalized = np.full_like(mel_float32, (target_range[0] + target_range[1]) / 2)
    
    final_min = np.min(normalized)
    final_max = np.max(normalized)
    print(f"   å½’ä¸€åŒ–ç»“æœ: min={final_min:.3f}, max={final_max:.3f}")
    
    if isinstance(mel_tensor, torch.Tensor):
        return torch.from_numpy(normalized).to(mel_tensor.device).to(torch.float32)
    else:
        return normalized


def advanced_audio_denoising(audio, sr=16000):
    """é«˜çº§éŸ³é¢‘é™å™ªå¤„ç†"""
    if len(audio) == 0:
        return audio
    
    # 1. ç§»é™¤ç›´æµåç½®
    audio = audio - np.mean(audio)
    
    # 2. æ£€æµ‹å¹¶ç§»é™¤å¼‚å¸¸å€¼ï¼ˆå¯èƒ½çš„ç‚¹å‡»å£°ï¼‰
    # ä½¿ç”¨3-sigmaè§„åˆ™æ£€æµ‹å¼‚å¸¸å€¼
    std_audio = np.std(audio)
    mean_audio = np.mean(audio)
    threshold = 3 * std_audio
    
    # æ‰¾åˆ°å¼‚å¸¸å€¼å¹¶ç”¨ä¸­å€¼æ›¿æ¢
    outliers = np.abs(audio - mean_audio) > threshold
    if np.any(outliers):
        print(f"   æ£€æµ‹åˆ° {np.sum(outliers)} ä¸ªå¼‚å¸¸å€¼ç‚¹å‡»ï¼Œè¿›è¡Œä¿®å¤...")
        # ä½¿ç”¨æ»‘åŠ¨çª—å£ä¸­å€¼æ»¤æ³¢å™¨ä¿®å¤å¼‚å¸¸å€¼
        from scipy.ndimage import median_filter
        audio_median = median_filter(audio, size=5)
        audio[outliers] = audio_median[outliers]
    
    # 3. åº”ç”¨æ¸å˜è¾¹ç•Œ
    fade_samples = min(1024, len(audio) // 8)
    if len(audio) > 2 * fade_samples:
        # æ·¡å…¥
        fade_in = np.linspace(0, 1, fade_samples) ** 0.5  # å¹³æ–¹æ ¹æ·¡å…¥æ›´å¹³æ»‘
        audio[:fade_samples] *= fade_in
        
        # æ·¡å‡º
        fade_out = np.linspace(1, 0, fade_samples) ** 0.5
        audio[-fade_samples:] *= fade_out
    
    # 4. è½»å¾®å¹³æ»‘ï¼ˆå‡å°‘é«˜é¢‘å™ªéŸ³ï¼‰
    audio = gaussian_filter1d(audio, sigma=1.0)
    
    # 5. é«˜è´¨é‡å¸¦é€šæ»¤æ³¢
    try:
        nyquist = sr / 2
        # æ›´ä¿å®ˆçš„æ»¤æ³¢èŒƒå›´
        low_freq = 60   # 60Hzé«˜é€š
        high_freq = 7000  # 7kHzä½é€š
        
        low = low_freq / nyquist
        high = high_freq / nyquist
        
        # ä½¿ç”¨æ¤­åœ†æ»¤æ³¢å™¨ï¼ˆæ›´é™¡å³­çš„è¡°å‡ï¼‰
        b, a = scipy.signal.ellip(5, 1, 60, [low, high], btype='band')
        audio = scipy.signal.filtfilt(b, a, audio)
        
    except Exception as e:
        print(f"   æ»¤æ³¢å™¨è­¦å‘Š: {e}")
    
    # 6. åŠ¨æ€èŒƒå›´å‹ç¼©ï¼ˆå‡å°‘å³°å€¼äº§ç”Ÿçš„ç‚¹å‡»ï¼‰
    threshold = 0.7
    ratio = 0.3
    audio = np.where(np.abs(audio) > threshold,
                     np.sign(audio) * (threshold + (np.abs(audio) - threshold) * ratio),
                     audio)
    
    return audio


def load_and_test_vae_final(audio_path, max_length=10):
    """æœ€ç»ˆçš„VAEæµ‹è¯•ç‰ˆæœ¬ï¼Œä¸“æ³¨äºå™ªéŸ³ä¿®å¤"""
    print(f"\nğŸµ AudioLDM2 VAEæœ€ç»ˆå™ªéŸ³ä¿®å¤æµ‹è¯•")
    print(f"éŸ³é¢‘æ–‡ä»¶: {audio_path}")
    print(f"æœ€å¤§é•¿åº¦: {max_length} ç§’")
    
    # è®¾å¤‡è®¾ç½®
    device = "cuda" if torch.cuda.is_available() else "cpu"
    dtype = torch.float32  # å¼ºåˆ¶ä½¿ç”¨float32
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}, æ•°æ®ç±»å‹: {dtype}")
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ“¦ åŠ è½½ AudioLDM2 æ¨¡å‹...")
    try:
        pipeline = AudioLDM2Pipeline.from_pretrained(
            "cvssp/audioldm2",
            torch_dtype=dtype
        ).to(device)
        
        vae = pipeline.vae
        vocoder = pipeline.vocoder
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None
    
    # åŠ è½½éŸ³é¢‘
    print(f"ğŸ¶ åŠ è½½éŸ³é¢‘...")
    try:
        sample_rate = 16000
        audio, orig_sr = torchaudio.load(audio_path)
        
        if orig_sr != sample_rate:
            audio = torchaudio.functional.resample(audio, orig_sr, sample_rate)
        
        if audio.shape[0] > 1:
            audio = torch.mean(audio, dim=0, keepdim=True)
        
        audio = audio.squeeze().numpy().astype(np.float32)
        
        # æˆªå–
        max_samples = int(max_length * sample_rate)
        if len(audio) > max_samples:
            audio = audio[:max_samples]
        
        # é¢„å¤„ç†
        audio = audio - np.mean(audio)
        if np.max(np.abs(audio)) > 0:
            audio = audio / np.max(np.abs(audio)) * 0.95
        
        print(f"   éŸ³é¢‘é•¿åº¦: {len(audio)} æ ·æœ¬")
        
    except Exception as e:
        print(f"âŒ éŸ³é¢‘åŠ è½½å¤±è´¥: {e}")
        return None
    
    # ç”Ÿæˆmel-spectrogram
    print("ğŸ”„ ç”Ÿæˆ mel-spectrogram...")
    mel_spec = librosa.feature.melspectrogram(
        y=audio,
        sr=sample_rate,
        n_fft=1024,
        hop_length=160,
        n_mels=64,
        fmin=0,
        fmax=8000
    )
    
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max, top_db=80)
    mel_spec_db = np.clip(mel_spec_db, -80, 0).astype(np.float32)
    
    print(f"   Melå½¢çŠ¶: {mel_spec_db.shape}")
    
    # VAEå¤„ç†
    with torch.no_grad():
        # å‡†å¤‡è¾“å…¥
        mel_tensor = torch.from_numpy(mel_spec_db).to(device).to(dtype)
        mel_input = mel_tensor.unsqueeze(0).unsqueeze(0)
        
        # å¡«å……
        time_dim = mel_input.shape[-1]
        if time_dim % 8 != 0:
            pad_width = 8 - (time_dim % 8)
            mel_input = torch.nn.functional.pad(mel_input, (0, pad_width), mode='constant', value=-80)
        
        # å½’ä¸€åŒ–
        mel_min, mel_max = -80.0, 0.0
        mel_normalized = 2.0 * (mel_input - mel_min) / (mel_max - mel_min) - 1.0
        mel_normalized = torch.clamp(mel_normalized, -1, 1)
        
        # VAEç¼–ç 
        print("ğŸ”§ VAE ç¼–ç ...")
        start_time = time.time()
        latents = vae.encode(mel_normalized).latent_dist.sample()
        latents = latents * vae.config.scaling_factor
        encode_time = time.time() - start_time
        
        # VAEè§£ç 
        print("ğŸ”§ VAE è§£ç ...")
        decode_start = time.time()
        latents_scaled = latents / vae.config.scaling_factor
        reconstructed_mel = vae.decode(latents_scaled).sample
        decode_time = time.time() - decode_start
        
        print(f"   ç¼–ç : {encode_time:.2f}s, è§£ç : {decode_time:.2f}s")
    
    # éŸ³é¢‘é‡å»º - é‡ç‚¹ä¿®å¤
    print("ğŸ”Š éŸ³é¢‘é‡å»º (å™ªéŸ³ä¿®å¤ç‰ˆæœ¬)...")
    
    try:
        with torch.no_grad():
            # åå½’ä¸€åŒ–
            mel_denorm = (reconstructed_mel + 1) / 2 * (mel_max - mel_min) + mel_min
            mel_denorm = torch.clamp(mel_denorm, mel_min, mel_max)
            
            # è½¬æ¢ä¸ºfloat32ç¡®ä¿å…¼å®¹æ€§
            mel_denorm = mel_denorm.to(torch.float32)
            
            # æ£€æŸ¥æœ‰æ•ˆæ€§
            if not torch.isfinite(mel_denorm).all():
                print(f"   âš ï¸ ä¿®å¤æ— æ•ˆå€¼...")
                mel_denorm = torch.nan_to_num(mel_denorm, nan=-40.0, posinf=-20.0, neginf=-80.0)
            
            # å‡†å¤‡vocoderè¾“å…¥
            vocoder_input = mel_denorm.squeeze(0).squeeze(0)  # [64, time]
            vocoder_input = vocoder_input.transpose(-2, -1)   # [time, 64]
            vocoder_input = vocoder_input.unsqueeze(0)        # [1, time, 64]
            
            print(f"   Vocoderè¾“å…¥å½¢çŠ¶: {vocoder_input.shape}")
            print(f"   Vocoderè¾“å…¥èŒƒå›´: [{vocoder_input.min().item():.3f}, {vocoder_input.max().item():.3f}]")
            
            # ç®€å•å½’ä¸€åŒ–
            vocoder_input_norm = simple_safe_normalize(vocoder_input, target_range=(-8, 2))
            
            # ç¡®ä¿vocoderä¹Ÿä½¿ç”¨float32
            vocoder.to(dtype)
            
            # ä½¿ç”¨vocoder
            reconstructed_audio_tensor = vocoder(vocoder_input_norm)
            reconstructed_audio = reconstructed_audio_tensor.squeeze().cpu().numpy().astype(np.float32)
            
            print(f"   âœ… HiFiGANæˆåŠŸ: {len(reconstructed_audio)}æ ·æœ¬")
            
            # é«˜çº§é™å™ªå¤„ç†
            print("ğŸ› ï¸ åº”ç”¨é«˜çº§é™å™ªå¤„ç†...")
            reconstructed_audio = advanced_audio_denoising(reconstructed_audio, sr=sample_rate)
            
            vocoder_method = "AudioLDM2_HiFiGAN_FinalFix"
            
    except Exception as e:
        print(f"   âŒ HiFiGANå¤±è´¥: {e}")
        print("   ğŸ“Š ä½¿ç”¨Griffin-Lim...")
        
        # Griffin-Limé™çº§
        try:
            recon_mel_np = reconstructed_mel.squeeze().cpu().numpy().astype(np.float32)
            recon_mel_denorm = (recon_mel_np + 1) / 2 * (mel_max - mel_min) + mel_min
            recon_mel_denorm = np.clip(recon_mel_denorm, -80.0, 0.0)
            
            recon_mel_power = librosa.db_to_power(recon_mel_denorm)
            recon_mel_power = np.clip(recon_mel_power, 1e-10, None)
            
            reconstructed_audio = librosa.feature.inverse.mel_to_audio(
                recon_mel_power,
                sr=sample_rate,
                hop_length=160,
                n_fft=1024,
                fmin=0,
                fmax=8000
            )
            
            reconstructed_audio = advanced_audio_denoising(reconstructed_audio, sr=sample_rate)
            vocoder_method = "Griffin_Lim_Advanced"
            
        except Exception as griffin_e:
            print(f"   âŒ Griffin-Limå¤±è´¥: {griffin_e}")
            reconstructed_audio = np.random.randn(len(audio)) * 0.001
            vocoder_method = "Fallback"
    
    # é•¿åº¦å¯¹é½
    if len(reconstructed_audio) > len(audio):
        reconstructed_audio = reconstructed_audio[:len(audio)]
    elif len(reconstructed_audio) < len(audio):
        reconstructed_audio = np.pad(reconstructed_audio, (0, len(audio) - len(reconstructed_audio)))
      # ä¿å­˜ç»“æœï¼ˆä½¿ç”¨é«˜å…¼å®¹æ€§ä¿å­˜æ–¹æ³•ï¼‰
    print("ğŸ’¾ ä¿å­˜ç»“æœ...")
    output_dir = "vae_final_noise_fix"
    os.makedirs(output_dir, exist_ok=True)
    
    input_name = Path(audio_path).stem
    timestamp = int(time.time())
    
    original_path = os.path.join(output_dir, f"{input_name}_original_{timestamp}.wav")
    reconstructed_path = os.path.join(output_dir, f"{input_name}_final_noisefixed_{timestamp}.wav")
    
    # å½’ä¸€åŒ–
    audio_norm = audio / np.max(np.abs(audio)) if np.max(np.abs(audio)) > 0 else audio
    recon_norm = reconstructed_audio / np.max(np.abs(reconstructed_audio)) if np.max(np.abs(reconstructed_audio)) > 0 else reconstructed_audio
    
    # ä½¿ç”¨å…¼å®¹æ€§ä¿å­˜å‡½æ•°
    save_audio_compatible(audio_norm, original_path, sample_rate)
    save_audio_compatible(recon_norm, reconstructed_path, sample_rate)
    
    # è®¡ç®—æŒ‡æ ‡
    min_len = min(len(audio), len(reconstructed_audio))
    orig_segment = audio[:min_len]
    recon_segment = reconstructed_audio[:min_len]
    
    mse = np.mean((orig_segment - recon_segment) ** 2)
    correlation = np.corrcoef(orig_segment, recon_segment)[0, 1] if len(orig_segment) > 1 else 0
    
    signal_power = np.mean(orig_segment ** 2)
    noise_power = np.mean((orig_segment - recon_segment) ** 2)
    snr = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else float('inf')
    
    original_size = mel_normalized.numel()
    compressed_size = latents.numel()
    compression_ratio = original_size / compressed_size
    
    # æ‰“å°ç»“æœ
    print(f"\n{'='*60}")
    print(f"VAE é‡å»ºæµ‹è¯• - æœ€ç»ˆå™ªéŸ³ä¿®å¤ç‰ˆæœ¬")
    print(f"{'='*60}")
    print(f"åŸå§‹éŸ³é¢‘: {original_path}")
    print(f"é‡å»ºéŸ³é¢‘: {reconstructed_path}")
    print(f"ç¼–ç æ—¶é—´: {encode_time:.2f}ç§’")
    print(f"è§£ç æ—¶é—´: {decode_time:.2f}ç§’")
    print(f"æ€»æ—¶é—´: {encode_time + decode_time:.2f}ç§’")
    print(f"MSE: {mse:.6f}")
    print(f"SNR: {snr:.2f} dB")
    print(f"ç›¸å…³ç³»æ•°: {correlation:.4f}")
    print(f"å‹ç¼©æ¯”: {compression_ratio:.1f}:1")
    print(f"é‡å»ºæ–¹æ³•: {vocoder_method}")
    print(f"âœ… ä¿®å¤å†…å®¹: float32å…¼å®¹æ€§ã€å¼‚å¸¸å€¼æ£€æµ‹ã€é«˜çº§é™å™ªã€åŠ¨æ€èŒƒå›´å‹ç¼©")
    
    return {
        'original_path': original_path,
        'reconstructed_path': reconstructed_path,
        'mse': mse,
        'snr': snr,
        'correlation': correlation,
        'encode_time': encode_time,
        'decode_time': decode_time,
        'compression_ratio': compression_ratio,
        'vocoder_method': vocoder_method
    }


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python vae_final_noise_fix.py <éŸ³é¢‘æ–‡ä»¶è·¯å¾„> [æœ€å¤§é•¿åº¦ç§’æ•°]")
        
        audio_files = []
        for ext in ['.wav', '.mp3', '.flac']:
            audio_files.extend(Path('.').glob(f'*{ext}'))
        
        if audio_files:
            print(f"\næ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶:")
            for i, file in enumerate(audio_files, 1):
                print(f"{i}. {file}")
            
            try:
                choice = input("è¯·é€‰æ‹©æ–‡ä»¶åºå·: ").strip()
                file_idx = int(choice) - 1
                if 0 <= file_idx < len(audio_files):
                    audio_path = str(audio_files[file_idx])
                else:
                    print("æ— æ•ˆé€‰æ‹©")
                    return
            except (ValueError, KeyboardInterrupt):
                print("å–æ¶ˆæ“ä½œ")
                return
        else:
            print("å½“å‰ç›®å½•æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
            return
    else:
        audio_path = sys.argv[1]
    
    max_length = 10
    if len(sys.argv) >= 3:
        try:
            max_length = float(sys.argv[2])
        except ValueError:
            print(f"æ— æ•ˆé•¿åº¦å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼ {max_length} ç§’")
    
    print(f"ğŸš€ å¼€å§‹æœ€ç»ˆå™ªéŸ³ä¿®å¤æµ‹è¯•")
    
    try:
        result = load_and_test_vae_final(audio_path, max_length=max_length)
        if result:
            print(f"\nâœ… æœ€ç»ˆæµ‹è¯•å®Œæˆï¼")
            print(f"è¯·æ’­æ”¾é‡å»ºéŸ³é¢‘æ£€æŸ¥å™ªéŸ³ä¿®å¤æ•ˆæœã€‚")
            print(f"å¦‚æœä»æœ‰å™ªéŸ³ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´vocoderå‚æ•°æˆ–ä½¿ç”¨æ›´é«˜çº§çš„åå¤„ç†ã€‚")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
